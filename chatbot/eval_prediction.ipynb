{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "103IcJjInlbmAyJidoshN2m8cU9cQi1II",
      "authorship_tag": "ABX9TyPSnezaxJsHSDPW0QRO4Ajn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeinabmohamed/CIT690E-DeepLearning-Zeinab_Abdelmawla-191009/blob/main/chatbot/eval_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def readJson(filename):\n",
        "  with open(filename, 'r') as file:\n",
        "    intents = json.load(file)\n",
        "    return intents"
      ],
      "metadata": {
        "id": "MvJxrd39x59v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questionDoctorQAs = readJson('questionDoctorQAs.json')"
      ],
      "metadata": {
        "id": "lR3kFRsix2D-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "all_medical_df = pd.DataFrame.from_dict(questionDoctorQAs)\n",
        "all_medical_df"
      ],
      "metadata": {
        "id": "plUEk78cyg0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "4894acab-b8c1-4c4d-f011-ae3fbd0b07ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b52a11bc-6240-49b9-8322-b3c2ecddf424\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_author</th>\n",
              "      <th>question</th>\n",
              "      <th>question_text</th>\n",
              "      <th>tags</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you can stay assured you are fine free of hiv....</td>\n",
              "      <td>Dr. Ayman Darrag</td>\n",
              "      <td>is my anti hiv test conclusive or need retest?</td>\n",
              "      <td>Is my Anti Hiv Test Conclusive or need retest?</td>\n",
              "      <td>[hiv test]</td>\n",
              "      <td>https://questiondoctors.com/is-my-anti-hiv-tes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi you are 100 % hiv free good luck</td>\n",
              "      <td>Dr Ahmed Fawzy</td>\n",
              "      <td>is my anti hiv test conclusive or need retest?</td>\n",
              "      <td>Is my Anti Hiv Test Conclusive or need retest?</td>\n",
              "      <td>[hiv test]</td>\n",
              "      <td>https://questiondoctors.com/is-my-anti-hiv-tes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>your time slots of the tests and the final res...</td>\n",
              "      <td>Dr.Honey</td>\n",
              "      <td>is my anti hiv test conclusive or need retest?</td>\n",
              "      <td>Is my Anti Hiv Test Conclusive or need retest?</td>\n",
              "      <td>[hiv test]</td>\n",
              "      <td>https://questiondoctors.com/is-my-anti-hiv-tes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi i see no labrum tear however i see acetabul...</td>\n",
              "      <td>Dr Ahmed Fawzy</td>\n",
              "      <td>i have some hip pain 9 weeks. had mra image re...</td>\n",
              "      <td>I have some hip pain 9 weeks. Had MRA image re...</td>\n",
              "      <td>[magnetic resonance angiography (mra)]</td>\n",
              "      <td>https://questiondoctors.com/i-have-some-hip-pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no visible tear in labrum but obviously calcif...</td>\n",
              "      <td>Dr. Ayman Darrag</td>\n",
              "      <td>i have some hip pain 9 weeks. had mra image re...</td>\n",
              "      <td>I have some hip pain 9 weeks. Had MRA image re...</td>\n",
              "      <td>[magnetic resonance angiography (mra)]</td>\n",
              "      <td>https://questiondoctors.com/i-have-some-hip-pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5674</th>\n",
              "      <td>get it confirmed by doing venous doppler of bo...</td>\n",
              "      <td>Dr Mahaveer</td>\n",
              "      <td>pain in legs – varicose veins?</td>\n",
              "      <td>Question: Pain in Legs – Varicose veins?</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://questiondoctors.com/question-pain-in-l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5675</th>\n",
              "      <td>hi dear. there are very less chances of pregna...</td>\n",
              "      <td>Dr Mahaveer</td>\n",
              "      <td>headaches really tired all the time feeling na...</td>\n",
              "      <td>Question: Headaches, really tired all the time...</td>\n",
              "      <td>[don't know if its too early to take a pregnan...</td>\n",
              "      <td>https://questiondoctors.com/question-headaches...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5676</th>\n",
              "      <td>i’m a radiologist. may be an mri misread. when...</td>\n",
              "      <td>Dr. Erik Ramonov</td>\n",
              "      <td>46 year old male had stroke on right side of b...</td>\n",
              "      <td>Question: 46 year old male had stroke on right...</td>\n",
              "      <td>[stroke on right side of brain]</td>\n",
              "      <td>https://questiondoctors.com/question-46-year-o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5677</th>\n",
              "      <td>could be reaction to oxycodone…. ”the most fre...</td>\n",
              "      <td>Jason Roberge</td>\n",
              "      <td>46 year old male had stroke on right side of b...</td>\n",
              "      <td>Question: 46 year old male had stroke on right...</td>\n",
              "      <td>[stroke on right side of brain]</td>\n",
              "      <td>https://questiondoctors.com/question-46-year-o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5678</th>\n",
              "      <td>dont think this is another stroke. dont worry....</td>\n",
              "      <td>Dr Mahaveer</td>\n",
              "      <td>46 year old male had stroke on right side of b...</td>\n",
              "      <td>Question: 46 year old male had stroke on right...</td>\n",
              "      <td>[stroke on right side of brain]</td>\n",
              "      <td>https://questiondoctors.com/question-46-year-o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5679 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52a11bc-6240-49b9-8322-b3c2ecddf424')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b52a11bc-6240-49b9-8322-b3c2ecddf424 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b52a11bc-6240-49b9-8322-b3c2ecddf424');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 answer  ...                                                url\n",
              "0     you can stay assured you are fine free of hiv....  ...  https://questiondoctors.com/is-my-anti-hiv-tes...\n",
              "1                   hi you are 100 % hiv free good luck  ...  https://questiondoctors.com/is-my-anti-hiv-tes...\n",
              "2     your time slots of the tests and the final res...  ...  https://questiondoctors.com/is-my-anti-hiv-tes...\n",
              "3     hi i see no labrum tear however i see acetabul...  ...  https://questiondoctors.com/i-have-some-hip-pa...\n",
              "4     no visible tear in labrum but obviously calcif...  ...  https://questiondoctors.com/i-have-some-hip-pa...\n",
              "...                                                 ...  ...                                                ...\n",
              "5674  get it confirmed by doing venous doppler of bo...  ...  https://questiondoctors.com/question-pain-in-l...\n",
              "5675  hi dear. there are very less chances of pregna...  ...  https://questiondoctors.com/question-headaches...\n",
              "5676  i’m a radiologist. may be an mri misread. when...  ...  https://questiondoctors.com/question-46-year-o...\n",
              "5677  could be reaction to oxycodone…. ”the most fre...  ...  https://questiondoctors.com/question-46-year-o...\n",
              "5678  dont think this is another stroke. dont worry....  ...  https://questiondoctors.com/question-46-year-o...\n",
              "\n",
              "[5679 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "url = 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
        "filename = wget.download(url)\n",
        "\n",
        "embedding_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "embedding_dict_lib = KeyedVectors.load_word2vec_format(embedding_path, binary=True)"
      ],
      "metadata": {
        "id": "TgaxLwNH1fXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d89ab5-19f7-4bc0-819f-481c67cd5ccb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('./en_ameseLSTM.h5', custom_objects={'ManDist': ManDist})\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVg4ELPY6TuN",
        "outputId": "d26ee618-1694-4d34-b208-72dc3513e886"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 32)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 32, 300)      3516600     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 32, 300)      3516600     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 32, 200)     320800      ['embedding_2[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_6 (Bidirectional  (None, 32, 200)     320800      ['embedding_3[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, 32, 200)     240800      ['bidirectional_4[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, 32, 200)     240800      ['bidirectional_6[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 32, 200)      0           ['bidirectional_5[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 32, 200)      0           ['bidirectional_7[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 32, 1)       201         ['dropout_4[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, 32, 1)       201         ['dropout_6[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 32)           0           ['time_distributed_2[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 32)           0           ['time_distributed_3[0][0]']     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32)           0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32)           0           ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " repeat_vector_2 (RepeatVector)  (None, 200, 32)     0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " repeat_vector_3 (RepeatVector)  (None, 200, 32)     0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 200)      0           ['repeat_vector_2[0][0]']        \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 32, 200)      0           ['repeat_vector_3[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 32, 200)      0           ['dropout_4[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 32, 200)      0           ['dropout_6[0][0]',              \n",
            "                                                                  'permute_3[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 200)          0           ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 200)          0           ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 200)          0           ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 200)          0           ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " man_dist_1 (ManDist)           (None, 1)            0           ['dropout_5[0][0]',              \n",
            "                                                                  'dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 401)          0           ['dropout_5[0][0]',              \n",
            "                                                                  'dropout_7[0][0]',              \n",
            "                                                                  'man_dist_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 16)           6432        ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4)            68          ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 2)            10          ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            3           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,163,315\n",
            "Trainable params: 1,130,115\n",
            "Non-trainable params: 7,033,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_col = all_medical_df[\"question\"]\n",
        "final_eval_result = pd.DataFrame(columns=['InputQ','RealatedQ','RealatedQ_prediaction','RealatedQ_sucess_predication','RealatedQ_index','RealatedQ_question_text','RealatedQ_answer','RealatedQ_answer_author','RealatedQ_tags','RealatedQ_url'])\n",
        "#range(len(question_col))\n",
        "for curentSelectedQIndex in range(20):\n",
        "  # preaper test DF\n",
        "  test_df = pd.DataFrame(question_col)\n",
        "  test_df.columns = ['question1']\n",
        "  test_df['question2']=test_df['question1'][curentSelectedQIndex]\n",
        "  ##################\n",
        "\n",
        "  predictions = predirct(test_df,embedding_dict_lib)\n",
        "\n",
        "  Eval = pd.DataFrame(columns= ['question1','question2','prediction'])\n",
        "  Eval['question1']= test_df['question1']\n",
        "  Eval['question2']=test_df['question2']\n",
        "  Eval['prediction']= predictions\n",
        "  \n",
        "  ######### start predicat related Question ############\n",
        "\n",
        "  validateEvalDirExist('./Eval/')\n",
        "  evalFileName = './Eval/Eval_question_'+str(curentSelectedQIndex)+'.csv'\n",
        "  Eval.to_csv(evalFileName)\n",
        "  column = Eval[\"prediction\"]\n",
        "  predictionـcol = Eval[\"prediction\"]\n",
        "  max_index = predictionـcol.idxmax()\n",
        "  max_predited_quetion_row = Eval.iloc[[max_index]]\n",
        "  prediacted_related_question_row = all_medical_df.iloc[[max_index]]\n",
        "  print(\"Question .. \",curentSelectedQIndex,\" : \",max_predited_quetion_row.iloc[0]['question2'])\n",
        "\n",
        "  ######### save predicated Question ############\n",
        "  isSucess = 1 if prediacted_related_question_row.iloc[0]['question']== max_predited_quetion_row.iloc[0]['question2'] else 0\n",
        "  new_row = {'InputQ':max_predited_quetion_row.iloc[0]['question2'],\n",
        "             'RealatedQ':prediacted_related_question_row.iloc[0]['question'],\n",
        "             'RealatedQ_prediaction':max_predited_quetion_row.iloc[0]['prediction'],\n",
        "             'RealatedQ_sucess_predication':isSucess,\n",
        "             'RealatedQ_index':max_index,\n",
        "             'RealatedQ_question_text':prediacted_related_question_row.iloc[0]['question_text'],\n",
        "             'RealatedQ_answer':prediacted_related_question_row.iloc[0]['answer'],\n",
        "             'RealatedQ_answer_author':prediacted_related_question_row.iloc[0]['answer_author'],\n",
        "             'RealatedQ_tags':prediacted_related_question_row.iloc[0]['tags'],\n",
        "             'RealatedQ_url':prediacted_related_question_row.iloc[0]['url']\n",
        "             }\n",
        "  final_eval_result = final_eval_result.append(new_row,ignore_index=True)\n",
        "\n",
        "final_eval_result.head(10)\n",
        "\n",
        "preicatedSucessRate = (final_eval_result['RealatedQ_sucess_predication'].sum()/len(final_eval_result))*100\n",
        "print(\"preicatedSucessRate\",preicatedSucessRate)\n",
        "######### Export final result to csv ######### \n",
        "finalEvalFileName = './Eval/Final_Eval_question.csv'\n",
        "final_eval_result.to_csv(finalEvalFileName)"
      ],
      "metadata": {
        "id": "-Ccd--OJxxCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7dc6574-1008-4e92-dc71-0c1265d6f86d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  0  :  is my anti hiv test conclusive or need retest?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  1  :  is my anti hiv test conclusive or need retest?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  2  :  is my anti hiv test conclusive or need retest?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  3  :  i have some hip pain 9 weeks. had mra image recently would welcome second opinion?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  4  :  i have some hip pain 9 weeks. had mra image recently would welcome second opinion?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  5  :  i have some hip pain 9 weeks. had mra image recently would welcome second opinion?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  6  :  i have some hip pain 9 weeks. had mra image recently would welcome second opinion?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  7  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  8  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  9  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  10  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  11  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  12  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  13  :  i developed breathing difficulties approx 2 years ago which have worsened daily since?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  14  :  low resting heart rate can it be a secondary adrenal insufficiency if not what is cause?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  15  :  low resting heart rate can it be a secondary adrenal insufficiency if not what is cause?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  16  :  low resting heart rate can it be a secondary adrenal insufficiency if not what is cause?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  17  :  low resting heart rate can it be a secondary adrenal insufficiency if not what is cause?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  18  :  i was recently diagnosed with an atypical mole (dysplastic nevi) please advise?\n",
            "1000 sentences embedded.\n",
            "2000 sentences embedded.\n",
            "3000 sentences embedded.\n",
            "4000 sentences embedded.\n",
            "5000 sentences embedded.\n",
            "Question ..  19  :  after reconstructive surgery i have extreme pain when i relax bladder muscles?\n",
            "preicatedSucessRate 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functaions:"
      ],
      "metadata": {
        "id": "8osCSCIKuW2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def predirct(input_test_df,embedding_dict):\n",
        "  # Load training set\n",
        "  for q in ['question1', 'question2']:\n",
        "    input_test_df[q + '_n'] = input_test_df[q]\n",
        "\n",
        "  # Make word2vec embeddings\n",
        "  embedding_dim = 300\n",
        "  max_seq_length = 32\n",
        "  \n",
        "  test_df, embeddings = make_w2v_embeddings(embedding_dict, input_test_df, embedding_dim=embedding_dim)\n",
        "\n",
        "  # Split to dicts and append zero padding.\n",
        "  X_test = split_and_zero_padding(test_df, max_seq_length)\n",
        "\n",
        "  # Make sure everything is ok\n",
        "  assert X_test['left'].shape == X_test['right'].shape\n",
        "\n",
        "  # --\n",
        "\n",
        "  prediction = model.predict([X_test['left'], X_test['right']])\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "zZ_5Cgi6xvlB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_word_list(text):  # 文本分词\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    # Text cleaning rules for English text\n",
        "    import re\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "o_cTdRzyuxCO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_w2v_embeddings(word2vec, df, embedding_dim):  # 将词转化为词向量\n",
        "    vocabs = {}  # 词序号\n",
        "    vocabs_count = 0  # 词个数计数器\n",
        "\n",
        "    vocabs_not_w2v = {}  # 无法用词向量表示的词\n",
        "    vocabs_not_w2v_count = 0  # Word count that cannot be represented by word vectors\n",
        "\n",
        "    # 停用词\n",
        "    # stops = set(open('data/stopwords.txt').read().strip().split('\\n'))\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # 打印处理进度\n",
        "        if index != 0 and index % 1000 == 0:\n",
        "            print(str(index) + \" sentences embedded.\")\n",
        "\n",
        "        for question in ['question1', 'question2']:\n",
        "            q2n = []  # q2n -> question to numbers representation\n",
        "            words = text_to_word_list(row[question])\n",
        "\n",
        "            for word in words:\n",
        "                # if word in stops:  # remove stop words\n",
        "                # continue\n",
        "                # The word of OOV is put into a dictionary that cannot be represented by a word vector, and the value is 1\n",
        "                if word not in word2vec and word not in vocabs_not_w2v:  \n",
        "                    vocabs_not_w2v_count += 1\n",
        "                    vocabs_not_w2v[word] = 1   \n",
        "                if word not in vocabs:  # Non-OOV words, extract the corresponding id\n",
        "                    vocabs_count += 1\n",
        "                    vocabs[word] = vocabs_count\n",
        "                    q2n.append(vocabs_count)\n",
        "                else:\n",
        "                    q2n.append(vocabs[word])\n",
        "            df.at[index, question + '_n'] = q2n\n",
        "\n",
        "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)  # 随机初始化一个形状为[全部词个数，词向量维度]的矩阵\n",
        "    '''\n",
        "    词1 [a1, a2, a3, ..., a60]\n",
        "    词2 [b1, b2, b3, ..., b60]\n",
        "    词3 [c1, c2, c3, ..., c60]\n",
        "    '''\n",
        "    embeddings[0] = 0  # 第一行用0填充，因为不存在index为0的词\n",
        "\n",
        "    for index in vocabs:\n",
        "        vocab_word = vocabs[index]\n",
        "        if vocab_word in word2vec:\n",
        "            embeddings[index] = word2vec[vocab_word]\n",
        "    del word2vec\n",
        "\n",
        "    return df, embeddings"
      ],
      "metadata": {
        "id": "eFijDDv7uVoa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import itertools\n",
        "\n",
        "def split_and_zero_padding(df, max_seq_length):  # 调整tokens长度\n",
        "\n",
        "    # 训练集矩阵转换成字典\n",
        "    X = {'left': df['question1_n'], 'right': df['question2_n']}\n",
        "\n",
        "    # 调整到规定长度\n",
        "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
        "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "vXIGelMEvAAp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class ManDist(Layer):  # 封装成keras层的曼哈顿距离计算\n",
        "\n",
        "    # 初始化ManDist层，此时不需要任何参数输入\n",
        "    def __init__(self, **kwargs):\n",
        "        self.result = None\n",
        "        super(ManDist, self).__init__(**kwargs)\n",
        "\n",
        "    # Automatically build ManDist layer\n",
        "    def build(self, input_shape):\n",
        "        super(ManDist, self).build(input_shape)\n",
        "\n",
        "    # Calculate Manhattan distance\n",
        "    def call(self, x, **kwargs):\n",
        "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
        "        return self.result\n",
        "\n",
        "    # return result\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return K.int_shape(self.result)"
      ],
      "metadata": {
        "id": "BYdIJgzVyz1T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def validateEvalDirExist(dirpath):\n",
        "  dirname = os.path.dirname(dirpath)\n",
        "  if not os.path.exists(dirname):\n",
        "    os.makedirs(dirname)"
      ],
      "metadata": {
        "id": "nLBVBz9J8kjh"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}