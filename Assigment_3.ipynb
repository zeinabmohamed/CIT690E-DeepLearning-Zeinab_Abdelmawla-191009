{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assigment#3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeinabmohamed/CIT690E-DeepLearning-Zeinab_Abdelmawla-191009/blob/main/Assigment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMsy-70LOQ9e"
      },
      "source": [
        "##**• Q1) In up to 3 sentences describe tilted convolution.** \n",
        "\n",
        "Convolutional neural networks (CNNs) have been successfully applied to many\n",
        "tasks such as digit and object recognition. Using convolutional (tied) weights\n",
        "significantly reduces the number of parameters that have to be learned, and also\n",
        "allows translational invariance to be hard-coded into the architecture. In this paper, we consider the problem of learning invariances, rather than relying on hardcoding. We propose tiled convolution neural networks (Tiled CNNs), which use\n",
        "a regular “tiled” pattern of tied weights that does not require that adjacent hidden\n",
        "units share identical weights, but instead requires only that hidden units k steps\n",
        "away from each other to have tied weights. By pooling over neighboring units,\n",
        "this architecture is able to learn complex invariances (such as scale and rotational\n",
        "invariance) beyond translational invariance. Further, it also enjoys much of CNNs’\n",
        "advantage of having a relatively small number of learned parameters (such as ease\n",
        "of learning and greater scalability). We provide an efficient learning algorithm for\n",
        "Tiled CNNs based on Topographic ICA, and show that learning complex invariant\n",
        "features allows us to achieve highly competitive results for both the NORB and\n",
        "CIFAR-10 datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3YMxyK5V3H3"
      },
      "source": [
        "##- Q2) Python-Pytorch: Using MNIST dataset, compare in terms of the train and test accuracies of two different ConvNet models (kernel width 5, 32 filters) at:\n",
        "##• Stride of 1 and 2.\n",
        "##• Calculate the total number of parameters for each case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0i2-dYFOpHE"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcXjgZysO9u4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENn0YV9tPByW"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 * len(mnist_testset)), int(0.1 * len(mnist_testset))])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Training dataset size: \", len(mnist_trainset))\n",
        "print(\"Validation dataset size: \", len(mnist_valset))\n",
        "print(\"Testing dataset size: \", len(mnist_testset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwwJqNUBPCwD"
      },
      "source": [
        "class CNN1(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN1, self).__init__()\n",
        "        self.conv_1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv_2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.linear_1 = torch.nn.Linear(7 * 7 * 64, 128)\n",
        "        self.linear_2 = torch.nn.Linear(128, 10)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46XdVgdmIF6A"
      },
      "source": [
        "model1 = CNN1()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    model1.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hR1fGOnRnVl"
      },
      "source": [
        "no_epochs = 10\n",
        "train_loss = list()\n",
        "val_loss = list()\n",
        "best_val_loss = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoQx5aGTlodj"
      },
      "source": [
        "for epoch in range(no_epochs):\n",
        "    total_train_loss = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    model1.train()\n",
        "    # training\n",
        "    for itr, (image, label) in enumerate(train_dataloader):\n",
        "\n",
        "        if (torch.cuda.is_available()):\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model1(image)\n",
        "\n",
        "        loss = criterion(pred, label)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    total_train_loss = total_train_loss / (itr + 1)\n",
        "    train_loss.append(total_train_loss)\n",
        "\n",
        "    # validation\n",
        "    model1.eval()\n",
        "    total = 0\n",
        "    for itr, (image, label) in enumerate(val_dataloader):\n",
        "\n",
        "        if (torch.cuda.is_available()):\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        pred = model1(image)\n",
        "\n",
        "        loss = criterion(pred, label)\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "        for i, p in enumerate(pred):\n",
        "            if label[i] == torch.max(p.data, 0)[1]:\n",
        "                total = total + 1\n",
        "\n",
        "    accuracy = total / len(mnist_valset)\n",
        "\n",
        "    total_val_loss = total_val_loss / (itr + 1)\n",
        "    val_loss.append(total_val_loss)\n",
        "\n",
        "    print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_val_loss, accuracy))\n",
        "\n",
        "    if total_val_loss < best_val_loss:\n",
        "        best_val_loss = total_val_loss\n",
        "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
        "        torch.save(model1.state_dict(), \"model.dth\")\n",
        "\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "plt.plot(np.arange(1, no_epochs+1), train_loss, label=\"Train loss\")\n",
        "plt.plot(np.arange(1, no_epochs+1), val_loss, label=\"Validation loss\")\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.title(\"Loss Plots\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq4TOFIymDGW"
      },
      "source": [
        "1# test model1\n",
        "model1.load_state_dict(torch.load(\"model.dth\"))\n",
        "model1.eval()\n",
        "\n",
        "# store correct predictions\n",
        "correct_results = list()\n",
        "# store wrong predictions\n",
        "wrong_results = list()\n",
        "total = 0\n",
        "for itr, (image, label) in enumerate(test_dataloader):\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "    pred = model1(image)\n",
        "    pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "\n",
        "    for i, p in enumerate(pred):\n",
        "        if label[i] == torch.max(p.data, 0)[1]:\n",
        "            total = total + 1\n",
        "            correct_results.append((image, torch.max(p.data, 0)[1]))\n",
        "\n",
        "        else:\n",
        "          wrong_results.append((image, torch.max(p.data, 0)[1]))\n",
        "\n",
        "test_accuracy = total / len(mnist_testset)\n",
        "print('Test accuracy {:.8f}'.format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdN61_6VoYQ_"
      },
      "source": [
        "#Calculate the total number of parameters for model stride 1\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model1):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model1.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwYughNEmIVo"
      },
      "source": [
        "# visualize correct results\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "for i in range(1, min(11, len(correct_results))):\n",
        "\n",
        "    img = transforms.ToPILImage(mode='L')(correct_results[0][0][i])\n",
        "    fig.add_subplot(2, 5, i)\n",
        "    plt.title(correct_results[i][1].item())\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j53ZcllVnD45"
      },
      "source": [
        "# visualize wrong results\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "for i in range(1, min(11, len(wrong_results))):\n",
        "\n",
        "    img = transforms.ToPILImage(mode='L')(wrong_results[0][0][i])\n",
        "    fig.add_subplot(2, 5, i)\n",
        "    plt.title(wrong_results[i][1].item())\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4649rt_o0EL"
      },
      "source": [
        "class CNN2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.conv_1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=9)\n",
        "        self.conv_2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=9)\n",
        "        self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.linear_1 = torch.nn.Linear(7 * 7 * 64, 128)\n",
        "        self.linear_2 = torch.nn.Linear(128, 10)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        pred = self.linear_2(x)\n",
        "\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwO4XjHCo0bh"
      },
      "source": [
        "model2 = CNN2()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    model2.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9odLXwtUBXz3"
      },
      "source": [
        "no_epochs = 10\n",
        "train_loss = list()\n",
        "val_loss = list()\n",
        "best_val_loss = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okk1hPlsEP_w"
      },
      "source": [
        "for epoch in range(no_epochs):\n",
        "    total_train_loss = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    model2.train()\n",
        "    # training\n",
        "    for itr, (image, label) in enumerate(train_dataloader):\n",
        "\n",
        "        if (torch.cuda.is_available()):\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model2(image)\n",
        "\n",
        "        loss = criterion(pred, label)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    total_train_loss = total_train_loss / (itr + 1)\n",
        "    train_loss.append(total_train_loss)\n",
        "\n",
        "    # validation\n",
        "    model2.eval()\n",
        "    total = 0\n",
        "    for itr, (image, label) in enumerate(val_dataloader):\n",
        "\n",
        "        if (torch.cuda.is_available()):\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        pred = model2(image)\n",
        "\n",
        "        loss = criterion(pred, label)\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "        for i, p in enumerate(pred):\n",
        "            if label[i] == torch.max(p.data, 0)[1]:\n",
        "                total = total + 1\n",
        "\n",
        "    accuracy = total / len(mnist_valset)\n",
        "\n",
        "    total_val_loss = total_val_loss / (itr + 1)\n",
        "    val_loss.append(total_val_loss)\n",
        "\n",
        "    print('\\nEpoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(epoch + 1, no_epochs, total_train_loss, total_val_loss, accuracy))\n",
        "\n",
        "    if total_val_loss < best_val_loss:\n",
        "        best_val_loss = total_val_loss\n",
        "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
        "        torch.save(model2.state_dict(), \"model.dth\")\n",
        "\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "plt.plot(np.arange(1, no_epochs+1), train_loss, label=\"Train loss\")\n",
        "plt.plot(np.arange(1, no_epochs+1), val_loss, label=\"Validation loss\")\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.title(\"Loss Plots\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoGaz_5Jn2T"
      },
      "source": [
        "# test model\n",
        "model2.load_state_dict(torch.load(\"model.dth\"))\n",
        "model2.eval()\n",
        "\n",
        "# store correct predictions\n",
        "correct_results = list()\n",
        "# store wrong predictions\n",
        "wrong_results = list()\n",
        "total = 0\n",
        "for itr, (image, label) in enumerate(test_dataloader):\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "    pred = model2(image)\n",
        "    pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "\n",
        "    for i, p in enumerate(pred):\n",
        "        if label[i] == torch.max(p.data, 0)[1]:\n",
        "            total = total + 1\n",
        "            correct_results.append((image, torch.max(p.data, 0)[1]))\n",
        "\n",
        "        else:\n",
        "          wrong_results.append((image, torch.max(p.data, 0)[1]))\n",
        "\n",
        "test_accuracy = total / len(mnist_testset)\n",
        "print('Test accuracy {:.8f}'.format(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at-QTQPon2SN"
      },
      "source": [
        "#Calculate the total number of parameters for model stride 2\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model2):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model2.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQw5lwHkPPfB"
      },
      "source": [
        "# visualize correct results\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "for i in range(1, min(11, len(correct_results))):\n",
        "\n",
        "    img = transforms.ToPILImage(mode='L')(correct_results[0][0][i])\n",
        "    fig.add_subplot(2, 5, i)\n",
        "    plt.title(correct_results[i][1].item())\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c37zuo5rRH_W"
      },
      "source": [
        "# visualize wrong results\n",
        "fig=plt.figure(figsize=(20, 10))\n",
        "for i in range(1, min(11, len(wrong_results))):\n",
        "\n",
        "    img = transforms.ToPILImage(mode='L')(wrong_results[0][0][i])\n",
        "    fig.add_subplot(2, 5, i)\n",
        "    plt.title(wrong_results[i][1].item())\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8b_-QpyPUqn"
      },
      "source": [
        "##**• Q3) From the previous question, plot sample successful and failure cases, and try to explain the effect of changing the Stride size on the results.**\n",
        "\n",
        "\n",
        "Stride 1 has higher accurecy and it's make senace bucause stride 1 jump 1 step in Vertically and horizontally to collect more feature data. \n",
        "###- Stride 1 model \n",
        "**training time is 12m &&  Test accuracy 0.99400000**\n",
        "###- Stride 2 model \n",
        "**training time is 10m &&  Test accuracy 0.98200000**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXvC14DaTXOi"
      },
      "source": [
        "##**• Q4) [True or False] The softmax activation function is shift-invariant. Explain why you chosen your answer.**\n",
        "\n",
        "True as softmax is just for normalization (e^e^x - e)'highlight higher than bias variances' but it dosen't affect the varincies properlaities .\n",
        "\n",
        "https://datascience.stackexchange.com/a/66855"
      ]
    }
  ]
}