{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2dbdaf1b155443049e439e3995230f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_778c0202481445b194d4a0734314e421",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9338b1c4b954c6daf4627a719fb3885",
              "IPY_MODEL_0d32833ede8e4b4eb15f7b8711c9f951",
              "IPY_MODEL_d254c7c7c89a48c29697c7a471660a3e"
            ]
          }
        },
        "778c0202481445b194d4a0734314e421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9338b1c4b954c6daf4627a719fb3885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b1df709db079413aa3d60d1f750f0628",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22a3486dc85a476fb20c4782db5bcb54"
          }
        },
        "0d32833ede8e4b4eb15f7b8711c9f951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb8bc9095ad24d2b9cb9b2e45bf74a55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e66f7ee8203f4b99850747b7781a5c2c"
          }
        },
        "d254c7c7c89a48c29697c7a471660a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddfc7fbf47634748b1d250f063d9c196",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 78590969.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae3499332cb546f0b1c27c76d8576d5d"
          }
        },
        "b1df709db079413aa3d60d1f750f0628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22a3486dc85a476fb20c4782db5bcb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb8bc9095ad24d2b9cb9b2e45bf74a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e66f7ee8203f4b99850747b7781a5c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddfc7fbf47634748b1d250f063d9c196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae3499332cb546f0b1c27c76d8576d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeinabmohamed/CIT690E-DeepLearning-Zeinab_Abdelmawla-191009/blob/main/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbJRzY1l6Ixv"
      },
      "source": [
        "Q1) Write a Python Colab Notebook: Use CIFAR-10 dataset and ResNet20, ResNet-32, ResNet-44 and ResNet-56 architectures in Pytorch to compute the\n",
        "classification error and the number of parameters of each architecture as reported in\n",
        "Table 6 of the following paper:\n",
        "• He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. \"Deep residual learning for image\n",
        "recognition.\" In Proceedings of the IEEE CVPR 2016.\n",
        "• Please note you should train your models on CIFAR-10 training set from scratch using the\n",
        "instructions given in the above paper and in particular Section 4.2 and Figure 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYkVbmmY56G2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE8XE2847YwS"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h180D_ABMnLP"
      },
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 80\n",
        "batch_size = 128\n",
        "learning_rate = 0.1\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4i4okad7L75"
      },
      "source": [
        "Load the dataset CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2dbdaf1b155443049e439e3995230f6f",
            "778c0202481445b194d4a0734314e421",
            "e9338b1c4b954c6daf4627a719fb3885",
            "0d32833ede8e4b4eb15f7b8711c9f951",
            "d254c7c7c89a48c29697c7a471660a3e",
            "b1df709db079413aa3d60d1f750f0628",
            "22a3486dc85a476fb20c4782db5bcb54",
            "cb8bc9095ad24d2b9cb9b2e45bf74a55",
            "e66f7ee8203f4b99850747b7781a5c2c",
            "ddfc7fbf47634748b1d250f063d9c196",
            "ae3499332cb546f0b1c27c76d8576d5d"
          ]
        },
        "id": "CJlAGqGa7LDF",
        "outputId": "041096c2-38e1-4f37-cb1c-f0260c867bc7"
      },
      "source": [
        "cifer10_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "cifer10_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dbdaf1b155443049e439e3995230f6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FX3Ne5p8MSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39bbafd-598f-4e47-e885-8d84dbc74ec6"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(cifer10_trainset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(cifer10_testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Training dataset size: \", len(cifer10_trainset))\n",
        "print(\"Testing dataset size: \", len(cifer10_testset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size:  50000\n",
            "Testing dataset size:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QGEuLE8D7GP"
      },
      "source": [
        "###Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tS5YM70KQa8"
      },
      "source": [
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
        "                     stride=stride, padding=1, bias=False)\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTnQ_7qPRswG"
      },
      "source": [
        "def createResnetModelWithDepth(depth):\n",
        "  noOfBlocks = int((depth-2/6))\n",
        "  return ResNet(ResidualBlock, [noOfBlocks, noOfBlocks, noOfBlocks]).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxUaxMn5NAO1"
      },
      "source": [
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):    \n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ZGqesQ0w5d"
      },
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    y_true = np.array([], dtype=np.int)\n",
        "    y_pred = np.array([], dtype=np.int)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for data in data_loader:\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "          y_true = np.concatenate((y_true, labels.cpu()))\n",
        "          y_pred = np.concatenate((y_pred, predicted.cpu()))\n",
        "    \n",
        "    error = np.sum(y_pred != y_true) / len(y_true)\n",
        "    return error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC4nxMq4N_el"
      },
      "source": [
        "# Train the model\n",
        "import os\n",
        "\n",
        "def trainModel(model,depth):\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9,weight_decay=1e-4)\n",
        "\n",
        "# Run on GPU if available\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  model.to(device)\n",
        "\n",
        "  outdir ='./results'\n",
        "  if not os.path.exists(outdir):\n",
        "    os.mkdir(outdir)\n",
        "\n",
        "  cols = ['epoch', 'train_loss', 'train_err', 'test_err']\n",
        "  results_df = pd.DataFrame(columns=cols).set_index('epoch')\n",
        "  \n",
        "  total_step = len(train_dataloader)\n",
        "  curr_lr = learning_rate\n",
        "  results_file = f'results/resnet{depth}.csv'\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss  = 0.0\n",
        "    best_test_err = 1.0\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #  optimize\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        #Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # print average loss for last 50 mini-batches\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    \n",
        "    # # Decay learning rate\n",
        "    # if (epoch+1) % 20 == 0:\n",
        "    #     curr_lr /= 3\n",
        "    #     update_lr(optimizer, curr_lr)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    train_loss = loss.item()\n",
        "    train_err = evaluate(model, train_dataloader, device)\n",
        "    test_err = evaluate(model, test_dataloader, device)\n",
        "    results_df.loc[epoch] = [train_loss, train_err, test_err]\n",
        "    results_df.to_csv(results_file)\n",
        "    print(f'train_err: {train_err} test_err: {test_err}')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "  return train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naboNYuBUA89"
      },
      "source": [
        "# Test the model\n",
        "def testModel(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkHuuAtTbZhy"
      },
      "source": [
        "#Calculate the total number of parameters for model stride 2\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def calculateModelParams(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFBMwQ46ULsY"
      },
      "source": [
        "# Save the model checkpoint\n",
        "def saveModel(model,layerNo):\n",
        "  snapShotName = \"resnet%s.ckpt\" % (layerNo)\n",
        "  torch.save(model.state_dict(), snapShotName)\n",
        "  print(snapShotName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7lgHZyXWSnq"
      },
      "source": [
        "**Resnet20**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gen3oqlRWRCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ae9490-b64e-4c3a-deec-4d3b8b09bec4"
      },
      "source": [
        "resnet20Model = createResnetModelWithDepth(20)\n",
        "trainModel(resnet20Model,20)\n",
        "testModel(resnet20Model)\n",
        "saveModel(resnet20Model,20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.2969\n",
            "Epoch [1/80], Step [200/391] Loss: 2.2884\n",
            "Epoch [1/80], Step [300/391] Loss: 1.9962\n",
            "train_err: 0.72428 test_err: 0.7178\n",
            "Epoch [2/80], Step [100/391] Loss: 1.8663\n",
            "Epoch [2/80], Step [200/391] Loss: 1.8134\n",
            "Epoch [2/80], Step [300/391] Loss: 1.7746\n",
            "train_err: 0.61932 test_err: 0.6223\n",
            "Epoch [3/80], Step [100/391] Loss: 1.6387\n",
            "Epoch [3/80], Step [200/391] Loss: 1.5846\n",
            "Epoch [3/80], Step [300/391] Loss: 1.3368\n",
            "train_err: 0.48506 test_err: 0.4932\n",
            "Epoch [4/80], Step [100/391] Loss: 1.1626\n",
            "Epoch [4/80], Step [200/391] Loss: 1.2379\n",
            "Epoch [4/80], Step [300/391] Loss: 1.2098\n",
            "train_err: 0.38192 test_err: 0.3909\n",
            "Epoch [5/80], Step [100/391] Loss: 0.9183\n",
            "Epoch [5/80], Step [200/391] Loss: 0.8241\n",
            "Epoch [5/80], Step [300/391] Loss: 0.8129\n",
            "train_err: 0.37242 test_err: 0.388\n",
            "Epoch [6/80], Step [100/391] Loss: 0.7824\n",
            "Epoch [6/80], Step [200/391] Loss: 1.0576\n",
            "Epoch [6/80], Step [300/391] Loss: 0.6191\n",
            "train_err: 0.29032 test_err: 0.3105\n",
            "Epoch [7/80], Step [100/391] Loss: 0.7807\n",
            "Epoch [7/80], Step [200/391] Loss: 0.5646\n",
            "Epoch [7/80], Step [300/391] Loss: 0.7263\n",
            "train_err: 0.2111 test_err: 0.2465\n",
            "Epoch [8/80], Step [100/391] Loss: 0.3837\n",
            "Epoch [8/80], Step [200/391] Loss: 0.4975\n",
            "Epoch [8/80], Step [300/391] Loss: 0.6551\n",
            "train_err: 0.20912 test_err: 0.2485\n",
            "Epoch [9/80], Step [100/391] Loss: 0.6378\n",
            "Epoch [9/80], Step [200/391] Loss: 0.6533\n",
            "Epoch [9/80], Step [300/391] Loss: 0.4036\n",
            "train_err: 0.15822 test_err: 0.215\n",
            "Epoch [10/80], Step [100/391] Loss: 0.2515\n",
            "Epoch [10/80], Step [200/391] Loss: 0.3802\n",
            "Epoch [10/80], Step [300/391] Loss: 0.4383\n",
            "train_err: 0.1367 test_err: 0.1982\n",
            "Epoch [11/80], Step [100/391] Loss: 0.3990\n",
            "Epoch [11/80], Step [200/391] Loss: 0.3409\n",
            "Epoch [11/80], Step [300/391] Loss: 0.3607\n",
            "train_err: 0.1294 test_err: 0.1928\n",
            "Epoch [12/80], Step [100/391] Loss: 0.3615\n",
            "Epoch [12/80], Step [200/391] Loss: 0.5288\n",
            "Epoch [12/80], Step [300/391] Loss: 0.3632\n",
            "train_err: 0.14438 test_err: 0.2166\n",
            "Epoch [13/80], Step [100/391] Loss: 0.4113\n",
            "Epoch [13/80], Step [200/391] Loss: 0.3286\n",
            "Epoch [13/80], Step [300/391] Loss: 0.3884\n",
            "train_err: 0.0923 test_err: 0.1812\n",
            "Epoch [14/80], Step [100/391] Loss: 0.3424\n",
            "Epoch [14/80], Step [200/391] Loss: 0.4203\n",
            "Epoch [14/80], Step [300/391] Loss: 0.2704\n",
            "train_err: 0.14794 test_err: 0.2255\n",
            "Epoch [15/80], Step [100/391] Loss: 0.2696\n",
            "Epoch [15/80], Step [200/391] Loss: 0.3282\n",
            "Epoch [15/80], Step [300/391] Loss: 0.2675\n",
            "train_err: 0.13538 test_err: 0.2287\n",
            "Epoch [16/80], Step [100/391] Loss: 0.1208\n",
            "Epoch [16/80], Step [200/391] Loss: 0.2696\n",
            "Epoch [16/80], Step [300/391] Loss: 0.2393\n",
            "train_err: 0.0921 test_err: 0.1964\n",
            "Epoch [17/80], Step [100/391] Loss: 0.1853\n",
            "Epoch [17/80], Step [200/391] Loss: 0.3476\n",
            "Epoch [17/80], Step [300/391] Loss: 0.2128\n",
            "train_err: 0.05364 test_err: 0.1728\n",
            "Epoch [18/80], Step [100/391] Loss: 0.2047\n",
            "Epoch [18/80], Step [200/391] Loss: 0.2282\n",
            "Epoch [18/80], Step [300/391] Loss: 0.1737\n",
            "train_err: 0.08954 test_err: 0.2013\n",
            "Epoch [19/80], Step [100/391] Loss: 0.0946\n",
            "Epoch [19/80], Step [200/391] Loss: 0.1750\n",
            "Epoch [19/80], Step [300/391] Loss: 0.3107\n",
            "train_err: 0.04726 test_err: 0.1709\n",
            "Epoch [20/80], Step [100/391] Loss: 0.1160\n",
            "Epoch [20/80], Step [200/391] Loss: 0.1440\n",
            "Epoch [20/80], Step [300/391] Loss: 0.2080\n",
            "train_err: 0.05732 test_err: 0.1809\n",
            "Epoch [21/80], Step [100/391] Loss: 0.0821\n",
            "Epoch [21/80], Step [200/391] Loss: 0.1123\n",
            "Epoch [21/80], Step [300/391] Loss: 0.2559\n",
            "train_err: 0.06658 test_err: 0.1974\n",
            "Epoch [22/80], Step [100/391] Loss: 0.1766\n",
            "Epoch [22/80], Step [200/391] Loss: 0.0904\n",
            "Epoch [22/80], Step [300/391] Loss: 0.1529\n",
            "train_err: 0.0414 test_err: 0.1771\n",
            "Epoch [23/80], Step [100/391] Loss: 0.1064\n",
            "Epoch [23/80], Step [200/391] Loss: 0.2376\n",
            "Epoch [23/80], Step [300/391] Loss: 0.0913\n",
            "train_err: 0.0707 test_err: 0.1929\n",
            "Epoch [24/80], Step [100/391] Loss: 0.1027\n",
            "Epoch [24/80], Step [200/391] Loss: 0.1995\n",
            "Epoch [24/80], Step [300/391] Loss: 0.1399\n",
            "train_err: 0.10348 test_err: 0.2216\n",
            "Epoch [25/80], Step [100/391] Loss: 0.1288\n",
            "Epoch [25/80], Step [200/391] Loss: 0.1928\n",
            "Epoch [25/80], Step [300/391] Loss: 0.1125\n",
            "train_err: 0.04166 test_err: 0.1776\n",
            "Epoch [26/80], Step [100/391] Loss: 0.0932\n",
            "Epoch [26/80], Step [200/391] Loss: 0.1080\n",
            "Epoch [26/80], Step [300/391] Loss: 0.0733\n",
            "train_err: 0.07888 test_err: 0.2066\n",
            "Epoch [27/80], Step [100/391] Loss: 0.0381\n",
            "Epoch [27/80], Step [200/391] Loss: 0.0781\n",
            "Epoch [27/80], Step [300/391] Loss: 0.1366\n",
            "train_err: 0.0477 test_err: 0.1805\n",
            "Epoch [28/80], Step [100/391] Loss: 0.1469\n",
            "Epoch [28/80], Step [200/391] Loss: 0.1143\n",
            "Epoch [28/80], Step [300/391] Loss: 0.1692\n",
            "train_err: 0.05422 test_err: 0.1869\n",
            "Epoch [29/80], Step [100/391] Loss: 0.0972\n",
            "Epoch [29/80], Step [200/391] Loss: 0.0603\n",
            "Epoch [29/80], Step [300/391] Loss: 0.0490\n",
            "train_err: 0.04966 test_err: 0.1944\n",
            "Epoch [30/80], Step [100/391] Loss: 0.0586\n",
            "Epoch [30/80], Step [200/391] Loss: 0.1050\n",
            "Epoch [30/80], Step [300/391] Loss: 0.0794\n",
            "train_err: 0.04644 test_err: 0.191\n",
            "Epoch [31/80], Step [100/391] Loss: 0.0599\n",
            "Epoch [31/80], Step [200/391] Loss: 0.1675\n",
            "Epoch [31/80], Step [300/391] Loss: 0.1324\n",
            "train_err: 0.07414 test_err: 0.2174\n",
            "Epoch [32/80], Step [100/391] Loss: 0.0851\n",
            "Epoch [32/80], Step [200/391] Loss: 0.0556\n",
            "Epoch [32/80], Step [300/391] Loss: 0.1128\n",
            "train_err: 0.05104 test_err: 0.1933\n",
            "Epoch [33/80], Step [100/391] Loss: 0.0377\n",
            "Epoch [33/80], Step [200/391] Loss: 0.0566\n",
            "Epoch [33/80], Step [300/391] Loss: 0.0369\n",
            "train_err: 0.06298 test_err: 0.202\n",
            "Epoch [34/80], Step [100/391] Loss: 0.0903\n",
            "Epoch [34/80], Step [200/391] Loss: 0.0946\n",
            "Epoch [34/80], Step [300/391] Loss: 0.0477\n",
            "train_err: 0.06646 test_err: 0.2045\n",
            "Epoch [35/80], Step [100/391] Loss: 0.0861\n",
            "Epoch [35/80], Step [200/391] Loss: 0.0680\n",
            "Epoch [35/80], Step [300/391] Loss: 0.0861\n",
            "train_err: 0.03624 test_err: 0.1754\n",
            "Epoch [36/80], Step [100/391] Loss: 0.0852\n",
            "Epoch [36/80], Step [200/391] Loss: 0.0908\n",
            "Epoch [36/80], Step [300/391] Loss: 0.0695\n",
            "train_err: 0.0693 test_err: 0.2173\n",
            "Epoch [37/80], Step [100/391] Loss: 0.1150\n",
            "Epoch [37/80], Step [200/391] Loss: 0.0477\n",
            "Epoch [37/80], Step [300/391] Loss: 0.0842\n",
            "train_err: 0.08444 test_err: 0.2107\n",
            "Epoch [38/80], Step [100/391] Loss: 0.0644\n",
            "Epoch [38/80], Step [200/391] Loss: 0.0304\n",
            "Epoch [38/80], Step [300/391] Loss: 0.0940\n",
            "train_err: 0.04418 test_err: 0.185\n",
            "Epoch [39/80], Step [100/391] Loss: 0.1139\n",
            "Epoch [39/80], Step [200/391] Loss: 0.0862\n",
            "Epoch [39/80], Step [300/391] Loss: 0.0762\n",
            "train_err: 0.03046 test_err: 0.1799\n",
            "Epoch [40/80], Step [100/391] Loss: 0.1174\n",
            "Epoch [40/80], Step [200/391] Loss: 0.0634\n",
            "Epoch [40/80], Step [300/391] Loss: 0.0789\n",
            "train_err: 0.0497 test_err: 0.1967\n",
            "Epoch [41/80], Step [100/391] Loss: 0.1093\n",
            "Epoch [41/80], Step [200/391] Loss: 0.0915\n",
            "Epoch [41/80], Step [300/391] Loss: 0.0494\n",
            "train_err: 0.07608 test_err: 0.2192\n",
            "Epoch [42/80], Step [100/391] Loss: 0.0583\n",
            "Epoch [42/80], Step [200/391] Loss: 0.0549\n",
            "Epoch [42/80], Step [300/391] Loss: 0.1016\n",
            "train_err: 0.07988 test_err: 0.2181\n",
            "Epoch [43/80], Step [100/391] Loss: 0.0440\n",
            "Epoch [43/80], Step [200/391] Loss: 0.0883\n",
            "Epoch [43/80], Step [300/391] Loss: 0.0746\n",
            "train_err: 0.05096 test_err: 0.1883\n",
            "Epoch [44/80], Step [100/391] Loss: 0.0493\n",
            "Epoch [44/80], Step [200/391] Loss: 0.0402\n",
            "Epoch [44/80], Step [300/391] Loss: 0.0766\n",
            "train_err: 0.07266 test_err: 0.2146\n",
            "Epoch [45/80], Step [100/391] Loss: 0.0422\n",
            "Epoch [45/80], Step [200/391] Loss: 0.1351\n",
            "Epoch [45/80], Step [300/391] Loss: 0.0623\n",
            "train_err: 0.03474 test_err: 0.1797\n",
            "Epoch [46/80], Step [100/391] Loss: 0.0732\n",
            "Epoch [46/80], Step [200/391] Loss: 0.1316\n",
            "Epoch [46/80], Step [300/391] Loss: 0.0491\n",
            "train_err: 0.036 test_err: 0.1698\n",
            "Epoch [47/80], Step [100/391] Loss: 0.0749\n",
            "Epoch [47/80], Step [200/391] Loss: 0.0498\n",
            "Epoch [47/80], Step [300/391] Loss: 0.0394\n",
            "train_err: 0.03212 test_err: 0.1855\n",
            "Epoch [48/80], Step [100/391] Loss: 0.0525\n",
            "Epoch [48/80], Step [200/391] Loss: 0.0550\n",
            "Epoch [48/80], Step [300/391] Loss: 0.0839\n",
            "train_err: 0.05576 test_err: 0.2007\n",
            "Epoch [49/80], Step [100/391] Loss: 0.0371\n",
            "Epoch [49/80], Step [200/391] Loss: 0.0479\n",
            "Epoch [49/80], Step [300/391] Loss: 0.1444\n",
            "train_err: 0.04992 test_err: 0.1981\n",
            "Epoch [50/80], Step [100/391] Loss: 0.0499\n",
            "Epoch [50/80], Step [200/391] Loss: 0.1624\n",
            "Epoch [50/80], Step [300/391] Loss: 0.1115\n",
            "train_err: 0.0499 test_err: 0.1912\n",
            "Epoch [51/80], Step [100/391] Loss: 0.0277\n",
            "Epoch [51/80], Step [200/391] Loss: 0.0620\n",
            "Epoch [51/80], Step [300/391] Loss: 0.1189\n",
            "train_err: 0.0642 test_err: 0.2101\n",
            "Epoch [52/80], Step [100/391] Loss: 0.0397\n",
            "Epoch [52/80], Step [200/391] Loss: 0.1099\n",
            "Epoch [52/80], Step [300/391] Loss: 0.1026\n",
            "train_err: 0.03528 test_err: 0.1821\n",
            "Epoch [53/80], Step [100/391] Loss: 0.0569\n",
            "Epoch [53/80], Step [200/391] Loss: 0.0906\n",
            "Epoch [53/80], Step [300/391] Loss: 0.0379\n",
            "train_err: 0.0488 test_err: 0.1925\n",
            "Epoch [54/80], Step [100/391] Loss: 0.1149\n",
            "Epoch [54/80], Step [200/391] Loss: 0.0902\n",
            "Epoch [54/80], Step [300/391] Loss: 0.0330\n",
            "train_err: 0.04278 test_err: 0.1884\n",
            "Epoch [55/80], Step [100/391] Loss: 0.0865\n",
            "Epoch [55/80], Step [200/391] Loss: 0.0398\n",
            "Epoch [55/80], Step [300/391] Loss: 0.0313\n",
            "train_err: 0.05148 test_err: 0.1955\n",
            "Epoch [56/80], Step [100/391] Loss: 0.0469\n",
            "Epoch [56/80], Step [200/391] Loss: 0.1309\n",
            "Epoch [56/80], Step [300/391] Loss: 0.0415\n",
            "train_err: 0.03482 test_err: 0.178\n",
            "Epoch [57/80], Step [100/391] Loss: 0.0210\n",
            "Epoch [57/80], Step [200/391] Loss: 0.0477\n",
            "Epoch [57/80], Step [300/391] Loss: 0.1058\n",
            "train_err: 0.06422 test_err: 0.202\n",
            "Epoch [58/80], Step [100/391] Loss: 0.0677\n",
            "Epoch [58/80], Step [200/391] Loss: 0.0295\n",
            "Epoch [58/80], Step [300/391] Loss: 0.0583\n",
            "train_err: 0.04746 test_err: 0.1925\n",
            "Epoch [59/80], Step [100/391] Loss: 0.0154\n",
            "Epoch [59/80], Step [200/391] Loss: 0.0660\n",
            "Epoch [59/80], Step [300/391] Loss: 0.0356\n",
            "train_err: 0.02212 test_err: 0.1707\n",
            "Epoch [60/80], Step [100/391] Loss: 0.0515\n",
            "Epoch [60/80], Step [200/391] Loss: 0.0627\n",
            "Epoch [60/80], Step [300/391] Loss: 0.1226\n",
            "train_err: 0.0475 test_err: 0.1959\n",
            "Epoch [61/80], Step [100/391] Loss: 0.0422\n",
            "Epoch [61/80], Step [200/391] Loss: 0.0903\n",
            "Epoch [61/80], Step [300/391] Loss: 0.0398\n",
            "train_err: 0.05816 test_err: 0.2048\n",
            "Epoch [62/80], Step [100/391] Loss: 0.0518\n",
            "Epoch [62/80], Step [200/391] Loss: 0.0175\n",
            "Epoch [62/80], Step [300/391] Loss: 0.0340\n",
            "train_err: 0.03328 test_err: 0.1757\n",
            "Epoch [63/80], Step [100/391] Loss: 0.0257\n",
            "Epoch [63/80], Step [200/391] Loss: 0.0374\n",
            "Epoch [63/80], Step [300/391] Loss: 0.0560\n",
            "train_err: 0.04948 test_err: 0.1925\n",
            "Epoch [64/80], Step [100/391] Loss: 0.0629\n",
            "Epoch [64/80], Step [200/391] Loss: 0.0847\n",
            "Epoch [64/80], Step [300/391] Loss: 0.0639\n",
            "train_err: 0.01818 test_err: 0.1643\n",
            "Epoch [65/80], Step [100/391] Loss: 0.0920\n",
            "Epoch [65/80], Step [200/391] Loss: 0.0822\n",
            "Epoch [65/80], Step [300/391] Loss: 0.0678\n",
            "train_err: 0.06652 test_err: 0.2076\n",
            "Epoch [66/80], Step [100/391] Loss: 0.0229\n",
            "Epoch [66/80], Step [200/391] Loss: 0.0300\n",
            "Epoch [66/80], Step [300/391] Loss: 0.1174\n",
            "train_err: 0.0973 test_err: 0.2313\n",
            "Epoch [67/80], Step [100/391] Loss: 0.0206\n",
            "Epoch [67/80], Step [200/391] Loss: 0.1222\n",
            "Epoch [67/80], Step [300/391] Loss: 0.0190\n",
            "train_err: 0.03654 test_err: 0.183\n",
            "Epoch [68/80], Step [100/391] Loss: 0.0269\n",
            "Epoch [68/80], Step [200/391] Loss: 0.0571\n",
            "Epoch [68/80], Step [300/391] Loss: 0.0505\n",
            "train_err: 0.04998 test_err: 0.1985\n",
            "Epoch [69/80], Step [100/391] Loss: 0.0807\n",
            "Epoch [69/80], Step [200/391] Loss: 0.0471\n",
            "Epoch [69/80], Step [300/391] Loss: 0.0463\n",
            "train_err: 0.02958 test_err: 0.1713\n",
            "Epoch [70/80], Step [100/391] Loss: 0.0441\n",
            "Epoch [70/80], Step [200/391] Loss: 0.0193\n",
            "Epoch [70/80], Step [300/391] Loss: 0.0796\n",
            "train_err: 0.03622 test_err: 0.1753\n",
            "Epoch [71/80], Step [100/391] Loss: 0.0449\n",
            "Epoch [71/80], Step [200/391] Loss: 0.0243\n",
            "Epoch [71/80], Step [300/391] Loss: 0.0802\n",
            "train_err: 0.03102 test_err: 0.183\n",
            "Epoch [72/80], Step [100/391] Loss: 0.0436\n",
            "Epoch [72/80], Step [200/391] Loss: 0.0223\n",
            "Epoch [72/80], Step [300/391] Loss: 0.0969\n",
            "train_err: 0.04574 test_err: 0.1884\n",
            "Epoch [73/80], Step [100/391] Loss: 0.0148\n",
            "Epoch [73/80], Step [200/391] Loss: 0.0309\n",
            "Epoch [73/80], Step [300/391] Loss: 0.0926\n",
            "train_err: 0.04756 test_err: 0.191\n",
            "Epoch [74/80], Step [100/391] Loss: 0.0482\n",
            "Epoch [74/80], Step [200/391] Loss: 0.0123\n",
            "Epoch [74/80], Step [300/391] Loss: 0.0349\n",
            "train_err: 0.03776 test_err: 0.1805\n",
            "Epoch [75/80], Step [100/391] Loss: 0.0644\n",
            "Epoch [75/80], Step [200/391] Loss: 0.0367\n",
            "Epoch [75/80], Step [300/391] Loss: 0.0718\n",
            "train_err: 0.06772 test_err: 0.2074\n",
            "Epoch [76/80], Step [100/391] Loss: 0.0865\n",
            "Epoch [76/80], Step [200/391] Loss: 0.0399\n",
            "Epoch [76/80], Step [300/391] Loss: 0.0581\n",
            "train_err: 0.03186 test_err: 0.1795\n",
            "Epoch [77/80], Step [100/391] Loss: 0.0278\n",
            "Epoch [77/80], Step [200/391] Loss: 0.0159\n",
            "Epoch [77/80], Step [300/391] Loss: 0.0357\n",
            "train_err: 0.05246 test_err: 0.2005\n",
            "Epoch [78/80], Step [100/391] Loss: 0.0360\n",
            "Epoch [78/80], Step [200/391] Loss: 0.1429\n",
            "Epoch [78/80], Step [300/391] Loss: 0.0921\n",
            "train_err: 0.03606 test_err: 0.1793\n",
            "Epoch [79/80], Step [100/391] Loss: 0.0595\n",
            "Epoch [79/80], Step [200/391] Loss: 0.1031\n",
            "Epoch [79/80], Step [300/391] Loss: 0.0238\n",
            "train_err: 0.03966 test_err: 0.1872\n",
            "Epoch [80/80], Step [100/391] Loss: 0.0446\n",
            "Epoch [80/80], Step [200/391] Loss: 0.0573\n",
            "Epoch [80/80], Step [300/391] Loss: 0.0363\n",
            "train_err: 0.03068 test_err: 0.1739\n",
            "Accuracy of the model on the test images: 82.61 %\n",
            "resnet20.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsM4rrTYLdw"
      },
      "source": [
        "**Resnet32**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifgBfAzVZ81P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a5d89c-3cfe-4ebe-a021-d87ca32debb9"
      },
      "source": [
        "resnet32Model = createResnetModelWithDepth(32)\n",
        "trainModel(resnet32Model,32)\n",
        "testModel(resnet32Model)\n",
        "saveModel(resnet32Model,32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.2961\n",
            "Epoch [1/80], Step [200/391] Loss: 2.2891\n",
            "Epoch [1/80], Step [300/391] Loss: 2.3069\n",
            "train_err: 0.88508 test_err: 0.885\n",
            "Epoch [2/80], Step [100/391] Loss: 2.3254\n",
            "Epoch [2/80], Step [200/391] Loss: 2.2633\n",
            "Epoch [2/80], Step [300/391] Loss: 2.2886\n",
            "train_err: 0.85666 test_err: 0.8587\n",
            "Epoch [3/80], Step [100/391] Loss: 2.1978\n",
            "Epoch [3/80], Step [200/391] Loss: 2.0728\n",
            "Epoch [3/80], Step [300/391] Loss: 2.0154\n",
            "train_err: 0.7054 test_err: 0.6979\n",
            "Epoch [4/80], Step [100/391] Loss: 1.6755\n",
            "Epoch [4/80], Step [200/391] Loss: 1.6022\n",
            "Epoch [4/80], Step [300/391] Loss: 1.6328\n",
            "train_err: 0.65028 test_err: 0.6583\n",
            "Epoch [5/80], Step [100/391] Loss: 1.4646\n",
            "Epoch [5/80], Step [200/391] Loss: 1.5313\n",
            "Epoch [5/80], Step [300/391] Loss: 1.4068\n",
            "train_err: 0.56016 test_err: 0.5619\n",
            "Epoch [6/80], Step [100/391] Loss: 1.4321\n",
            "Epoch [6/80], Step [200/391] Loss: 1.4216\n",
            "Epoch [6/80], Step [300/391] Loss: 1.1875\n",
            "train_err: 0.48928 test_err: 0.4972\n",
            "Epoch [7/80], Step [100/391] Loss: 1.2397\n",
            "Epoch [7/80], Step [200/391] Loss: 1.0994\n",
            "Epoch [7/80], Step [300/391] Loss: 1.2011\n",
            "train_err: 0.45584 test_err: 0.4759\n",
            "Epoch [8/80], Step [100/391] Loss: 1.1110\n",
            "Epoch [8/80], Step [200/391] Loss: 1.1352\n",
            "Epoch [8/80], Step [300/391] Loss: 1.1650\n",
            "train_err: 0.42988 test_err: 0.4486\n",
            "Epoch [9/80], Step [100/391] Loss: 0.9306\n",
            "Epoch [9/80], Step [200/391] Loss: 1.0505\n",
            "Epoch [9/80], Step [300/391] Loss: 0.8756\n",
            "train_err: 0.3881 test_err: 0.4055\n",
            "Epoch [10/80], Step [100/391] Loss: 0.8861\n",
            "Epoch [10/80], Step [200/391] Loss: 1.0226\n",
            "Epoch [10/80], Step [300/391] Loss: 0.9034\n",
            "train_err: 0.35192 test_err: 0.3692\n",
            "Epoch [11/80], Step [100/391] Loss: 0.8257\n",
            "Epoch [11/80], Step [200/391] Loss: 0.7834\n",
            "Epoch [11/80], Step [300/391] Loss: 0.5866\n",
            "train_err: 0.30918 test_err: 0.3434\n",
            "Epoch [12/80], Step [100/391] Loss: 0.6613\n",
            "Epoch [12/80], Step [200/391] Loss: 0.6698\n",
            "Epoch [12/80], Step [300/391] Loss: 0.6889\n",
            "train_err: 0.25296 test_err: 0.2878\n",
            "Epoch [13/80], Step [100/391] Loss: 0.7669\n",
            "Epoch [13/80], Step [200/391] Loss: 0.7030\n",
            "Epoch [13/80], Step [300/391] Loss: 0.7074\n",
            "train_err: 0.30692 test_err: 0.3384\n",
            "Epoch [14/80], Step [100/391] Loss: 0.4487\n",
            "Epoch [14/80], Step [200/391] Loss: 0.6351\n",
            "Epoch [14/80], Step [300/391] Loss: 0.6409\n",
            "train_err: 0.26308 test_err: 0.3086\n",
            "Epoch [15/80], Step [100/391] Loss: 0.5439\n",
            "Epoch [15/80], Step [200/391] Loss: 0.4850\n",
            "Epoch [15/80], Step [300/391] Loss: 0.6742\n",
            "train_err: 0.2059 test_err: 0.2644\n",
            "Epoch [16/80], Step [100/391] Loss: 0.4944\n",
            "Epoch [16/80], Step [200/391] Loss: 0.5183\n",
            "Epoch [16/80], Step [300/391] Loss: 0.4270\n",
            "train_err: 0.21758 test_err: 0.2724\n",
            "Epoch [17/80], Step [100/391] Loss: 0.4575\n",
            "Epoch [17/80], Step [200/391] Loss: 0.3961\n",
            "Epoch [17/80], Step [300/391] Loss: 0.3686\n",
            "train_err: 0.25524 test_err: 0.3079\n",
            "Epoch [18/80], Step [100/391] Loss: 0.3815\n",
            "Epoch [18/80], Step [200/391] Loss: 0.5499\n",
            "Epoch [18/80], Step [300/391] Loss: 0.3718\n",
            "train_err: 0.1793 test_err: 0.248\n",
            "Epoch [19/80], Step [100/391] Loss: 0.4829\n",
            "Epoch [19/80], Step [200/391] Loss: 0.3502\n",
            "Epoch [19/80], Step [300/391] Loss: 0.3294\n",
            "train_err: 0.26154 test_err: 0.3172\n",
            "Epoch [20/80], Step [100/391] Loss: 0.3470\n",
            "Epoch [20/80], Step [200/391] Loss: 0.4717\n",
            "Epoch [20/80], Step [300/391] Loss: 0.3837\n",
            "train_err: 0.22644 test_err: 0.2883\n",
            "Epoch [21/80], Step [100/391] Loss: 0.3738\n",
            "Epoch [21/80], Step [200/391] Loss: 0.4708\n",
            "Epoch [21/80], Step [300/391] Loss: 0.4026\n",
            "train_err: 0.20292 test_err: 0.2814\n",
            "Epoch [22/80], Step [100/391] Loss: 0.3005\n",
            "Epoch [22/80], Step [200/391] Loss: 0.2323\n",
            "Epoch [22/80], Step [300/391] Loss: 0.3709\n",
            "train_err: 0.19974 test_err: 0.2705\n",
            "Epoch [23/80], Step [100/391] Loss: 0.2988\n",
            "Epoch [23/80], Step [200/391] Loss: 0.2868\n",
            "Epoch [23/80], Step [300/391] Loss: 0.4460\n",
            "train_err: 0.16662 test_err: 0.2549\n",
            "Epoch [24/80], Step [100/391] Loss: 0.2449\n",
            "Epoch [24/80], Step [200/391] Loss: 0.2814\n",
            "Epoch [24/80], Step [300/391] Loss: 0.2811\n",
            "train_err: 0.12924 test_err: 0.2257\n",
            "Epoch [25/80], Step [100/391] Loss: 0.3098\n",
            "Epoch [25/80], Step [200/391] Loss: 0.2045\n",
            "Epoch [25/80], Step [300/391] Loss: 0.2183\n",
            "train_err: 0.09294 test_err: 0.2026\n",
            "Epoch [26/80], Step [100/391] Loss: 0.2232\n",
            "Epoch [26/80], Step [200/391] Loss: 0.2914\n",
            "Epoch [26/80], Step [300/391] Loss: 0.2815\n",
            "train_err: 0.10602 test_err: 0.2145\n",
            "Epoch [27/80], Step [100/391] Loss: 0.2409\n",
            "Epoch [27/80], Step [200/391] Loss: 0.2860\n",
            "Epoch [27/80], Step [300/391] Loss: 0.2187\n",
            "train_err: 0.17498 test_err: 0.2624\n",
            "Epoch [28/80], Step [100/391] Loss: 0.2324\n",
            "Epoch [28/80], Step [200/391] Loss: 0.1134\n",
            "Epoch [28/80], Step [300/391] Loss: 0.1748\n",
            "train_err: 0.23672 test_err: 0.3191\n",
            "Epoch [29/80], Step [100/391] Loss: 0.1804\n",
            "Epoch [29/80], Step [200/391] Loss: 0.3906\n",
            "Epoch [29/80], Step [300/391] Loss: 0.1762\n",
            "train_err: 0.20142 test_err: 0.2821\n",
            "Epoch [30/80], Step [100/391] Loss: 0.1651\n",
            "Epoch [30/80], Step [200/391] Loss: 0.2654\n",
            "Epoch [30/80], Step [300/391] Loss: 0.2896\n",
            "train_err: 0.1167 test_err: 0.2265\n",
            "Epoch [31/80], Step [100/391] Loss: 0.1777\n",
            "Epoch [31/80], Step [200/391] Loss: 0.1489\n",
            "Epoch [31/80], Step [300/391] Loss: 0.3506\n",
            "train_err: 0.22786 test_err: 0.3011\n",
            "Epoch [32/80], Step [100/391] Loss: 0.2180\n",
            "Epoch [32/80], Step [200/391] Loss: 0.1814\n",
            "Epoch [32/80], Step [300/391] Loss: 0.3839\n",
            "train_err: 0.14632 test_err: 0.264\n",
            "Epoch [33/80], Step [100/391] Loss: 0.2708\n",
            "Epoch [33/80], Step [200/391] Loss: 0.1820\n",
            "Epoch [33/80], Step [300/391] Loss: 0.2431\n",
            "train_err: 0.16872 test_err: 0.2695\n",
            "Epoch [34/80], Step [100/391] Loss: 0.1830\n",
            "Epoch [34/80], Step [200/391] Loss: 0.2126\n",
            "Epoch [34/80], Step [300/391] Loss: 0.2802\n",
            "train_err: 0.1112 test_err: 0.2332\n",
            "Epoch [35/80], Step [100/391] Loss: 0.1881\n",
            "Epoch [35/80], Step [200/391] Loss: 0.1648\n",
            "Epoch [35/80], Step [300/391] Loss: 0.3103\n",
            "train_err: 0.1518 test_err: 0.2683\n",
            "Epoch [36/80], Step [100/391] Loss: 0.1181\n",
            "Epoch [36/80], Step [200/391] Loss: 0.1478\n",
            "Epoch [36/80], Step [300/391] Loss: 0.1819\n",
            "train_err: 0.10646 test_err: 0.2322\n",
            "Epoch [37/80], Step [100/391] Loss: 0.2607\n",
            "Epoch [37/80], Step [200/391] Loss: 0.3378\n",
            "Epoch [37/80], Step [300/391] Loss: 0.2109\n",
            "train_err: 0.07822 test_err: 0.2097\n",
            "Epoch [38/80], Step [100/391] Loss: 0.1750\n",
            "Epoch [38/80], Step [200/391] Loss: 0.1879\n",
            "Epoch [38/80], Step [300/391] Loss: 0.1421\n",
            "train_err: 0.09126 test_err: 0.2144\n",
            "Epoch [39/80], Step [100/391] Loss: 0.0978\n",
            "Epoch [39/80], Step [200/391] Loss: 0.1198\n",
            "Epoch [39/80], Step [300/391] Loss: 0.2657\n",
            "train_err: 0.22154 test_err: 0.3223\n",
            "Epoch [40/80], Step [100/391] Loss: 0.2005\n",
            "Epoch [40/80], Step [200/391] Loss: 0.1375\n",
            "Epoch [40/80], Step [300/391] Loss: 0.1604\n",
            "train_err: 0.21292 test_err: 0.3135\n",
            "Epoch [41/80], Step [100/391] Loss: 0.0669\n",
            "Epoch [41/80], Step [200/391] Loss: 0.1973\n",
            "Epoch [41/80], Step [300/391] Loss: 0.2692\n",
            "train_err: 0.12718 test_err: 0.2547\n",
            "Epoch [42/80], Step [100/391] Loss: 0.1192\n",
            "Epoch [42/80], Step [200/391] Loss: 0.1685\n",
            "Epoch [42/80], Step [300/391] Loss: 0.1803\n",
            "train_err: 0.11874 test_err: 0.2481\n",
            "Epoch [43/80], Step [100/391] Loss: 0.1109\n",
            "Epoch [43/80], Step [200/391] Loss: 0.1998\n",
            "Epoch [43/80], Step [300/391] Loss: 0.2011\n",
            "train_err: 0.07474 test_err: 0.2142\n",
            "Epoch [44/80], Step [100/391] Loss: 0.1416\n",
            "Epoch [44/80], Step [200/391] Loss: 0.1235\n",
            "Epoch [44/80], Step [300/391] Loss: 0.1336\n",
            "train_err: 0.1453 test_err: 0.263\n",
            "Epoch [45/80], Step [100/391] Loss: 0.0504\n",
            "Epoch [45/80], Step [200/391] Loss: 0.1650\n",
            "Epoch [45/80], Step [300/391] Loss: 0.3986\n",
            "train_err: 0.07566 test_err: 0.2045\n",
            "Epoch [46/80], Step [100/391] Loss: 0.1312\n",
            "Epoch [46/80], Step [200/391] Loss: 0.1140\n",
            "Epoch [46/80], Step [300/391] Loss: 0.2120\n",
            "train_err: 0.10216 test_err: 0.2325\n",
            "Epoch [47/80], Step [100/391] Loss: 0.1036\n",
            "Epoch [47/80], Step [200/391] Loss: 0.1522\n",
            "Epoch [47/80], Step [300/391] Loss: 0.1521\n",
            "train_err: 0.10664 test_err: 0.2397\n",
            "Epoch [48/80], Step [100/391] Loss: 0.0715\n",
            "Epoch [48/80], Step [200/391] Loss: 0.1059\n",
            "Epoch [48/80], Step [300/391] Loss: 0.1948\n",
            "train_err: 0.13774 test_err: 0.2596\n",
            "Epoch [49/80], Step [100/391] Loss: 0.1650\n",
            "Epoch [49/80], Step [200/391] Loss: 0.1212\n",
            "Epoch [49/80], Step [300/391] Loss: 0.1530\n",
            "train_err: 0.06202 test_err: 0.2034\n",
            "Epoch [50/80], Step [100/391] Loss: 0.1381\n",
            "Epoch [50/80], Step [200/391] Loss: 0.1647\n",
            "Epoch [50/80], Step [300/391] Loss: 0.1674\n",
            "train_err: 0.13848 test_err: 0.2555\n",
            "Epoch [51/80], Step [100/391] Loss: 0.1963\n",
            "Epoch [51/80], Step [200/391] Loss: 0.3500\n",
            "Epoch [51/80], Step [300/391] Loss: 0.1667\n",
            "train_err: 0.08422 test_err: 0.2112\n",
            "Epoch [52/80], Step [100/391] Loss: 0.1328\n",
            "Epoch [52/80], Step [200/391] Loss: 0.0748\n",
            "Epoch [52/80], Step [300/391] Loss: 0.2111\n",
            "train_err: 0.10118 test_err: 0.2306\n",
            "Epoch [53/80], Step [100/391] Loss: 0.0810\n",
            "Epoch [53/80], Step [200/391] Loss: 0.1126\n",
            "Epoch [53/80], Step [300/391] Loss: 0.1754\n",
            "train_err: 0.07164 test_err: 0.2134\n",
            "Epoch [54/80], Step [100/391] Loss: 0.0741\n",
            "Epoch [54/80], Step [200/391] Loss: 0.1021\n",
            "Epoch [54/80], Step [300/391] Loss: 0.1105\n",
            "train_err: 0.1017 test_err: 0.2465\n",
            "Epoch [55/80], Step [100/391] Loss: 0.0674\n",
            "Epoch [55/80], Step [200/391] Loss: 0.1275\n",
            "Epoch [55/80], Step [300/391] Loss: 0.1942\n",
            "train_err: 0.14236 test_err: 0.2707\n",
            "Epoch [56/80], Step [100/391] Loss: 0.0780\n",
            "Epoch [56/80], Step [200/391] Loss: 0.0869\n",
            "Epoch [56/80], Step [300/391] Loss: 0.1551\n",
            "train_err: 0.12086 test_err: 0.2413\n",
            "Epoch [57/80], Step [100/391] Loss: 0.1159\n",
            "Epoch [57/80], Step [200/391] Loss: 0.1014\n",
            "Epoch [57/80], Step [300/391] Loss: 0.1446\n",
            "train_err: 0.10136 test_err: 0.2445\n",
            "Epoch [58/80], Step [100/391] Loss: 0.0874\n",
            "Epoch [58/80], Step [200/391] Loss: 0.0859\n",
            "Epoch [58/80], Step [300/391] Loss: 0.1690\n",
            "train_err: 0.05784 test_err: 0.2012\n",
            "Epoch [59/80], Step [100/391] Loss: 0.0785\n",
            "Epoch [59/80], Step [200/391] Loss: 0.1261\n",
            "Epoch [59/80], Step [300/391] Loss: 0.1102\n",
            "train_err: 0.10526 test_err: 0.2445\n",
            "Epoch [60/80], Step [100/391] Loss: 0.0535\n",
            "Epoch [60/80], Step [200/391] Loss: 0.1966\n",
            "Epoch [60/80], Step [300/391] Loss: 0.1175\n",
            "train_err: 0.10694 test_err: 0.2464\n",
            "Epoch [61/80], Step [100/391] Loss: 0.0456\n",
            "Epoch [61/80], Step [200/391] Loss: 0.1273\n",
            "Epoch [61/80], Step [300/391] Loss: 0.1252\n",
            "train_err: 0.05964 test_err: 0.2038\n",
            "Epoch [62/80], Step [100/391] Loss: 0.0467\n",
            "Epoch [62/80], Step [200/391] Loss: 0.1483\n",
            "Epoch [62/80], Step [300/391] Loss: 0.0805\n",
            "train_err: 0.03948 test_err: 0.1881\n",
            "Epoch [63/80], Step [100/391] Loss: 0.0698\n",
            "Epoch [63/80], Step [200/391] Loss: 0.0832\n",
            "Epoch [63/80], Step [300/391] Loss: 0.1261\n",
            "train_err: 0.06304 test_err: 0.2081\n",
            "Epoch [64/80], Step [100/391] Loss: 0.1633\n",
            "Epoch [64/80], Step [200/391] Loss: 0.0735\n",
            "Epoch [64/80], Step [300/391] Loss: 0.0635\n",
            "train_err: 0.09722 test_err: 0.237\n",
            "Epoch [65/80], Step [100/391] Loss: 0.1659\n",
            "Epoch [65/80], Step [200/391] Loss: 0.1043\n",
            "Epoch [65/80], Step [300/391] Loss: 0.1037\n",
            "train_err: 0.12642 test_err: 0.2598\n",
            "Epoch [66/80], Step [100/391] Loss: 0.1483\n",
            "Epoch [66/80], Step [200/391] Loss: 0.0756\n",
            "Epoch [66/80], Step [300/391] Loss: 0.1142\n",
            "train_err: 0.07444 test_err: 0.2111\n",
            "Epoch [67/80], Step [100/391] Loss: 0.0480\n",
            "Epoch [67/80], Step [200/391] Loss: 0.1492\n",
            "Epoch [67/80], Step [300/391] Loss: 0.0778\n",
            "train_err: 0.08438 test_err: 0.2152\n",
            "Epoch [68/80], Step [100/391] Loss: 0.0806\n",
            "Epoch [68/80], Step [200/391] Loss: 0.2278\n",
            "Epoch [68/80], Step [300/391] Loss: 0.1683\n",
            "train_err: 0.1361 test_err: 0.2668\n",
            "Epoch [69/80], Step [100/391] Loss: 0.0650\n",
            "Epoch [69/80], Step [200/391] Loss: 0.0746\n",
            "Epoch [69/80], Step [300/391] Loss: 0.1051\n",
            "train_err: 0.0618 test_err: 0.2093\n",
            "Epoch [70/80], Step [100/391] Loss: 0.1060\n",
            "Epoch [70/80], Step [200/391] Loss: 0.0790\n",
            "Epoch [70/80], Step [300/391] Loss: 0.0877\n",
            "train_err: 0.05972 test_err: 0.2048\n",
            "Epoch [71/80], Step [100/391] Loss: 0.1228\n",
            "Epoch [71/80], Step [200/391] Loss: 0.0734\n",
            "Epoch [71/80], Step [300/391] Loss: 0.0704\n",
            "train_err: 0.08028 test_err: 0.2201\n",
            "Epoch [72/80], Step [100/391] Loss: 0.1625\n",
            "Epoch [72/80], Step [200/391] Loss: 0.1272\n",
            "Epoch [72/80], Step [300/391] Loss: 0.0361\n",
            "train_err: 0.17572 test_err: 0.3048\n",
            "Epoch [73/80], Step [100/391] Loss: 0.1547\n",
            "Epoch [73/80], Step [200/391] Loss: 0.0892\n",
            "Epoch [73/80], Step [300/391] Loss: 0.0747\n",
            "train_err: 0.07638 test_err: 0.2188\n",
            "Epoch [74/80], Step [100/391] Loss: 0.0394\n",
            "Epoch [74/80], Step [200/391] Loss: 0.1585\n",
            "Epoch [74/80], Step [300/391] Loss: 0.1388\n",
            "train_err: 0.09086 test_err: 0.2261\n",
            "Epoch [75/80], Step [100/391] Loss: 0.0712\n",
            "Epoch [75/80], Step [200/391] Loss: 0.2200\n",
            "Epoch [75/80], Step [300/391] Loss: 0.2482\n",
            "train_err: 0.24568 test_err: 0.3318\n",
            "Epoch [76/80], Step [100/391] Loss: 0.1706\n",
            "Epoch [76/80], Step [200/391] Loss: 0.2072\n",
            "Epoch [76/80], Step [300/391] Loss: 0.2316\n",
            "train_err: 0.07448 test_err: 0.2107\n",
            "Epoch [77/80], Step [100/391] Loss: 0.0732\n",
            "Epoch [77/80], Step [200/391] Loss: 0.1111\n",
            "Epoch [77/80], Step [300/391] Loss: 0.2259\n",
            "train_err: 0.05556 test_err: 0.1915\n",
            "Epoch [78/80], Step [100/391] Loss: 0.1117\n",
            "Epoch [78/80], Step [200/391] Loss: 0.1134\n",
            "Epoch [78/80], Step [300/391] Loss: 0.1538\n",
            "train_err: 0.17914 test_err: 0.2829\n",
            "Epoch [79/80], Step [100/391] Loss: 0.0850\n",
            "Epoch [79/80], Step [200/391] Loss: 0.2444\n",
            "Epoch [79/80], Step [300/391] Loss: 0.1790\n",
            "train_err: 0.15884 test_err: 0.2829\n",
            "Epoch [80/80], Step [100/391] Loss: 0.1406\n",
            "Epoch [80/80], Step [200/391] Loss: 0.0981\n",
            "Epoch [80/80], Step [300/391] Loss: 0.0814\n",
            "train_err: 0.05716 test_err: 0.2044\n",
            "Accuracy of the model on the test images: 79.56 %\n",
            "resnet32.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzW3PdDuYTsC"
      },
      "source": [
        "**Resnet44**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyxKW5mzaFeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21290509-245a-4dc0-d756-d971b5a57ca8"
      },
      "source": [
        "resnet44Model = createResnetModelWithDepth(44)\n",
        "trainModel(resnet44Model,44)\n",
        "testModel(resnet44Model)\n",
        "saveModel(resnet44Model,44)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.2902\n",
            "Epoch [1/80], Step [200/391] Loss: 2.2962\n",
            "Epoch [1/80], Step [300/391] Loss: 2.3020\n",
            "train_err: 0.8976 test_err: 0.897\n",
            "Epoch [2/80], Step [100/391] Loss: 2.3211\n",
            "Epoch [2/80], Step [200/391] Loss: 2.2911\n",
            "Epoch [2/80], Step [300/391] Loss: 2.3040\n",
            "train_err: 0.89818 test_err: 0.8997\n",
            "Epoch [3/80], Step [100/391] Loss: 2.2993\n",
            "Epoch [3/80], Step [200/391] Loss: 2.2811\n",
            "Epoch [3/80], Step [300/391] Loss: 2.2781\n",
            "train_err: 0.89962 test_err: 0.8995\n",
            "Epoch [4/80], Step [100/391] Loss: 2.3024\n",
            "Epoch [4/80], Step [200/391] Loss: 2.2986\n",
            "Epoch [4/80], Step [300/391] Loss: 2.2140\n",
            "train_err: 0.83594 test_err: 0.8347\n",
            "Epoch [5/80], Step [100/391] Loss: 2.0337\n",
            "Epoch [5/80], Step [200/391] Loss: 2.0738\n",
            "Epoch [5/80], Step [300/391] Loss: 1.9323\n",
            "train_err: 0.74904 test_err: 0.7484\n",
            "Epoch [6/80], Step [100/391] Loss: 1.7836\n",
            "Epoch [6/80], Step [200/391] Loss: 1.7977\n",
            "Epoch [6/80], Step [300/391] Loss: 1.7815\n",
            "train_err: 0.6747 test_err: 0.679\n",
            "Epoch [7/80], Step [100/391] Loss: 1.7121\n",
            "Epoch [7/80], Step [200/391] Loss: 1.7914\n",
            "Epoch [7/80], Step [300/391] Loss: 1.6747\n",
            "train_err: 0.57544 test_err: 0.5862\n",
            "Epoch [8/80], Step [100/391] Loss: 1.5402\n",
            "Epoch [8/80], Step [200/391] Loss: 1.4888\n",
            "Epoch [8/80], Step [300/391] Loss: 1.5403\n",
            "train_err: 0.59328 test_err: 0.5886\n",
            "Epoch [9/80], Step [100/391] Loss: 1.4969\n",
            "Epoch [9/80], Step [200/391] Loss: 1.2140\n",
            "Epoch [9/80], Step [300/391] Loss: 1.2516\n",
            "train_err: 0.52256 test_err: 0.5388\n",
            "Epoch [10/80], Step [100/391] Loss: 1.3593\n",
            "Epoch [10/80], Step [200/391] Loss: 1.3148\n",
            "Epoch [10/80], Step [300/391] Loss: 1.1345\n",
            "train_err: 0.45498 test_err: 0.4707\n",
            "Epoch [11/80], Step [100/391] Loss: 1.0218\n",
            "Epoch [11/80], Step [200/391] Loss: 1.0502\n",
            "Epoch [11/80], Step [300/391] Loss: 1.0814\n",
            "train_err: 0.4062 test_err: 0.4252\n",
            "Epoch [12/80], Step [100/391] Loss: 0.9959\n",
            "Epoch [12/80], Step [200/391] Loss: 0.6718\n",
            "Epoch [12/80], Step [300/391] Loss: 0.8713\n",
            "train_err: 0.34704 test_err: 0.366\n",
            "Epoch [13/80], Step [100/391] Loss: 0.7135\n",
            "Epoch [13/80], Step [200/391] Loss: 0.8423\n",
            "Epoch [13/80], Step [300/391] Loss: 0.8082\n",
            "train_err: 0.37628 test_err: 0.3922\n",
            "Epoch [14/80], Step [100/391] Loss: 0.5559\n",
            "Epoch [14/80], Step [200/391] Loss: 0.5158\n",
            "Epoch [14/80], Step [300/391] Loss: 0.5672\n",
            "train_err: 0.24314 test_err: 0.2841\n",
            "Epoch [15/80], Step [100/391] Loss: 0.6414\n",
            "Epoch [15/80], Step [200/391] Loss: 0.5893\n",
            "Epoch [15/80], Step [300/391] Loss: 0.7220\n",
            "train_err: 0.2105 test_err: 0.251\n",
            "Epoch [16/80], Step [100/391] Loss: 0.4731\n",
            "Epoch [16/80], Step [200/391] Loss: 0.5910\n",
            "Epoch [16/80], Step [300/391] Loss: 0.3679\n",
            "train_err: 0.24556 test_err: 0.2829\n",
            "Epoch [17/80], Step [100/391] Loss: 0.3940\n",
            "Epoch [17/80], Step [200/391] Loss: 0.6612\n",
            "Epoch [17/80], Step [300/391] Loss: 0.5812\n",
            "train_err: 0.15478 test_err: 0.2147\n",
            "Epoch [18/80], Step [100/391] Loss: 0.3469\n",
            "Epoch [18/80], Step [200/391] Loss: 0.4368\n",
            "Epoch [18/80], Step [300/391] Loss: 0.4923\n",
            "train_err: 0.1487 test_err: 0.2062\n",
            "Epoch [19/80], Step [100/391] Loss: 0.4248\n",
            "Epoch [19/80], Step [200/391] Loss: 0.4141\n",
            "Epoch [19/80], Step [300/391] Loss: 0.5072\n",
            "train_err: 0.16056 test_err: 0.2288\n",
            "Epoch [20/80], Step [100/391] Loss: 0.5443\n",
            "Epoch [20/80], Step [200/391] Loss: 0.4335\n",
            "Epoch [20/80], Step [300/391] Loss: 0.3452\n",
            "train_err: 0.15554 test_err: 0.2286\n",
            "Epoch [21/80], Step [100/391] Loss: 0.2748\n",
            "Epoch [21/80], Step [200/391] Loss: 0.4386\n",
            "Epoch [21/80], Step [300/391] Loss: 0.4945\n",
            "train_err: 0.1695 test_err: 0.2387\n",
            "Epoch [22/80], Step [100/391] Loss: 0.3330\n",
            "Epoch [22/80], Step [200/391] Loss: 0.4594\n",
            "Epoch [22/80], Step [300/391] Loss: 0.3244\n",
            "train_err: 0.12972 test_err: 0.2166\n",
            "Epoch [23/80], Step [100/391] Loss: 0.3187\n",
            "Epoch [23/80], Step [200/391] Loss: 0.3371\n",
            "Epoch [23/80], Step [300/391] Loss: 0.2996\n",
            "train_err: 0.17354 test_err: 0.2524\n",
            "Epoch [24/80], Step [100/391] Loss: 0.3906\n",
            "Epoch [24/80], Step [200/391] Loss: 0.2189\n",
            "Epoch [24/80], Step [300/391] Loss: 0.3705\n",
            "train_err: 0.13114 test_err: 0.2184\n",
            "Epoch [25/80], Step [100/391] Loss: 0.2989\n",
            "Epoch [25/80], Step [200/391] Loss: 0.3227\n",
            "Epoch [25/80], Step [300/391] Loss: 0.3662\n",
            "train_err: 0.07916 test_err: 0.1895\n",
            "Epoch [26/80], Step [100/391] Loss: 0.2637\n",
            "Epoch [26/80], Step [200/391] Loss: 0.2669\n",
            "Epoch [26/80], Step [300/391] Loss: 0.1624\n",
            "train_err: 0.0742 test_err: 0.1879\n",
            "Epoch [27/80], Step [100/391] Loss: 0.1530\n",
            "Epoch [27/80], Step [200/391] Loss: 0.2616\n",
            "Epoch [27/80], Step [300/391] Loss: 0.2216\n",
            "train_err: 0.0716 test_err: 0.1931\n",
            "Epoch [28/80], Step [100/391] Loss: 0.2596\n",
            "Epoch [28/80], Step [200/391] Loss: 0.2436\n",
            "Epoch [28/80], Step [300/391] Loss: 0.2235\n",
            "train_err: 0.06568 test_err: 0.1901\n",
            "Epoch [29/80], Step [100/391] Loss: 0.1064\n",
            "Epoch [29/80], Step [200/391] Loss: 0.2437\n",
            "Epoch [29/80], Step [300/391] Loss: 0.2200\n",
            "train_err: 0.08146 test_err: 0.2051\n",
            "Epoch [30/80], Step [100/391] Loss: 0.1109\n",
            "Epoch [30/80], Step [200/391] Loss: 0.1039\n",
            "Epoch [30/80], Step [300/391] Loss: 0.1724\n",
            "train_err: 0.12582 test_err: 0.2337\n",
            "Epoch [31/80], Step [100/391] Loss: 0.1474\n",
            "Epoch [31/80], Step [200/391] Loss: 0.1236\n",
            "Epoch [31/80], Step [300/391] Loss: 0.2085\n",
            "train_err: 0.08838 test_err: 0.2133\n",
            "Epoch [32/80], Step [100/391] Loss: 0.1069\n",
            "Epoch [32/80], Step [200/391] Loss: 0.1613\n",
            "Epoch [32/80], Step [300/391] Loss: 0.1631\n",
            "train_err: 0.06894 test_err: 0.1935\n",
            "Epoch [33/80], Step [100/391] Loss: 0.1238\n",
            "Epoch [33/80], Step [200/391] Loss: 0.0715\n",
            "Epoch [33/80], Step [300/391] Loss: 0.0909\n",
            "train_err: 0.10142 test_err: 0.2246\n",
            "Epoch [34/80], Step [100/391] Loss: 0.0716\n",
            "Epoch [34/80], Step [200/391] Loss: 0.1100\n",
            "Epoch [34/80], Step [300/391] Loss: 0.1463\n",
            "train_err: 0.06624 test_err: 0.2049\n",
            "Epoch [35/80], Step [100/391] Loss: 0.1197\n",
            "Epoch [35/80], Step [200/391] Loss: 0.1371\n",
            "Epoch [35/80], Step [300/391] Loss: 0.1291\n",
            "train_err: 0.13324 test_err: 0.2554\n",
            "Epoch [36/80], Step [100/391] Loss: 0.0764\n",
            "Epoch [36/80], Step [200/391] Loss: 0.1417\n",
            "Epoch [36/80], Step [300/391] Loss: 0.2855\n",
            "train_err: 0.06598 test_err: 0.1985\n",
            "Epoch [37/80], Step [100/391] Loss: 0.0865\n",
            "Epoch [37/80], Step [200/391] Loss: 0.1822\n",
            "Epoch [37/80], Step [300/391] Loss: 0.1923\n",
            "train_err: 0.05582 test_err: 0.1935\n",
            "Epoch [38/80], Step [100/391] Loss: 0.1278\n",
            "Epoch [38/80], Step [200/391] Loss: 0.1216\n",
            "Epoch [38/80], Step [300/391] Loss: 0.2023\n",
            "train_err: 0.11634 test_err: 0.2485\n",
            "Epoch [39/80], Step [100/391] Loss: 0.0501\n",
            "Epoch [39/80], Step [200/391] Loss: 0.1746\n",
            "Epoch [39/80], Step [300/391] Loss: 0.0783\n",
            "train_err: 0.03648 test_err: 0.1814\n",
            "Epoch [40/80], Step [100/391] Loss: 0.1148\n",
            "Epoch [40/80], Step [200/391] Loss: 0.1154\n",
            "Epoch [40/80], Step [300/391] Loss: 0.1065\n",
            "train_err: 0.0819 test_err: 0.2199\n",
            "Epoch [41/80], Step [100/391] Loss: 0.0605\n",
            "Epoch [41/80], Step [200/391] Loss: 0.1778\n",
            "Epoch [41/80], Step [300/391] Loss: 0.0922\n",
            "train_err: 0.0693 test_err: 0.2089\n",
            "Epoch [42/80], Step [100/391] Loss: 0.0477\n",
            "Epoch [42/80], Step [200/391] Loss: 0.0571\n",
            "Epoch [42/80], Step [300/391] Loss: 0.1582\n",
            "train_err: 0.04902 test_err: 0.1941\n",
            "Epoch [43/80], Step [100/391] Loss: 0.0510\n",
            "Epoch [43/80], Step [200/391] Loss: 0.1314\n",
            "Epoch [43/80], Step [300/391] Loss: 0.1669\n",
            "train_err: 0.0454 test_err: 0.1921\n",
            "Epoch [44/80], Step [100/391] Loss: 0.0958\n",
            "Epoch [44/80], Step [200/391] Loss: 0.0943\n",
            "Epoch [44/80], Step [300/391] Loss: 0.0425\n",
            "train_err: 0.04664 test_err: 0.1974\n",
            "Epoch [45/80], Step [100/391] Loss: 0.0666\n",
            "Epoch [45/80], Step [200/391] Loss: 0.0416\n",
            "Epoch [45/80], Step [300/391] Loss: 0.0788\n",
            "train_err: 0.05102 test_err: 0.1887\n",
            "Epoch [46/80], Step [100/391] Loss: 0.0837\n",
            "Epoch [46/80], Step [200/391] Loss: 0.0860\n",
            "Epoch [46/80], Step [300/391] Loss: 0.1012\n",
            "train_err: 0.05358 test_err: 0.1982\n",
            "Epoch [47/80], Step [100/391] Loss: 0.1496\n",
            "Epoch [47/80], Step [200/391] Loss: 0.0687\n",
            "Epoch [47/80], Step [300/391] Loss: 0.1427\n",
            "train_err: 0.03726 test_err: 0.192\n",
            "Epoch [48/80], Step [100/391] Loss: 0.0188\n",
            "Epoch [48/80], Step [200/391] Loss: 0.1315\n",
            "Epoch [48/80], Step [300/391] Loss: 0.1506\n",
            "train_err: 0.04204 test_err: 0.19\n",
            "Epoch [49/80], Step [100/391] Loss: 0.0482\n",
            "Epoch [49/80], Step [200/391] Loss: 0.1063\n",
            "Epoch [49/80], Step [300/391] Loss: 0.0858\n",
            "train_err: 0.04366 test_err: 0.1928\n",
            "Epoch [50/80], Step [100/391] Loss: 0.0500\n",
            "Epoch [50/80], Step [200/391] Loss: 0.0892\n",
            "Epoch [50/80], Step [300/391] Loss: 0.0531\n",
            "train_err: 0.05702 test_err: 0.2009\n",
            "Epoch [51/80], Step [100/391] Loss: 0.1047\n",
            "Epoch [51/80], Step [200/391] Loss: 0.0887\n",
            "Epoch [51/80], Step [300/391] Loss: 0.1592\n",
            "train_err: 0.0578 test_err: 0.1996\n",
            "Epoch [52/80], Step [100/391] Loss: 0.0952\n",
            "Epoch [52/80], Step [200/391] Loss: 0.0640\n",
            "Epoch [52/80], Step [300/391] Loss: 0.1263\n",
            "train_err: 0.0354 test_err: 0.1849\n",
            "Epoch [53/80], Step [100/391] Loss: 0.0710\n",
            "Epoch [53/80], Step [200/391] Loss: 0.0645\n",
            "Epoch [53/80], Step [300/391] Loss: 0.1093\n",
            "train_err: 0.064 test_err: 0.2093\n",
            "Epoch [54/80], Step [100/391] Loss: 0.0749\n",
            "Epoch [54/80], Step [200/391] Loss: 0.1470\n",
            "Epoch [54/80], Step [300/391] Loss: 0.0733\n",
            "train_err: 0.1094 test_err: 0.2433\n",
            "Epoch [55/80], Step [100/391] Loss: 0.0406\n",
            "Epoch [55/80], Step [200/391] Loss: 0.1252\n",
            "Epoch [55/80], Step [300/391] Loss: 0.0656\n",
            "train_err: 0.033 test_err: 0.1829\n",
            "Epoch [56/80], Step [100/391] Loss: 0.0577\n",
            "Epoch [56/80], Step [200/391] Loss: 0.0620\n",
            "Epoch [56/80], Step [300/391] Loss: 0.0969\n",
            "train_err: 0.07906 test_err: 0.2186\n",
            "Epoch [57/80], Step [100/391] Loss: 0.0505\n",
            "Epoch [57/80], Step [200/391] Loss: 0.0411\n",
            "Epoch [57/80], Step [300/391] Loss: 0.1163\n",
            "train_err: 0.05628 test_err: 0.1986\n",
            "Epoch [58/80], Step [100/391] Loss: 0.0918\n",
            "Epoch [58/80], Step [200/391] Loss: 0.1132\n",
            "Epoch [58/80], Step [300/391] Loss: 0.1204\n",
            "train_err: 0.03746 test_err: 0.1842\n",
            "Epoch [59/80], Step [100/391] Loss: 0.0674\n",
            "Epoch [59/80], Step [200/391] Loss: 0.0758\n",
            "Epoch [59/80], Step [300/391] Loss: 0.1228\n",
            "train_err: 0.1091 test_err: 0.2381\n",
            "Epoch [60/80], Step [100/391] Loss: 0.0493\n",
            "Epoch [60/80], Step [200/391] Loss: 0.0299\n",
            "Epoch [60/80], Step [300/391] Loss: 0.0494\n",
            "train_err: 0.05836 test_err: 0.2107\n",
            "Epoch [61/80], Step [100/391] Loss: 0.0653\n",
            "Epoch [61/80], Step [200/391] Loss: 0.0810\n",
            "Epoch [61/80], Step [300/391] Loss: 0.0622\n",
            "train_err: 0.03758 test_err: 0.1751\n",
            "Epoch [62/80], Step [100/391] Loss: 0.0147\n",
            "Epoch [62/80], Step [200/391] Loss: 0.1261\n",
            "Epoch [62/80], Step [300/391] Loss: 0.0807\n",
            "train_err: 0.04698 test_err: 0.19\n",
            "Epoch [63/80], Step [100/391] Loss: 0.0566\n",
            "Epoch [63/80], Step [200/391] Loss: 0.0669\n",
            "Epoch [63/80], Step [300/391] Loss: 0.0420\n",
            "train_err: 0.05006 test_err: 0.1988\n",
            "Epoch [64/80], Step [100/391] Loss: 0.0649\n",
            "Epoch [64/80], Step [200/391] Loss: 0.1265\n",
            "Epoch [64/80], Step [300/391] Loss: 0.0883\n",
            "train_err: 0.049 test_err: 0.1957\n",
            "Epoch [65/80], Step [100/391] Loss: 0.0965\n",
            "Epoch [65/80], Step [200/391] Loss: 0.0873\n",
            "Epoch [65/80], Step [300/391] Loss: 0.0836\n",
            "train_err: 0.04824 test_err: 0.2029\n",
            "Epoch [66/80], Step [100/391] Loss: 0.0998\n",
            "Epoch [66/80], Step [200/391] Loss: 0.0126\n",
            "Epoch [66/80], Step [300/391] Loss: 0.0992\n",
            "train_err: 0.0569 test_err: 0.1969\n",
            "Epoch [67/80], Step [100/391] Loss: 0.0666\n",
            "Epoch [67/80], Step [200/391] Loss: 0.0317\n",
            "Epoch [67/80], Step [300/391] Loss: 0.0567\n",
            "train_err: 0.04468 test_err: 0.1921\n",
            "Epoch [68/80], Step [100/391] Loss: 0.0721\n",
            "Epoch [68/80], Step [200/391] Loss: 0.0480\n",
            "Epoch [68/80], Step [300/391] Loss: 0.0582\n",
            "train_err: 0.02752 test_err: 0.1761\n",
            "Epoch [69/80], Step [100/391] Loss: 0.0792\n",
            "Epoch [69/80], Step [200/391] Loss: 0.1263\n",
            "Epoch [69/80], Step [300/391] Loss: 0.1828\n",
            "train_err: 0.02156 test_err: 0.1735\n",
            "Epoch [70/80], Step [100/391] Loss: 0.0191\n",
            "Epoch [70/80], Step [200/391] Loss: 0.0829\n",
            "Epoch [70/80], Step [300/391] Loss: 0.1214\n",
            "train_err: 0.03734 test_err: 0.1948\n",
            "Epoch [71/80], Step [100/391] Loss: 0.0264\n",
            "Epoch [71/80], Step [200/391] Loss: 0.1615\n",
            "Epoch [71/80], Step [300/391] Loss: 0.0895\n",
            "train_err: 0.05454 test_err: 0.2001\n",
            "Epoch [72/80], Step [100/391] Loss: 0.0854\n",
            "Epoch [72/80], Step [200/391] Loss: 0.1397\n",
            "Epoch [72/80], Step [300/391] Loss: 0.0976\n",
            "train_err: 0.05446 test_err: 0.1989\n",
            "Epoch [73/80], Step [100/391] Loss: 0.1034\n",
            "Epoch [73/80], Step [200/391] Loss: 0.0820\n",
            "Epoch [73/80], Step [300/391] Loss: 0.0459\n",
            "train_err: 0.06476 test_err: 0.2145\n",
            "Epoch [74/80], Step [100/391] Loss: 0.0473\n",
            "Epoch [74/80], Step [200/391] Loss: 0.0739\n",
            "Epoch [74/80], Step [300/391] Loss: 0.0663\n",
            "train_err: 0.04838 test_err: 0.1974\n",
            "Epoch [75/80], Step [100/391] Loss: 0.1097\n",
            "Epoch [75/80], Step [200/391] Loss: 0.0654\n",
            "Epoch [75/80], Step [300/391] Loss: 0.2154\n",
            "train_err: 0.04986 test_err: 0.1943\n",
            "Epoch [76/80], Step [100/391] Loss: 0.0641\n",
            "Epoch [76/80], Step [200/391] Loss: 0.0816\n",
            "Epoch [76/80], Step [300/391] Loss: 0.0511\n",
            "train_err: 0.04488 test_err: 0.1952\n",
            "Epoch [77/80], Step [100/391] Loss: 0.1630\n",
            "Epoch [77/80], Step [200/391] Loss: 0.0333\n",
            "Epoch [77/80], Step [300/391] Loss: 0.0337\n",
            "train_err: 0.05706 test_err: 0.1991\n",
            "Epoch [78/80], Step [100/391] Loss: 0.0327\n",
            "Epoch [78/80], Step [200/391] Loss: 0.0574\n",
            "Epoch [78/80], Step [300/391] Loss: 0.0234\n",
            "train_err: 0.11922 test_err: 0.2526\n",
            "Epoch [79/80], Step [100/391] Loss: 0.0711\n",
            "Epoch [79/80], Step [200/391] Loss: 0.0980\n",
            "Epoch [79/80], Step [300/391] Loss: 0.0541\n",
            "train_err: 0.03124 test_err: 0.185\n",
            "Epoch [80/80], Step [100/391] Loss: 0.0798\n",
            "Epoch [80/80], Step [200/391] Loss: 0.0582\n",
            "Epoch [80/80], Step [300/391] Loss: 0.0729\n",
            "train_err: 0.06044 test_err: 0.2093\n",
            "Accuracy of the model on the test images: 79.07 %\n",
            "resnet44.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NULlJaGtYVL5"
      },
      "source": [
        "**Resnet56**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqjIFm7MaJBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6929ae-0bfb-42f2-92a2-2922de6d8e0a"
      },
      "source": [
        "resnet56Model = createResnetModelWithDepth(56)\n",
        "trainModel(resnet56Model,56)\n",
        "testModel(resnet56Model)\n",
        "saveModel(resnet56Model,56)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.2851\n",
            "Epoch [1/80], Step [200/391] Loss: 2.2793\n",
            "Epoch [1/80], Step [300/391] Loss: 2.2381\n",
            "train_err: 0.87336 test_err: 0.8722\n",
            "Epoch [2/80], Step [100/391] Loss: 2.1901\n",
            "Epoch [2/80], Step [200/391] Loss: 2.0979\n",
            "Epoch [2/80], Step [300/391] Loss: 1.9811\n",
            "train_err: 0.74428 test_err: 0.7405\n",
            "Epoch [3/80], Step [100/391] Loss: 1.8649\n",
            "Epoch [3/80], Step [200/391] Loss: 1.8804\n",
            "Epoch [3/80], Step [300/391] Loss: 1.8222\n",
            "train_err: 0.70926 test_err: 0.7092\n",
            "Epoch [4/80], Step [100/391] Loss: 1.8655\n",
            "Epoch [4/80], Step [200/391] Loss: 1.7609\n",
            "Epoch [4/80], Step [300/391] Loss: 1.7350\n",
            "train_err: 0.63418 test_err: 0.6375\n",
            "Epoch [5/80], Step [100/391] Loss: 1.6834\n",
            "Epoch [5/80], Step [200/391] Loss: 1.6493\n",
            "Epoch [5/80], Step [300/391] Loss: 1.8242\n",
            "train_err: 0.58242 test_err: 0.5856\n",
            "Epoch [6/80], Step [100/391] Loss: 1.5505\n",
            "Epoch [6/80], Step [200/391] Loss: 1.4106\n",
            "Epoch [6/80], Step [300/391] Loss: 1.5584\n",
            "train_err: 0.54658 test_err: 0.5525\n",
            "Epoch [7/80], Step [100/391] Loss: 1.3811\n",
            "Epoch [7/80], Step [200/391] Loss: 1.3504\n",
            "Epoch [7/80], Step [300/391] Loss: 1.3299\n",
            "train_err: 0.51512 test_err: 0.5182\n",
            "Epoch [8/80], Step [100/391] Loss: 1.1498\n",
            "Epoch [8/80], Step [200/391] Loss: 1.3141\n",
            "Epoch [8/80], Step [300/391] Loss: 1.2548\n",
            "train_err: 0.45784 test_err: 0.4662\n",
            "Epoch [9/80], Step [100/391] Loss: 1.0395\n",
            "Epoch [9/80], Step [200/391] Loss: 1.1299\n",
            "Epoch [9/80], Step [300/391] Loss: 1.0607\n",
            "train_err: 0.37186 test_err: 0.3952\n",
            "Epoch [10/80], Step [100/391] Loss: 1.0009\n",
            "Epoch [10/80], Step [200/391] Loss: 1.0461\n",
            "Epoch [10/80], Step [300/391] Loss: 0.9636\n",
            "train_err: 0.37814 test_err: 0.398\n",
            "Epoch [11/80], Step [100/391] Loss: 0.9911\n",
            "Epoch [11/80], Step [200/391] Loss: 0.7196\n",
            "Epoch [11/80], Step [300/391] Loss: 0.9133\n",
            "train_err: 0.36668 test_err: 0.3944\n",
            "Epoch [12/80], Step [100/391] Loss: 0.9486\n",
            "Epoch [12/80], Step [200/391] Loss: 0.9103\n",
            "Epoch [12/80], Step [300/391] Loss: 0.8124\n",
            "train_err: 0.2773 test_err: 0.3118\n",
            "Epoch [13/80], Step [100/391] Loss: 0.8081\n",
            "Epoch [13/80], Step [200/391] Loss: 0.8051\n",
            "Epoch [13/80], Step [300/391] Loss: 0.8815\n",
            "train_err: 0.2708 test_err: 0.3109\n",
            "Epoch [14/80], Step [100/391] Loss: 0.6647\n",
            "Epoch [14/80], Step [200/391] Loss: 0.8725\n",
            "Epoch [14/80], Step [300/391] Loss: 0.6664\n",
            "train_err: 0.22798 test_err: 0.2722\n",
            "Epoch [15/80], Step [100/391] Loss: 0.5754\n",
            "Epoch [15/80], Step [200/391] Loss: 0.7986\n",
            "Epoch [15/80], Step [300/391] Loss: 0.7284\n",
            "train_err: 0.21076 test_err: 0.2629\n",
            "Epoch [16/80], Step [100/391] Loss: 0.4625\n",
            "Epoch [16/80], Step [200/391] Loss: 0.6037\n",
            "Epoch [16/80], Step [300/391] Loss: 0.4430\n",
            "train_err: 0.21614 test_err: 0.2657\n",
            "Epoch [17/80], Step [100/391] Loss: 0.5631\n",
            "Epoch [17/80], Step [200/391] Loss: 0.4370\n",
            "Epoch [17/80], Step [300/391] Loss: 0.4890\n",
            "train_err: 0.19238 test_err: 0.2445\n",
            "Epoch [18/80], Step [100/391] Loss: 0.5282\n",
            "Epoch [18/80], Step [200/391] Loss: 0.4321\n",
            "Epoch [18/80], Step [300/391] Loss: 0.6582\n",
            "train_err: 0.24616 test_err: 0.3011\n",
            "Epoch [19/80], Step [100/391] Loss: 0.6528\n",
            "Epoch [19/80], Step [200/391] Loss: 0.4013\n",
            "Epoch [19/80], Step [300/391] Loss: 0.8351\n",
            "train_err: 0.19096 test_err: 0.2524\n",
            "Epoch [20/80], Step [100/391] Loss: 0.3277\n",
            "Epoch [20/80], Step [200/391] Loss: 0.3300\n",
            "Epoch [20/80], Step [300/391] Loss: 0.5311\n",
            "train_err: 0.15668 test_err: 0.2342\n",
            "Epoch [21/80], Step [100/391] Loss: 0.3053\n",
            "Epoch [21/80], Step [200/391] Loss: 0.2636\n",
            "Epoch [21/80], Step [300/391] Loss: 0.3045\n",
            "train_err: 0.15046 test_err: 0.2276\n",
            "Epoch [22/80], Step [100/391] Loss: 0.2753\n",
            "Epoch [22/80], Step [200/391] Loss: 0.3901\n",
            "Epoch [22/80], Step [300/391] Loss: 0.4593\n",
            "train_err: 0.16322 test_err: 0.238\n",
            "Epoch [23/80], Step [100/391] Loss: 0.4765\n",
            "Epoch [23/80], Step [200/391] Loss: 0.5814\n",
            "Epoch [23/80], Step [300/391] Loss: 0.3336\n",
            "train_err: 0.14586 test_err: 0.2302\n",
            "Epoch [24/80], Step [100/391] Loss: 0.3980\n",
            "Epoch [24/80], Step [200/391] Loss: 0.3635\n",
            "Epoch [24/80], Step [300/391] Loss: 0.5295\n",
            "train_err: 0.12304 test_err: 0.2177\n",
            "Epoch [25/80], Step [100/391] Loss: 0.2514\n",
            "Epoch [25/80], Step [200/391] Loss: 0.4600\n",
            "Epoch [25/80], Step [300/391] Loss: 0.4018\n",
            "train_err: 0.12378 test_err: 0.2174\n",
            "Epoch [26/80], Step [100/391] Loss: 0.1991\n",
            "Epoch [26/80], Step [200/391] Loss: 0.3309\n",
            "Epoch [26/80], Step [300/391] Loss: 0.2434\n",
            "train_err: 0.13948 test_err: 0.2353\n",
            "Epoch [27/80], Step [100/391] Loss: 0.3143\n",
            "Epoch [27/80], Step [200/391] Loss: 0.2842\n",
            "Epoch [27/80], Step [300/391] Loss: 0.4158\n",
            "train_err: 0.07398 test_err: 0.189\n",
            "Epoch [28/80], Step [100/391] Loss: 0.1774\n",
            "Epoch [28/80], Step [200/391] Loss: 0.3161\n",
            "Epoch [28/80], Step [300/391] Loss: 0.2340\n",
            "train_err: 0.18324 test_err: 0.2728\n",
            "Epoch [29/80], Step [100/391] Loss: 0.1556\n",
            "Epoch [29/80], Step [200/391] Loss: 0.2323\n",
            "Epoch [29/80], Step [300/391] Loss: 0.2944\n",
            "train_err: 0.09752 test_err: 0.212\n",
            "Epoch [30/80], Step [100/391] Loss: 0.2083\n",
            "Epoch [30/80], Step [200/391] Loss: 0.1968\n",
            "Epoch [30/80], Step [300/391] Loss: 0.2568\n",
            "train_err: 0.15272 test_err: 0.2508\n",
            "Epoch [31/80], Step [100/391] Loss: 0.1623\n",
            "Epoch [31/80], Step [200/391] Loss: 0.3999\n",
            "Epoch [31/80], Step [300/391] Loss: 0.1733\n",
            "train_err: 0.09506 test_err: 0.2106\n",
            "Epoch [32/80], Step [100/391] Loss: 0.1339\n",
            "Epoch [32/80], Step [200/391] Loss: 0.2073\n",
            "Epoch [32/80], Step [300/391] Loss: 0.1470\n",
            "train_err: 0.09552 test_err: 0.2149\n",
            "Epoch [33/80], Step [100/391] Loss: 0.1560\n",
            "Epoch [33/80], Step [200/391] Loss: 0.1869\n",
            "Epoch [33/80], Step [300/391] Loss: 0.2397\n",
            "train_err: 0.07536 test_err: 0.2019\n",
            "Epoch [34/80], Step [100/391] Loss: 0.1834\n",
            "Epoch [34/80], Step [200/391] Loss: 0.1962\n",
            "Epoch [34/80], Step [300/391] Loss: 0.1674\n",
            "train_err: 0.0672 test_err: 0.1932\n",
            "Epoch [35/80], Step [100/391] Loss: 0.2542\n",
            "Epoch [35/80], Step [200/391] Loss: 0.1014\n",
            "Epoch [35/80], Step [300/391] Loss: 0.1739\n",
            "train_err: 0.0712 test_err: 0.2043\n",
            "Epoch [36/80], Step [100/391] Loss: 0.1519\n",
            "Epoch [36/80], Step [200/391] Loss: 0.2837\n",
            "Epoch [36/80], Step [300/391] Loss: 0.2939\n",
            "train_err: 0.09208 test_err: 0.2262\n",
            "Epoch [37/80], Step [100/391] Loss: 0.1223\n",
            "Epoch [37/80], Step [200/391] Loss: 0.2315\n",
            "Epoch [37/80], Step [300/391] Loss: 0.1291\n",
            "train_err: 0.06954 test_err: 0.199\n",
            "Epoch [38/80], Step [100/391] Loss: 0.1195\n",
            "Epoch [38/80], Step [200/391] Loss: 0.1763\n",
            "Epoch [38/80], Step [300/391] Loss: 0.3217\n",
            "train_err: 0.07654 test_err: 0.2078\n",
            "Epoch [39/80], Step [100/391] Loss: 0.2260\n",
            "Epoch [39/80], Step [200/391] Loss: 0.1926\n",
            "Epoch [39/80], Step [300/391] Loss: 0.1192\n",
            "train_err: 0.07164 test_err: 0.2009\n",
            "Epoch [40/80], Step [100/391] Loss: 0.1241\n",
            "Epoch [40/80], Step [200/391] Loss: 0.0699\n",
            "Epoch [40/80], Step [300/391] Loss: 0.1811\n",
            "train_err: 0.0455 test_err: 0.1838\n",
            "Epoch [41/80], Step [100/391] Loss: 0.2271\n",
            "Epoch [41/80], Step [200/391] Loss: 0.1494\n",
            "Epoch [41/80], Step [300/391] Loss: 0.0896\n",
            "train_err: 0.07924 test_err: 0.2142\n",
            "Epoch [42/80], Step [100/391] Loss: 0.0724\n",
            "Epoch [42/80], Step [200/391] Loss: 0.0690\n",
            "Epoch [42/80], Step [300/391] Loss: 0.1450\n",
            "train_err: 0.14494 test_err: 0.2671\n",
            "Epoch [43/80], Step [100/391] Loss: 0.1300\n",
            "Epoch [43/80], Step [200/391] Loss: 0.2384\n",
            "Epoch [43/80], Step [300/391] Loss: 0.1531\n",
            "train_err: 0.04628 test_err: 0.1899\n",
            "Epoch [44/80], Step [100/391] Loss: 0.1063\n",
            "Epoch [44/80], Step [200/391] Loss: 0.1894\n",
            "Epoch [44/80], Step [300/391] Loss: 0.0724\n",
            "train_err: 0.0601 test_err: 0.2057\n",
            "Epoch [45/80], Step [100/391] Loss: 0.0619\n",
            "Epoch [45/80], Step [200/391] Loss: 0.0907\n",
            "Epoch [45/80], Step [300/391] Loss: 0.1486\n",
            "train_err: 0.05586 test_err: 0.191\n",
            "Epoch [46/80], Step [100/391] Loss: 0.1480\n",
            "Epoch [46/80], Step [200/391] Loss: 0.1954\n",
            "Epoch [46/80], Step [300/391] Loss: 0.0766\n",
            "train_err: 0.0532 test_err: 0.1977\n",
            "Epoch [47/80], Step [100/391] Loss: 0.0848\n",
            "Epoch [47/80], Step [200/391] Loss: 0.1226\n",
            "Epoch [47/80], Step [300/391] Loss: 0.1219\n",
            "train_err: 0.05186 test_err: 0.1952\n",
            "Epoch [48/80], Step [100/391] Loss: 0.1030\n",
            "Epoch [48/80], Step [200/391] Loss: 0.1469\n",
            "Epoch [48/80], Step [300/391] Loss: 0.1037\n",
            "train_err: 0.05514 test_err: 0.2007\n",
            "Epoch [49/80], Step [100/391] Loss: 0.0885\n",
            "Epoch [49/80], Step [200/391] Loss: 0.1947\n",
            "Epoch [49/80], Step [300/391] Loss: 0.1138\n",
            "train_err: 0.05004 test_err: 0.1959\n",
            "Epoch [50/80], Step [100/391] Loss: 0.0550\n",
            "Epoch [50/80], Step [200/391] Loss: 0.1456\n",
            "Epoch [50/80], Step [300/391] Loss: 0.0905\n",
            "train_err: 0.04562 test_err: 0.1943\n",
            "Epoch [51/80], Step [100/391] Loss: 0.1189\n",
            "Epoch [51/80], Step [200/391] Loss: 0.0728\n",
            "Epoch [51/80], Step [300/391] Loss: 0.1493\n",
            "train_err: 0.0378 test_err: 0.1793\n",
            "Epoch [52/80], Step [100/391] Loss: 0.1808\n",
            "Epoch [52/80], Step [200/391] Loss: 0.0495\n",
            "Epoch [52/80], Step [300/391] Loss: 0.0810\n",
            "train_err: 0.06518 test_err: 0.2053\n",
            "Epoch [53/80], Step [100/391] Loss: 0.0821\n",
            "Epoch [53/80], Step [200/391] Loss: 0.1685\n",
            "Epoch [53/80], Step [300/391] Loss: 0.1111\n",
            "train_err: 0.04414 test_err: 0.1932\n",
            "Epoch [54/80], Step [100/391] Loss: 0.0287\n",
            "Epoch [54/80], Step [200/391] Loss: 0.0690\n",
            "Epoch [54/80], Step [300/391] Loss: 0.0624\n",
            "train_err: 0.05178 test_err: 0.1981\n",
            "Epoch [55/80], Step [100/391] Loss: 0.0403\n",
            "Epoch [55/80], Step [200/391] Loss: 0.0620\n",
            "Epoch [55/80], Step [300/391] Loss: 0.0769\n",
            "train_err: 0.08792 test_err: 0.2272\n",
            "Epoch [56/80], Step [100/391] Loss: 0.0462\n",
            "Epoch [56/80], Step [200/391] Loss: 0.1091\n",
            "Epoch [56/80], Step [300/391] Loss: 0.0925\n",
            "train_err: 0.07776 test_err: 0.2127\n",
            "Epoch [57/80], Step [100/391] Loss: 0.1070\n",
            "Epoch [57/80], Step [200/391] Loss: 0.0596\n",
            "Epoch [57/80], Step [300/391] Loss: 0.1667\n",
            "train_err: 0.15682 test_err: 0.2745\n",
            "Epoch [58/80], Step [100/391] Loss: 0.1349\n",
            "Epoch [58/80], Step [200/391] Loss: 0.1607\n",
            "Epoch [58/80], Step [300/391] Loss: 0.1616\n",
            "train_err: 0.05076 test_err: 0.1935\n",
            "Epoch [59/80], Step [100/391] Loss: 0.0570\n",
            "Epoch [59/80], Step [200/391] Loss: 0.0488\n",
            "Epoch [59/80], Step [300/391] Loss: 0.0815\n",
            "train_err: 0.03392 test_err: 0.1824\n",
            "Epoch [60/80], Step [100/391] Loss: 0.1326\n",
            "Epoch [60/80], Step [200/391] Loss: 0.0571\n",
            "Epoch [60/80], Step [300/391] Loss: 0.0985\n",
            "train_err: 0.02954 test_err: 0.1779\n",
            "Epoch [61/80], Step [100/391] Loss: 0.1937\n",
            "Epoch [61/80], Step [200/391] Loss: 0.0539\n",
            "Epoch [61/80], Step [300/391] Loss: 0.0548\n",
            "train_err: 0.03492 test_err: 0.1813\n",
            "Epoch [62/80], Step [100/391] Loss: 0.0200\n",
            "Epoch [62/80], Step [200/391] Loss: 0.0810\n",
            "Epoch [62/80], Step [300/391] Loss: 0.1220\n",
            "train_err: 0.06134 test_err: 0.2094\n",
            "Epoch [63/80], Step [100/391] Loss: 0.0139\n",
            "Epoch [63/80], Step [200/391] Loss: 0.0531\n",
            "Epoch [63/80], Step [300/391] Loss: 0.0880\n",
            "train_err: 0.09004 test_err: 0.2281\n",
            "Epoch [64/80], Step [100/391] Loss: 0.0435\n",
            "Epoch [64/80], Step [200/391] Loss: 0.0959\n",
            "Epoch [64/80], Step [300/391] Loss: 0.0437\n",
            "train_err: 0.07906 test_err: 0.2178\n",
            "Epoch [65/80], Step [100/391] Loss: 0.0152\n",
            "Epoch [65/80], Step [200/391] Loss: 0.1412\n",
            "Epoch [65/80], Step [300/391] Loss: 0.0657\n",
            "train_err: 0.024 test_err: 0.1709\n",
            "Epoch [66/80], Step [100/391] Loss: 0.0450\n",
            "Epoch [66/80], Step [200/391] Loss: 0.0265\n",
            "Epoch [66/80], Step [300/391] Loss: 0.0828\n",
            "train_err: 0.0863 test_err: 0.2279\n",
            "Epoch [67/80], Step [100/391] Loss: 0.0261\n",
            "Epoch [67/80], Step [200/391] Loss: 0.0578\n",
            "Epoch [67/80], Step [300/391] Loss: 0.0796\n",
            "train_err: 0.06488 test_err: 0.2042\n",
            "Epoch [68/80], Step [100/391] Loss: 0.1326\n",
            "Epoch [68/80], Step [200/391] Loss: 0.0795\n",
            "Epoch [68/80], Step [300/391] Loss: 0.0770\n",
            "train_err: 0.0444 test_err: 0.1916\n",
            "Epoch [69/80], Step [100/391] Loss: 0.0871\n",
            "Epoch [69/80], Step [200/391] Loss: 0.0190\n",
            "Epoch [69/80], Step [300/391] Loss: 0.1483\n",
            "train_err: 0.03244 test_err: 0.1806\n",
            "Epoch [70/80], Step [100/391] Loss: 0.0716\n",
            "Epoch [70/80], Step [200/391] Loss: 0.0667\n",
            "Epoch [70/80], Step [300/391] Loss: 0.1488\n",
            "train_err: 0.03098 test_err: 0.18\n",
            "Epoch [71/80], Step [100/391] Loss: 0.0896\n",
            "Epoch [71/80], Step [200/391] Loss: 0.0839\n",
            "Epoch [71/80], Step [300/391] Loss: 0.0558\n",
            "train_err: 0.07102 test_err: 0.2181\n",
            "Epoch [72/80], Step [100/391] Loss: 0.1021\n",
            "Epoch [72/80], Step [200/391] Loss: 0.0960\n",
            "Epoch [72/80], Step [300/391] Loss: 0.0751\n",
            "train_err: 0.0688 test_err: 0.2142\n",
            "Epoch [73/80], Step [100/391] Loss: 0.0743\n",
            "Epoch [73/80], Step [200/391] Loss: 0.1027\n",
            "Epoch [73/80], Step [300/391] Loss: 0.1828\n",
            "train_err: 0.0477 test_err: 0.1938\n",
            "Epoch [74/80], Step [100/391] Loss: 0.0839\n",
            "Epoch [74/80], Step [200/391] Loss: 0.0357\n",
            "Epoch [74/80], Step [300/391] Loss: 0.0784\n",
            "train_err: 0.03572 test_err: 0.1841\n",
            "Epoch [75/80], Step [100/391] Loss: 0.1840\n",
            "Epoch [75/80], Step [200/391] Loss: 0.1490\n",
            "Epoch [75/80], Step [300/391] Loss: 0.0890\n",
            "train_err: 0.03358 test_err: 0.1767\n",
            "Epoch [76/80], Step [100/391] Loss: 0.0756\n",
            "Epoch [76/80], Step [200/391] Loss: 0.0441\n",
            "Epoch [76/80], Step [300/391] Loss: 0.0439\n",
            "train_err: 0.04598 test_err: 0.1922\n",
            "Epoch [77/80], Step [100/391] Loss: 0.0891\n",
            "Epoch [77/80], Step [200/391] Loss: 0.0698\n",
            "Epoch [77/80], Step [300/391] Loss: 0.0944\n",
            "train_err: 0.07286 test_err: 0.2122\n",
            "Epoch [78/80], Step [100/391] Loss: 0.1081\n",
            "Epoch [78/80], Step [200/391] Loss: 0.1058\n",
            "Epoch [78/80], Step [300/391] Loss: 0.1549\n",
            "train_err: 0.03766 test_err: 0.186\n",
            "Epoch [79/80], Step [100/391] Loss: 0.0477\n",
            "Epoch [79/80], Step [200/391] Loss: 0.0342\n",
            "Epoch [79/80], Step [300/391] Loss: 0.0541\n",
            "train_err: 0.0614 test_err: 0.207\n",
            "Epoch [80/80], Step [100/391] Loss: 0.0428\n",
            "Epoch [80/80], Step [200/391] Loss: 0.0878\n",
            "Epoch [80/80], Step [300/391] Loss: 0.1105\n",
            "train_err: 0.0531 test_err: 0.1927\n",
            "Accuracy of the model on the test images: 80.73 %\n",
            "resnet56.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWcRO6T6AOis"
      },
      "source": [
        "###Classification error and the number of parameters of each architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FwFIy4iIQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f20eb2-8afc-4328-dc59-21ee14614b45"
      },
      "source": [
        "calculateModelParams(resnet20Model)\n",
        "calculateModelParams(resnet32Model)\n",
        "calculateModelParams(resnet44Model)\n",
        "calculateModelParams(resnet56Model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------+\n",
            "|           Modules            | Parameters |\n",
            "+------------------------------+------------+\n",
            "|         conv.weight          |    432     |\n",
            "|          bn.weight           |     16     |\n",
            "|           bn.bias            |     16     |\n",
            "|    layer1.0.conv1.weight     |    2304    |\n",
            "|     layer1.0.bn1.weight      |     16     |\n",
            "|      layer1.0.bn1.bias       |     16     |\n",
            "|    layer1.0.conv2.weight     |    2304    |\n",
            "|     layer1.0.bn2.weight      |     16     |\n",
            "|      layer1.0.bn2.bias       |     16     |\n",
            "|    layer1.1.conv1.weight     |    2304    |\n",
            "|     layer1.1.bn1.weight      |     16     |\n",
            "|      layer1.1.bn1.bias       |     16     |\n",
            "|    layer1.1.conv2.weight     |    2304    |\n",
            "|     layer1.1.bn2.weight      |     16     |\n",
            "|      layer1.1.bn2.bias       |     16     |\n",
            "|    layer1.2.conv1.weight     |    2304    |\n",
            "|     layer1.2.bn1.weight      |     16     |\n",
            "|      layer1.2.bn1.bias       |     16     |\n",
            "|    layer1.2.conv2.weight     |    2304    |\n",
            "|     layer1.2.bn2.weight      |     16     |\n",
            "|      layer1.2.bn2.bias       |     16     |\n",
            "|    layer1.3.conv1.weight     |    2304    |\n",
            "|     layer1.3.bn1.weight      |     16     |\n",
            "|      layer1.3.bn1.bias       |     16     |\n",
            "|    layer1.3.conv2.weight     |    2304    |\n",
            "|     layer1.3.bn2.weight      |     16     |\n",
            "|      layer1.3.bn2.bias       |     16     |\n",
            "|    layer1.4.conv1.weight     |    2304    |\n",
            "|     layer1.4.bn1.weight      |     16     |\n",
            "|      layer1.4.bn1.bias       |     16     |\n",
            "|    layer1.4.conv2.weight     |    2304    |\n",
            "|     layer1.4.bn2.weight      |     16     |\n",
            "|      layer1.4.bn2.bias       |     16     |\n",
            "|    layer1.5.conv1.weight     |    2304    |\n",
            "|     layer1.5.bn1.weight      |     16     |\n",
            "|      layer1.5.bn1.bias       |     16     |\n",
            "|    layer1.5.conv2.weight     |    2304    |\n",
            "|     layer1.5.bn2.weight      |     16     |\n",
            "|      layer1.5.bn2.bias       |     16     |\n",
            "|    layer1.6.conv1.weight     |    2304    |\n",
            "|     layer1.6.bn1.weight      |     16     |\n",
            "|      layer1.6.bn1.bias       |     16     |\n",
            "|    layer1.6.conv2.weight     |    2304    |\n",
            "|     layer1.6.bn2.weight      |     16     |\n",
            "|      layer1.6.bn2.bias       |     16     |\n",
            "|    layer1.7.conv1.weight     |    2304    |\n",
            "|     layer1.7.bn1.weight      |     16     |\n",
            "|      layer1.7.bn1.bias       |     16     |\n",
            "|    layer1.7.conv2.weight     |    2304    |\n",
            "|     layer1.7.bn2.weight      |     16     |\n",
            "|      layer1.7.bn2.bias       |     16     |\n",
            "|    layer1.8.conv1.weight     |    2304    |\n",
            "|     layer1.8.bn1.weight      |     16     |\n",
            "|      layer1.8.bn1.bias       |     16     |\n",
            "|    layer1.8.conv2.weight     |    2304    |\n",
            "|     layer1.8.bn2.weight      |     16     |\n",
            "|      layer1.8.bn2.bias       |     16     |\n",
            "|    layer1.9.conv1.weight     |    2304    |\n",
            "|     layer1.9.bn1.weight      |     16     |\n",
            "|      layer1.9.bn1.bias       |     16     |\n",
            "|    layer1.9.conv2.weight     |    2304    |\n",
            "|     layer1.9.bn2.weight      |     16     |\n",
            "|      layer1.9.bn2.bias       |     16     |\n",
            "|    layer1.10.conv1.weight    |    2304    |\n",
            "|     layer1.10.bn1.weight     |     16     |\n",
            "|      layer1.10.bn1.bias      |     16     |\n",
            "|    layer1.10.conv2.weight    |    2304    |\n",
            "|     layer1.10.bn2.weight     |     16     |\n",
            "|      layer1.10.bn2.bias      |     16     |\n",
            "|    layer1.11.conv1.weight    |    2304    |\n",
            "|     layer1.11.bn1.weight     |     16     |\n",
            "|      layer1.11.bn1.bias      |     16     |\n",
            "|    layer1.11.conv2.weight    |    2304    |\n",
            "|     layer1.11.bn2.weight     |     16     |\n",
            "|      layer1.11.bn2.bias      |     16     |\n",
            "|    layer1.12.conv1.weight    |    2304    |\n",
            "|     layer1.12.bn1.weight     |     16     |\n",
            "|      layer1.12.bn1.bias      |     16     |\n",
            "|    layer1.12.conv2.weight    |    2304    |\n",
            "|     layer1.12.bn2.weight     |     16     |\n",
            "|      layer1.12.bn2.bias      |     16     |\n",
            "|    layer1.13.conv1.weight    |    2304    |\n",
            "|     layer1.13.bn1.weight     |     16     |\n",
            "|      layer1.13.bn1.bias      |     16     |\n",
            "|    layer1.13.conv2.weight    |    2304    |\n",
            "|     layer1.13.bn2.weight     |     16     |\n",
            "|      layer1.13.bn2.bias      |     16     |\n",
            "|    layer1.14.conv1.weight    |    2304    |\n",
            "|     layer1.14.bn1.weight     |     16     |\n",
            "|      layer1.14.bn1.bias      |     16     |\n",
            "|    layer1.14.conv2.weight    |    2304    |\n",
            "|     layer1.14.bn2.weight     |     16     |\n",
            "|      layer1.14.bn2.bias      |     16     |\n",
            "|    layer1.15.conv1.weight    |    2304    |\n",
            "|     layer1.15.bn1.weight     |     16     |\n",
            "|      layer1.15.bn1.bias      |     16     |\n",
            "|    layer1.15.conv2.weight    |    2304    |\n",
            "|     layer1.15.bn2.weight     |     16     |\n",
            "|      layer1.15.bn2.bias      |     16     |\n",
            "|    layer1.16.conv1.weight    |    2304    |\n",
            "|     layer1.16.bn1.weight     |     16     |\n",
            "|      layer1.16.bn1.bias      |     16     |\n",
            "|    layer1.16.conv2.weight    |    2304    |\n",
            "|     layer1.16.bn2.weight     |     16     |\n",
            "|      layer1.16.bn2.bias      |     16     |\n",
            "|    layer1.17.conv1.weight    |    2304    |\n",
            "|     layer1.17.bn1.weight     |     16     |\n",
            "|      layer1.17.bn1.bias      |     16     |\n",
            "|    layer1.17.conv2.weight    |    2304    |\n",
            "|     layer1.17.bn2.weight     |     16     |\n",
            "|      layer1.17.bn2.bias      |     16     |\n",
            "|    layer1.18.conv1.weight    |    2304    |\n",
            "|     layer1.18.bn1.weight     |     16     |\n",
            "|      layer1.18.bn1.bias      |     16     |\n",
            "|    layer1.18.conv2.weight    |    2304    |\n",
            "|     layer1.18.bn2.weight     |     16     |\n",
            "|      layer1.18.bn2.bias      |     16     |\n",
            "|    layer2.0.conv1.weight     |    4608    |\n",
            "|     layer2.0.bn1.weight      |     32     |\n",
            "|      layer2.0.bn1.bias       |     32     |\n",
            "|    layer2.0.conv2.weight     |    9216    |\n",
            "|     layer2.0.bn2.weight      |     32     |\n",
            "|      layer2.0.bn2.bias       |     32     |\n",
            "| layer2.0.downsample.0.weight |    4608    |\n",
            "| layer2.0.downsample.1.weight |     32     |\n",
            "|  layer2.0.downsample.1.bias  |     32     |\n",
            "|    layer2.1.conv1.weight     |    9216    |\n",
            "|     layer2.1.bn1.weight      |     32     |\n",
            "|      layer2.1.bn1.bias       |     32     |\n",
            "|    layer2.1.conv2.weight     |    9216    |\n",
            "|     layer2.1.bn2.weight      |     32     |\n",
            "|      layer2.1.bn2.bias       |     32     |\n",
            "|    layer2.2.conv1.weight     |    9216    |\n",
            "|     layer2.2.bn1.weight      |     32     |\n",
            "|      layer2.2.bn1.bias       |     32     |\n",
            "|    layer2.2.conv2.weight     |    9216    |\n",
            "|     layer2.2.bn2.weight      |     32     |\n",
            "|      layer2.2.bn2.bias       |     32     |\n",
            "|    layer2.3.conv1.weight     |    9216    |\n",
            "|     layer2.3.bn1.weight      |     32     |\n",
            "|      layer2.3.bn1.bias       |     32     |\n",
            "|    layer2.3.conv2.weight     |    9216    |\n",
            "|     layer2.3.bn2.weight      |     32     |\n",
            "|      layer2.3.bn2.bias       |     32     |\n",
            "|    layer2.4.conv1.weight     |    9216    |\n",
            "|     layer2.4.bn1.weight      |     32     |\n",
            "|      layer2.4.bn1.bias       |     32     |\n",
            "|    layer2.4.conv2.weight     |    9216    |\n",
            "|     layer2.4.bn2.weight      |     32     |\n",
            "|      layer2.4.bn2.bias       |     32     |\n",
            "|    layer2.5.conv1.weight     |    9216    |\n",
            "|     layer2.5.bn1.weight      |     32     |\n",
            "|      layer2.5.bn1.bias       |     32     |\n",
            "|    layer2.5.conv2.weight     |    9216    |\n",
            "|     layer2.5.bn2.weight      |     32     |\n",
            "|      layer2.5.bn2.bias       |     32     |\n",
            "|    layer2.6.conv1.weight     |    9216    |\n",
            "|     layer2.6.bn1.weight      |     32     |\n",
            "|      layer2.6.bn1.bias       |     32     |\n",
            "|    layer2.6.conv2.weight     |    9216    |\n",
            "|     layer2.6.bn2.weight      |     32     |\n",
            "|      layer2.6.bn2.bias       |     32     |\n",
            "|    layer2.7.conv1.weight     |    9216    |\n",
            "|     layer2.7.bn1.weight      |     32     |\n",
            "|      layer2.7.bn1.bias       |     32     |\n",
            "|    layer2.7.conv2.weight     |    9216    |\n",
            "|     layer2.7.bn2.weight      |     32     |\n",
            "|      layer2.7.bn2.bias       |     32     |\n",
            "|    layer2.8.conv1.weight     |    9216    |\n",
            "|     layer2.8.bn1.weight      |     32     |\n",
            "|      layer2.8.bn1.bias       |     32     |\n",
            "|    layer2.8.conv2.weight     |    9216    |\n",
            "|     layer2.8.bn2.weight      |     32     |\n",
            "|      layer2.8.bn2.bias       |     32     |\n",
            "|    layer2.9.conv1.weight     |    9216    |\n",
            "|     layer2.9.bn1.weight      |     32     |\n",
            "|      layer2.9.bn1.bias       |     32     |\n",
            "|    layer2.9.conv2.weight     |    9216    |\n",
            "|     layer2.9.bn2.weight      |     32     |\n",
            "|      layer2.9.bn2.bias       |     32     |\n",
            "|    layer2.10.conv1.weight    |    9216    |\n",
            "|     layer2.10.bn1.weight     |     32     |\n",
            "|      layer2.10.bn1.bias      |     32     |\n",
            "|    layer2.10.conv2.weight    |    9216    |\n",
            "|     layer2.10.bn2.weight     |     32     |\n",
            "|      layer2.10.bn2.bias      |     32     |\n",
            "|    layer2.11.conv1.weight    |    9216    |\n",
            "|     layer2.11.bn1.weight     |     32     |\n",
            "|      layer2.11.bn1.bias      |     32     |\n",
            "|    layer2.11.conv2.weight    |    9216    |\n",
            "|     layer2.11.bn2.weight     |     32     |\n",
            "|      layer2.11.bn2.bias      |     32     |\n",
            "|    layer2.12.conv1.weight    |    9216    |\n",
            "|     layer2.12.bn1.weight     |     32     |\n",
            "|      layer2.12.bn1.bias      |     32     |\n",
            "|    layer2.12.conv2.weight    |    9216    |\n",
            "|     layer2.12.bn2.weight     |     32     |\n",
            "|      layer2.12.bn2.bias      |     32     |\n",
            "|    layer2.13.conv1.weight    |    9216    |\n",
            "|     layer2.13.bn1.weight     |     32     |\n",
            "|      layer2.13.bn1.bias      |     32     |\n",
            "|    layer2.13.conv2.weight    |    9216    |\n",
            "|     layer2.13.bn2.weight     |     32     |\n",
            "|      layer2.13.bn2.bias      |     32     |\n",
            "|    layer2.14.conv1.weight    |    9216    |\n",
            "|     layer2.14.bn1.weight     |     32     |\n",
            "|      layer2.14.bn1.bias      |     32     |\n",
            "|    layer2.14.conv2.weight    |    9216    |\n",
            "|     layer2.14.bn2.weight     |     32     |\n",
            "|      layer2.14.bn2.bias      |     32     |\n",
            "|    layer2.15.conv1.weight    |    9216    |\n",
            "|     layer2.15.bn1.weight     |     32     |\n",
            "|      layer2.15.bn1.bias      |     32     |\n",
            "|    layer2.15.conv2.weight    |    9216    |\n",
            "|     layer2.15.bn2.weight     |     32     |\n",
            "|      layer2.15.bn2.bias      |     32     |\n",
            "|    layer2.16.conv1.weight    |    9216    |\n",
            "|     layer2.16.bn1.weight     |     32     |\n",
            "|      layer2.16.bn1.bias      |     32     |\n",
            "|    layer2.16.conv2.weight    |    9216    |\n",
            "|     layer2.16.bn2.weight     |     32     |\n",
            "|      layer2.16.bn2.bias      |     32     |\n",
            "|    layer2.17.conv1.weight    |    9216    |\n",
            "|     layer2.17.bn1.weight     |     32     |\n",
            "|      layer2.17.bn1.bias      |     32     |\n",
            "|    layer2.17.conv2.weight    |    9216    |\n",
            "|     layer2.17.bn2.weight     |     32     |\n",
            "|      layer2.17.bn2.bias      |     32     |\n",
            "|    layer2.18.conv1.weight    |    9216    |\n",
            "|     layer2.18.bn1.weight     |     32     |\n",
            "|      layer2.18.bn1.bias      |     32     |\n",
            "|    layer2.18.conv2.weight    |    9216    |\n",
            "|     layer2.18.bn2.weight     |     32     |\n",
            "|      layer2.18.bn2.bias      |     32     |\n",
            "|    layer3.0.conv1.weight     |   18432    |\n",
            "|     layer3.0.bn1.weight      |     64     |\n",
            "|      layer3.0.bn1.bias       |     64     |\n",
            "|    layer3.0.conv2.weight     |   36864    |\n",
            "|     layer3.0.bn2.weight      |     64     |\n",
            "|      layer3.0.bn2.bias       |     64     |\n",
            "| layer3.0.downsample.0.weight |   18432    |\n",
            "| layer3.0.downsample.1.weight |     64     |\n",
            "|  layer3.0.downsample.1.bias  |     64     |\n",
            "|    layer3.1.conv1.weight     |   36864    |\n",
            "|     layer3.1.bn1.weight      |     64     |\n",
            "|      layer3.1.bn1.bias       |     64     |\n",
            "|    layer3.1.conv2.weight     |   36864    |\n",
            "|     layer3.1.bn2.weight      |     64     |\n",
            "|      layer3.1.bn2.bias       |     64     |\n",
            "|    layer3.2.conv1.weight     |   36864    |\n",
            "|     layer3.2.bn1.weight      |     64     |\n",
            "|      layer3.2.bn1.bias       |     64     |\n",
            "|    layer3.2.conv2.weight     |   36864    |\n",
            "|     layer3.2.bn2.weight      |     64     |\n",
            "|      layer3.2.bn2.bias       |     64     |\n",
            "|    layer3.3.conv1.weight     |   36864    |\n",
            "|     layer3.3.bn1.weight      |     64     |\n",
            "|      layer3.3.bn1.bias       |     64     |\n",
            "|    layer3.3.conv2.weight     |   36864    |\n",
            "|     layer3.3.bn2.weight      |     64     |\n",
            "|      layer3.3.bn2.bias       |     64     |\n",
            "|    layer3.4.conv1.weight     |   36864    |\n",
            "|     layer3.4.bn1.weight      |     64     |\n",
            "|      layer3.4.bn1.bias       |     64     |\n",
            "|    layer3.4.conv2.weight     |   36864    |\n",
            "|     layer3.4.bn2.weight      |     64     |\n",
            "|      layer3.4.bn2.bias       |     64     |\n",
            "|    layer3.5.conv1.weight     |   36864    |\n",
            "|     layer3.5.bn1.weight      |     64     |\n",
            "|      layer3.5.bn1.bias       |     64     |\n",
            "|    layer3.5.conv2.weight     |   36864    |\n",
            "|     layer3.5.bn2.weight      |     64     |\n",
            "|      layer3.5.bn2.bias       |     64     |\n",
            "|    layer3.6.conv1.weight     |   36864    |\n",
            "|     layer3.6.bn1.weight      |     64     |\n",
            "|      layer3.6.bn1.bias       |     64     |\n",
            "|    layer3.6.conv2.weight     |   36864    |\n",
            "|     layer3.6.bn2.weight      |     64     |\n",
            "|      layer3.6.bn2.bias       |     64     |\n",
            "|    layer3.7.conv1.weight     |   36864    |\n",
            "|     layer3.7.bn1.weight      |     64     |\n",
            "|      layer3.7.bn1.bias       |     64     |\n",
            "|    layer3.7.conv2.weight     |   36864    |\n",
            "|     layer3.7.bn2.weight      |     64     |\n",
            "|      layer3.7.bn2.bias       |     64     |\n",
            "|    layer3.8.conv1.weight     |   36864    |\n",
            "|     layer3.8.bn1.weight      |     64     |\n",
            "|      layer3.8.bn1.bias       |     64     |\n",
            "|    layer3.8.conv2.weight     |   36864    |\n",
            "|     layer3.8.bn2.weight      |     64     |\n",
            "|      layer3.8.bn2.bias       |     64     |\n",
            "|    layer3.9.conv1.weight     |   36864    |\n",
            "|     layer3.9.bn1.weight      |     64     |\n",
            "|      layer3.9.bn1.bias       |     64     |\n",
            "|    layer3.9.conv2.weight     |   36864    |\n",
            "|     layer3.9.bn2.weight      |     64     |\n",
            "|      layer3.9.bn2.bias       |     64     |\n",
            "|    layer3.10.conv1.weight    |   36864    |\n",
            "|     layer3.10.bn1.weight     |     64     |\n",
            "|      layer3.10.bn1.bias      |     64     |\n",
            "|    layer3.10.conv2.weight    |   36864    |\n",
            "|     layer3.10.bn2.weight     |     64     |\n",
            "|      layer3.10.bn2.bias      |     64     |\n",
            "|    layer3.11.conv1.weight    |   36864    |\n",
            "|     layer3.11.bn1.weight     |     64     |\n",
            "|      layer3.11.bn1.bias      |     64     |\n",
            "|    layer3.11.conv2.weight    |   36864    |\n",
            "|     layer3.11.bn2.weight     |     64     |\n",
            "|      layer3.11.bn2.bias      |     64     |\n",
            "|    layer3.12.conv1.weight    |   36864    |\n",
            "|     layer3.12.bn1.weight     |     64     |\n",
            "|      layer3.12.bn1.bias      |     64     |\n",
            "|    layer3.12.conv2.weight    |   36864    |\n",
            "|     layer3.12.bn2.weight     |     64     |\n",
            "|      layer3.12.bn2.bias      |     64     |\n",
            "|    layer3.13.conv1.weight    |   36864    |\n",
            "|     layer3.13.bn1.weight     |     64     |\n",
            "|      layer3.13.bn1.bias      |     64     |\n",
            "|    layer3.13.conv2.weight    |   36864    |\n",
            "|     layer3.13.bn2.weight     |     64     |\n",
            "|      layer3.13.bn2.bias      |     64     |\n",
            "|    layer3.14.conv1.weight    |   36864    |\n",
            "|     layer3.14.bn1.weight     |     64     |\n",
            "|      layer3.14.bn1.bias      |     64     |\n",
            "|    layer3.14.conv2.weight    |   36864    |\n",
            "|     layer3.14.bn2.weight     |     64     |\n",
            "|      layer3.14.bn2.bias      |     64     |\n",
            "|    layer3.15.conv1.weight    |   36864    |\n",
            "|     layer3.15.bn1.weight     |     64     |\n",
            "|      layer3.15.bn1.bias      |     64     |\n",
            "|    layer3.15.conv2.weight    |   36864    |\n",
            "|     layer3.15.bn2.weight     |     64     |\n",
            "|      layer3.15.bn2.bias      |     64     |\n",
            "|    layer3.16.conv1.weight    |   36864    |\n",
            "|     layer3.16.bn1.weight     |     64     |\n",
            "|      layer3.16.bn1.bias      |     64     |\n",
            "|    layer3.16.conv2.weight    |   36864    |\n",
            "|     layer3.16.bn2.weight     |     64     |\n",
            "|      layer3.16.bn2.bias      |     64     |\n",
            "|    layer3.17.conv1.weight    |   36864    |\n",
            "|     layer3.17.bn1.weight     |     64     |\n",
            "|      layer3.17.bn1.bias      |     64     |\n",
            "|    layer3.17.conv2.weight    |   36864    |\n",
            "|     layer3.17.bn2.weight     |     64     |\n",
            "|      layer3.17.bn2.bias      |     64     |\n",
            "|    layer3.18.conv1.weight    |   36864    |\n",
            "|     layer3.18.bn1.weight     |     64     |\n",
            "|      layer3.18.bn1.bias      |     64     |\n",
            "|    layer3.18.conv2.weight    |   36864    |\n",
            "|     layer3.18.bn2.weight     |     64     |\n",
            "|      layer3.18.bn2.bias      |     64     |\n",
            "|          fc.weight           |    640     |\n",
            "|           fc.bias            |     10     |\n",
            "+------------------------------+------------+\n",
            "Total Trainable Params: 1848410\n",
            "+------------------------------+------------+\n",
            "|           Modules            | Parameters |\n",
            "+------------------------------+------------+\n",
            "|         conv.weight          |    432     |\n",
            "|          bn.weight           |     16     |\n",
            "|           bn.bias            |     16     |\n",
            "|    layer1.0.conv1.weight     |    2304    |\n",
            "|     layer1.0.bn1.weight      |     16     |\n",
            "|      layer1.0.bn1.bias       |     16     |\n",
            "|    layer1.0.conv2.weight     |    2304    |\n",
            "|     layer1.0.bn2.weight      |     16     |\n",
            "|      layer1.0.bn2.bias       |     16     |\n",
            "|    layer1.1.conv1.weight     |    2304    |\n",
            "|     layer1.1.bn1.weight      |     16     |\n",
            "|      layer1.1.bn1.bias       |     16     |\n",
            "|    layer1.1.conv2.weight     |    2304    |\n",
            "|     layer1.1.bn2.weight      |     16     |\n",
            "|      layer1.1.bn2.bias       |     16     |\n",
            "|    layer1.2.conv1.weight     |    2304    |\n",
            "|     layer1.2.bn1.weight      |     16     |\n",
            "|      layer1.2.bn1.bias       |     16     |\n",
            "|    layer1.2.conv2.weight     |    2304    |\n",
            "|     layer1.2.bn2.weight      |     16     |\n",
            "|      layer1.2.bn2.bias       |     16     |\n",
            "|    layer1.3.conv1.weight     |    2304    |\n",
            "|     layer1.3.bn1.weight      |     16     |\n",
            "|      layer1.3.bn1.bias       |     16     |\n",
            "|    layer1.3.conv2.weight     |    2304    |\n",
            "|     layer1.3.bn2.weight      |     16     |\n",
            "|      layer1.3.bn2.bias       |     16     |\n",
            "|    layer1.4.conv1.weight     |    2304    |\n",
            "|     layer1.4.bn1.weight      |     16     |\n",
            "|      layer1.4.bn1.bias       |     16     |\n",
            "|    layer1.4.conv2.weight     |    2304    |\n",
            "|     layer1.4.bn2.weight      |     16     |\n",
            "|      layer1.4.bn2.bias       |     16     |\n",
            "|    layer1.5.conv1.weight     |    2304    |\n",
            "|     layer1.5.bn1.weight      |     16     |\n",
            "|      layer1.5.bn1.bias       |     16     |\n",
            "|    layer1.5.conv2.weight     |    2304    |\n",
            "|     layer1.5.bn2.weight      |     16     |\n",
            "|      layer1.5.bn2.bias       |     16     |\n",
            "|    layer1.6.conv1.weight     |    2304    |\n",
            "|     layer1.6.bn1.weight      |     16     |\n",
            "|      layer1.6.bn1.bias       |     16     |\n",
            "|    layer1.6.conv2.weight     |    2304    |\n",
            "|     layer1.6.bn2.weight      |     16     |\n",
            "|      layer1.6.bn2.bias       |     16     |\n",
            "|    layer1.7.conv1.weight     |    2304    |\n",
            "|     layer1.7.bn1.weight      |     16     |\n",
            "|      layer1.7.bn1.bias       |     16     |\n",
            "|    layer1.7.conv2.weight     |    2304    |\n",
            "|     layer1.7.bn2.weight      |     16     |\n",
            "|      layer1.7.bn2.bias       |     16     |\n",
            "|    layer1.8.conv1.weight     |    2304    |\n",
            "|     layer1.8.bn1.weight      |     16     |\n",
            "|      layer1.8.bn1.bias       |     16     |\n",
            "|    layer1.8.conv2.weight     |    2304    |\n",
            "|     layer1.8.bn2.weight      |     16     |\n",
            "|      layer1.8.bn2.bias       |     16     |\n",
            "|    layer1.9.conv1.weight     |    2304    |\n",
            "|     layer1.9.bn1.weight      |     16     |\n",
            "|      layer1.9.bn1.bias       |     16     |\n",
            "|    layer1.9.conv2.weight     |    2304    |\n",
            "|     layer1.9.bn2.weight      |     16     |\n",
            "|      layer1.9.bn2.bias       |     16     |\n",
            "|    layer1.10.conv1.weight    |    2304    |\n",
            "|     layer1.10.bn1.weight     |     16     |\n",
            "|      layer1.10.bn1.bias      |     16     |\n",
            "|    layer1.10.conv2.weight    |    2304    |\n",
            "|     layer1.10.bn2.weight     |     16     |\n",
            "|      layer1.10.bn2.bias      |     16     |\n",
            "|    layer1.11.conv1.weight    |    2304    |\n",
            "|     layer1.11.bn1.weight     |     16     |\n",
            "|      layer1.11.bn1.bias      |     16     |\n",
            "|    layer1.11.conv2.weight    |    2304    |\n",
            "|     layer1.11.bn2.weight     |     16     |\n",
            "|      layer1.11.bn2.bias      |     16     |\n",
            "|    layer1.12.conv1.weight    |    2304    |\n",
            "|     layer1.12.bn1.weight     |     16     |\n",
            "|      layer1.12.bn1.bias      |     16     |\n",
            "|    layer1.12.conv2.weight    |    2304    |\n",
            "|     layer1.12.bn2.weight     |     16     |\n",
            "|      layer1.12.bn2.bias      |     16     |\n",
            "|    layer1.13.conv1.weight    |    2304    |\n",
            "|     layer1.13.bn1.weight     |     16     |\n",
            "|      layer1.13.bn1.bias      |     16     |\n",
            "|    layer1.13.conv2.weight    |    2304    |\n",
            "|     layer1.13.bn2.weight     |     16     |\n",
            "|      layer1.13.bn2.bias      |     16     |\n",
            "|    layer1.14.conv1.weight    |    2304    |\n",
            "|     layer1.14.bn1.weight     |     16     |\n",
            "|      layer1.14.bn1.bias      |     16     |\n",
            "|    layer1.14.conv2.weight    |    2304    |\n",
            "|     layer1.14.bn2.weight     |     16     |\n",
            "|      layer1.14.bn2.bias      |     16     |\n",
            "|    layer1.15.conv1.weight    |    2304    |\n",
            "|     layer1.15.bn1.weight     |     16     |\n",
            "|      layer1.15.bn1.bias      |     16     |\n",
            "|    layer1.15.conv2.weight    |    2304    |\n",
            "|     layer1.15.bn2.weight     |     16     |\n",
            "|      layer1.15.bn2.bias      |     16     |\n",
            "|    layer1.16.conv1.weight    |    2304    |\n",
            "|     layer1.16.bn1.weight     |     16     |\n",
            "|      layer1.16.bn1.bias      |     16     |\n",
            "|    layer1.16.conv2.weight    |    2304    |\n",
            "|     layer1.16.bn2.weight     |     16     |\n",
            "|      layer1.16.bn2.bias      |     16     |\n",
            "|    layer1.17.conv1.weight    |    2304    |\n",
            "|     layer1.17.bn1.weight     |     16     |\n",
            "|      layer1.17.bn1.bias      |     16     |\n",
            "|    layer1.17.conv2.weight    |    2304    |\n",
            "|     layer1.17.bn2.weight     |     16     |\n",
            "|      layer1.17.bn2.bias      |     16     |\n",
            "|    layer1.18.conv1.weight    |    2304    |\n",
            "|     layer1.18.bn1.weight     |     16     |\n",
            "|      layer1.18.bn1.bias      |     16     |\n",
            "|    layer1.18.conv2.weight    |    2304    |\n",
            "|     layer1.18.bn2.weight     |     16     |\n",
            "|      layer1.18.bn2.bias      |     16     |\n",
            "|    layer1.19.conv1.weight    |    2304    |\n",
            "|     layer1.19.bn1.weight     |     16     |\n",
            "|      layer1.19.bn1.bias      |     16     |\n",
            "|    layer1.19.conv2.weight    |    2304    |\n",
            "|     layer1.19.bn2.weight     |     16     |\n",
            "|      layer1.19.bn2.bias      |     16     |\n",
            "|    layer1.20.conv1.weight    |    2304    |\n",
            "|     layer1.20.bn1.weight     |     16     |\n",
            "|      layer1.20.bn1.bias      |     16     |\n",
            "|    layer1.20.conv2.weight    |    2304    |\n",
            "|     layer1.20.bn2.weight     |     16     |\n",
            "|      layer1.20.bn2.bias      |     16     |\n",
            "|    layer1.21.conv1.weight    |    2304    |\n",
            "|     layer1.21.bn1.weight     |     16     |\n",
            "|      layer1.21.bn1.bias      |     16     |\n",
            "|    layer1.21.conv2.weight    |    2304    |\n",
            "|     layer1.21.bn2.weight     |     16     |\n",
            "|      layer1.21.bn2.bias      |     16     |\n",
            "|    layer1.22.conv1.weight    |    2304    |\n",
            "|     layer1.22.bn1.weight     |     16     |\n",
            "|      layer1.22.bn1.bias      |     16     |\n",
            "|    layer1.22.conv2.weight    |    2304    |\n",
            "|     layer1.22.bn2.weight     |     16     |\n",
            "|      layer1.22.bn2.bias      |     16     |\n",
            "|    layer1.23.conv1.weight    |    2304    |\n",
            "|     layer1.23.bn1.weight     |     16     |\n",
            "|      layer1.23.bn1.bias      |     16     |\n",
            "|    layer1.23.conv2.weight    |    2304    |\n",
            "|     layer1.23.bn2.weight     |     16     |\n",
            "|      layer1.23.bn2.bias      |     16     |\n",
            "|    layer1.24.conv1.weight    |    2304    |\n",
            "|     layer1.24.bn1.weight     |     16     |\n",
            "|      layer1.24.bn1.bias      |     16     |\n",
            "|    layer1.24.conv2.weight    |    2304    |\n",
            "|     layer1.24.bn2.weight     |     16     |\n",
            "|      layer1.24.bn2.bias      |     16     |\n",
            "|    layer1.25.conv1.weight    |    2304    |\n",
            "|     layer1.25.bn1.weight     |     16     |\n",
            "|      layer1.25.bn1.bias      |     16     |\n",
            "|    layer1.25.conv2.weight    |    2304    |\n",
            "|     layer1.25.bn2.weight     |     16     |\n",
            "|      layer1.25.bn2.bias      |     16     |\n",
            "|    layer1.26.conv1.weight    |    2304    |\n",
            "|     layer1.26.bn1.weight     |     16     |\n",
            "|      layer1.26.bn1.bias      |     16     |\n",
            "|    layer1.26.conv2.weight    |    2304    |\n",
            "|     layer1.26.bn2.weight     |     16     |\n",
            "|      layer1.26.bn2.bias      |     16     |\n",
            "|    layer1.27.conv1.weight    |    2304    |\n",
            "|     layer1.27.bn1.weight     |     16     |\n",
            "|      layer1.27.bn1.bias      |     16     |\n",
            "|    layer1.27.conv2.weight    |    2304    |\n",
            "|     layer1.27.bn2.weight     |     16     |\n",
            "|      layer1.27.bn2.bias      |     16     |\n",
            "|    layer1.28.conv1.weight    |    2304    |\n",
            "|     layer1.28.bn1.weight     |     16     |\n",
            "|      layer1.28.bn1.bias      |     16     |\n",
            "|    layer1.28.conv2.weight    |    2304    |\n",
            "|     layer1.28.bn2.weight     |     16     |\n",
            "|      layer1.28.bn2.bias      |     16     |\n",
            "|    layer1.29.conv1.weight    |    2304    |\n",
            "|     layer1.29.bn1.weight     |     16     |\n",
            "|      layer1.29.bn1.bias      |     16     |\n",
            "|    layer1.29.conv2.weight    |    2304    |\n",
            "|     layer1.29.bn2.weight     |     16     |\n",
            "|      layer1.29.bn2.bias      |     16     |\n",
            "|    layer1.30.conv1.weight    |    2304    |\n",
            "|     layer1.30.bn1.weight     |     16     |\n",
            "|      layer1.30.bn1.bias      |     16     |\n",
            "|    layer1.30.conv2.weight    |    2304    |\n",
            "|     layer1.30.bn2.weight     |     16     |\n",
            "|      layer1.30.bn2.bias      |     16     |\n",
            "|    layer2.0.conv1.weight     |    4608    |\n",
            "|     layer2.0.bn1.weight      |     32     |\n",
            "|      layer2.0.bn1.bias       |     32     |\n",
            "|    layer2.0.conv2.weight     |    9216    |\n",
            "|     layer2.0.bn2.weight      |     32     |\n",
            "|      layer2.0.bn2.bias       |     32     |\n",
            "| layer2.0.downsample.0.weight |    4608    |\n",
            "| layer2.0.downsample.1.weight |     32     |\n",
            "|  layer2.0.downsample.1.bias  |     32     |\n",
            "|    layer2.1.conv1.weight     |    9216    |\n",
            "|     layer2.1.bn1.weight      |     32     |\n",
            "|      layer2.1.bn1.bias       |     32     |\n",
            "|    layer2.1.conv2.weight     |    9216    |\n",
            "|     layer2.1.bn2.weight      |     32     |\n",
            "|      layer2.1.bn2.bias       |     32     |\n",
            "|    layer2.2.conv1.weight     |    9216    |\n",
            "|     layer2.2.bn1.weight      |     32     |\n",
            "|      layer2.2.bn1.bias       |     32     |\n",
            "|    layer2.2.conv2.weight     |    9216    |\n",
            "|     layer2.2.bn2.weight      |     32     |\n",
            "|      layer2.2.bn2.bias       |     32     |\n",
            "|    layer2.3.conv1.weight     |    9216    |\n",
            "|     layer2.3.bn1.weight      |     32     |\n",
            "|      layer2.3.bn1.bias       |     32     |\n",
            "|    layer2.3.conv2.weight     |    9216    |\n",
            "|     layer2.3.bn2.weight      |     32     |\n",
            "|      layer2.3.bn2.bias       |     32     |\n",
            "|    layer2.4.conv1.weight     |    9216    |\n",
            "|     layer2.4.bn1.weight      |     32     |\n",
            "|      layer2.4.bn1.bias       |     32     |\n",
            "|    layer2.4.conv2.weight     |    9216    |\n",
            "|     layer2.4.bn2.weight      |     32     |\n",
            "|      layer2.4.bn2.bias       |     32     |\n",
            "|    layer2.5.conv1.weight     |    9216    |\n",
            "|     layer2.5.bn1.weight      |     32     |\n",
            "|      layer2.5.bn1.bias       |     32     |\n",
            "|    layer2.5.conv2.weight     |    9216    |\n",
            "|     layer2.5.bn2.weight      |     32     |\n",
            "|      layer2.5.bn2.bias       |     32     |\n",
            "|    layer2.6.conv1.weight     |    9216    |\n",
            "|     layer2.6.bn1.weight      |     32     |\n",
            "|      layer2.6.bn1.bias       |     32     |\n",
            "|    layer2.6.conv2.weight     |    9216    |\n",
            "|     layer2.6.bn2.weight      |     32     |\n",
            "|      layer2.6.bn2.bias       |     32     |\n",
            "|    layer2.7.conv1.weight     |    9216    |\n",
            "|     layer2.7.bn1.weight      |     32     |\n",
            "|      layer2.7.bn1.bias       |     32     |\n",
            "|    layer2.7.conv2.weight     |    9216    |\n",
            "|     layer2.7.bn2.weight      |     32     |\n",
            "|      layer2.7.bn2.bias       |     32     |\n",
            "|    layer2.8.conv1.weight     |    9216    |\n",
            "|     layer2.8.bn1.weight      |     32     |\n",
            "|      layer2.8.bn1.bias       |     32     |\n",
            "|    layer2.8.conv2.weight     |    9216    |\n",
            "|     layer2.8.bn2.weight      |     32     |\n",
            "|      layer2.8.bn2.bias       |     32     |\n",
            "|    layer2.9.conv1.weight     |    9216    |\n",
            "|     layer2.9.bn1.weight      |     32     |\n",
            "|      layer2.9.bn1.bias       |     32     |\n",
            "|    layer2.9.conv2.weight     |    9216    |\n",
            "|     layer2.9.bn2.weight      |     32     |\n",
            "|      layer2.9.bn2.bias       |     32     |\n",
            "|    layer2.10.conv1.weight    |    9216    |\n",
            "|     layer2.10.bn1.weight     |     32     |\n",
            "|      layer2.10.bn1.bias      |     32     |\n",
            "|    layer2.10.conv2.weight    |    9216    |\n",
            "|     layer2.10.bn2.weight     |     32     |\n",
            "|      layer2.10.bn2.bias      |     32     |\n",
            "|    layer2.11.conv1.weight    |    9216    |\n",
            "|     layer2.11.bn1.weight     |     32     |\n",
            "|      layer2.11.bn1.bias      |     32     |\n",
            "|    layer2.11.conv2.weight    |    9216    |\n",
            "|     layer2.11.bn2.weight     |     32     |\n",
            "|      layer2.11.bn2.bias      |     32     |\n",
            "|    layer2.12.conv1.weight    |    9216    |\n",
            "|     layer2.12.bn1.weight     |     32     |\n",
            "|      layer2.12.bn1.bias      |     32     |\n",
            "|    layer2.12.conv2.weight    |    9216    |\n",
            "|     layer2.12.bn2.weight     |     32     |\n",
            "|      layer2.12.bn2.bias      |     32     |\n",
            "|    layer2.13.conv1.weight    |    9216    |\n",
            "|     layer2.13.bn1.weight     |     32     |\n",
            "|      layer2.13.bn1.bias      |     32     |\n",
            "|    layer2.13.conv2.weight    |    9216    |\n",
            "|     layer2.13.bn2.weight     |     32     |\n",
            "|      layer2.13.bn2.bias      |     32     |\n",
            "|    layer2.14.conv1.weight    |    9216    |\n",
            "|     layer2.14.bn1.weight     |     32     |\n",
            "|      layer2.14.bn1.bias      |     32     |\n",
            "|    layer2.14.conv2.weight    |    9216    |\n",
            "|     layer2.14.bn2.weight     |     32     |\n",
            "|      layer2.14.bn2.bias      |     32     |\n",
            "|    layer2.15.conv1.weight    |    9216    |\n",
            "|     layer2.15.bn1.weight     |     32     |\n",
            "|      layer2.15.bn1.bias      |     32     |\n",
            "|    layer2.15.conv2.weight    |    9216    |\n",
            "|     layer2.15.bn2.weight     |     32     |\n",
            "|      layer2.15.bn2.bias      |     32     |\n",
            "|    layer2.16.conv1.weight    |    9216    |\n",
            "|     layer2.16.bn1.weight     |     32     |\n",
            "|      layer2.16.bn1.bias      |     32     |\n",
            "|    layer2.16.conv2.weight    |    9216    |\n",
            "|     layer2.16.bn2.weight     |     32     |\n",
            "|      layer2.16.bn2.bias      |     32     |\n",
            "|    layer2.17.conv1.weight    |    9216    |\n",
            "|     layer2.17.bn1.weight     |     32     |\n",
            "|      layer2.17.bn1.bias      |     32     |\n",
            "|    layer2.17.conv2.weight    |    9216    |\n",
            "|     layer2.17.bn2.weight     |     32     |\n",
            "|      layer2.17.bn2.bias      |     32     |\n",
            "|    layer2.18.conv1.weight    |    9216    |\n",
            "|     layer2.18.bn1.weight     |     32     |\n",
            "|      layer2.18.bn1.bias      |     32     |\n",
            "|    layer2.18.conv2.weight    |    9216    |\n",
            "|     layer2.18.bn2.weight     |     32     |\n",
            "|      layer2.18.bn2.bias      |     32     |\n",
            "|    layer2.19.conv1.weight    |    9216    |\n",
            "|     layer2.19.bn1.weight     |     32     |\n",
            "|      layer2.19.bn1.bias      |     32     |\n",
            "|    layer2.19.conv2.weight    |    9216    |\n",
            "|     layer2.19.bn2.weight     |     32     |\n",
            "|      layer2.19.bn2.bias      |     32     |\n",
            "|    layer2.20.conv1.weight    |    9216    |\n",
            "|     layer2.20.bn1.weight     |     32     |\n",
            "|      layer2.20.bn1.bias      |     32     |\n",
            "|    layer2.20.conv2.weight    |    9216    |\n",
            "|     layer2.20.bn2.weight     |     32     |\n",
            "|      layer2.20.bn2.bias      |     32     |\n",
            "|    layer2.21.conv1.weight    |    9216    |\n",
            "|     layer2.21.bn1.weight     |     32     |\n",
            "|      layer2.21.bn1.bias      |     32     |\n",
            "|    layer2.21.conv2.weight    |    9216    |\n",
            "|     layer2.21.bn2.weight     |     32     |\n",
            "|      layer2.21.bn2.bias      |     32     |\n",
            "|    layer2.22.conv1.weight    |    9216    |\n",
            "|     layer2.22.bn1.weight     |     32     |\n",
            "|      layer2.22.bn1.bias      |     32     |\n",
            "|    layer2.22.conv2.weight    |    9216    |\n",
            "|     layer2.22.bn2.weight     |     32     |\n",
            "|      layer2.22.bn2.bias      |     32     |\n",
            "|    layer2.23.conv1.weight    |    9216    |\n",
            "|     layer2.23.bn1.weight     |     32     |\n",
            "|      layer2.23.bn1.bias      |     32     |\n",
            "|    layer2.23.conv2.weight    |    9216    |\n",
            "|     layer2.23.bn2.weight     |     32     |\n",
            "|      layer2.23.bn2.bias      |     32     |\n",
            "|    layer2.24.conv1.weight    |    9216    |\n",
            "|     layer2.24.bn1.weight     |     32     |\n",
            "|      layer2.24.bn1.bias      |     32     |\n",
            "|    layer2.24.conv2.weight    |    9216    |\n",
            "|     layer2.24.bn2.weight     |     32     |\n",
            "|      layer2.24.bn2.bias      |     32     |\n",
            "|    layer2.25.conv1.weight    |    9216    |\n",
            "|     layer2.25.bn1.weight     |     32     |\n",
            "|      layer2.25.bn1.bias      |     32     |\n",
            "|    layer2.25.conv2.weight    |    9216    |\n",
            "|     layer2.25.bn2.weight     |     32     |\n",
            "|      layer2.25.bn2.bias      |     32     |\n",
            "|    layer2.26.conv1.weight    |    9216    |\n",
            "|     layer2.26.bn1.weight     |     32     |\n",
            "|      layer2.26.bn1.bias      |     32     |\n",
            "|    layer2.26.conv2.weight    |    9216    |\n",
            "|     layer2.26.bn2.weight     |     32     |\n",
            "|      layer2.26.bn2.bias      |     32     |\n",
            "|    layer2.27.conv1.weight    |    9216    |\n",
            "|     layer2.27.bn1.weight     |     32     |\n",
            "|      layer2.27.bn1.bias      |     32     |\n",
            "|    layer2.27.conv2.weight    |    9216    |\n",
            "|     layer2.27.bn2.weight     |     32     |\n",
            "|      layer2.27.bn2.bias      |     32     |\n",
            "|    layer2.28.conv1.weight    |    9216    |\n",
            "|     layer2.28.bn1.weight     |     32     |\n",
            "|      layer2.28.bn1.bias      |     32     |\n",
            "|    layer2.28.conv2.weight    |    9216    |\n",
            "|     layer2.28.bn2.weight     |     32     |\n",
            "|      layer2.28.bn2.bias      |     32     |\n",
            "|    layer2.29.conv1.weight    |    9216    |\n",
            "|     layer2.29.bn1.weight     |     32     |\n",
            "|      layer2.29.bn1.bias      |     32     |\n",
            "|    layer2.29.conv2.weight    |    9216    |\n",
            "|     layer2.29.bn2.weight     |     32     |\n",
            "|      layer2.29.bn2.bias      |     32     |\n",
            "|    layer2.30.conv1.weight    |    9216    |\n",
            "|     layer2.30.bn1.weight     |     32     |\n",
            "|      layer2.30.bn1.bias      |     32     |\n",
            "|    layer2.30.conv2.weight    |    9216    |\n",
            "|     layer2.30.bn2.weight     |     32     |\n",
            "|      layer2.30.bn2.bias      |     32     |\n",
            "|    layer3.0.conv1.weight     |   18432    |\n",
            "|     layer3.0.bn1.weight      |     64     |\n",
            "|      layer3.0.bn1.bias       |     64     |\n",
            "|    layer3.0.conv2.weight     |   36864    |\n",
            "|     layer3.0.bn2.weight      |     64     |\n",
            "|      layer3.0.bn2.bias       |     64     |\n",
            "| layer3.0.downsample.0.weight |   18432    |\n",
            "| layer3.0.downsample.1.weight |     64     |\n",
            "|  layer3.0.downsample.1.bias  |     64     |\n",
            "|    layer3.1.conv1.weight     |   36864    |\n",
            "|     layer3.1.bn1.weight      |     64     |\n",
            "|      layer3.1.bn1.bias       |     64     |\n",
            "|    layer3.1.conv2.weight     |   36864    |\n",
            "|     layer3.1.bn2.weight      |     64     |\n",
            "|      layer3.1.bn2.bias       |     64     |\n",
            "|    layer3.2.conv1.weight     |   36864    |\n",
            "|     layer3.2.bn1.weight      |     64     |\n",
            "|      layer3.2.bn1.bias       |     64     |\n",
            "|    layer3.2.conv2.weight     |   36864    |\n",
            "|     layer3.2.bn2.weight      |     64     |\n",
            "|      layer3.2.bn2.bias       |     64     |\n",
            "|    layer3.3.conv1.weight     |   36864    |\n",
            "|     layer3.3.bn1.weight      |     64     |\n",
            "|      layer3.3.bn1.bias       |     64     |\n",
            "|    layer3.3.conv2.weight     |   36864    |\n",
            "|     layer3.3.bn2.weight      |     64     |\n",
            "|      layer3.3.bn2.bias       |     64     |\n",
            "|    layer3.4.conv1.weight     |   36864    |\n",
            "|     layer3.4.bn1.weight      |     64     |\n",
            "|      layer3.4.bn1.bias       |     64     |\n",
            "|    layer3.4.conv2.weight     |   36864    |\n",
            "|     layer3.4.bn2.weight      |     64     |\n",
            "|      layer3.4.bn2.bias       |     64     |\n",
            "|    layer3.5.conv1.weight     |   36864    |\n",
            "|     layer3.5.bn1.weight      |     64     |\n",
            "|      layer3.5.bn1.bias       |     64     |\n",
            "|    layer3.5.conv2.weight     |   36864    |\n",
            "|     layer3.5.bn2.weight      |     64     |\n",
            "|      layer3.5.bn2.bias       |     64     |\n",
            "|    layer3.6.conv1.weight     |   36864    |\n",
            "|     layer3.6.bn1.weight      |     64     |\n",
            "|      layer3.6.bn1.bias       |     64     |\n",
            "|    layer3.6.conv2.weight     |   36864    |\n",
            "|     layer3.6.bn2.weight      |     64     |\n",
            "|      layer3.6.bn2.bias       |     64     |\n",
            "|    layer3.7.conv1.weight     |   36864    |\n",
            "|     layer3.7.bn1.weight      |     64     |\n",
            "|      layer3.7.bn1.bias       |     64     |\n",
            "|    layer3.7.conv2.weight     |   36864    |\n",
            "|     layer3.7.bn2.weight      |     64     |\n",
            "|      layer3.7.bn2.bias       |     64     |\n",
            "|    layer3.8.conv1.weight     |   36864    |\n",
            "|     layer3.8.bn1.weight      |     64     |\n",
            "|      layer3.8.bn1.bias       |     64     |\n",
            "|    layer3.8.conv2.weight     |   36864    |\n",
            "|     layer3.8.bn2.weight      |     64     |\n",
            "|      layer3.8.bn2.bias       |     64     |\n",
            "|    layer3.9.conv1.weight     |   36864    |\n",
            "|     layer3.9.bn1.weight      |     64     |\n",
            "|      layer3.9.bn1.bias       |     64     |\n",
            "|    layer3.9.conv2.weight     |   36864    |\n",
            "|     layer3.9.bn2.weight      |     64     |\n",
            "|      layer3.9.bn2.bias       |     64     |\n",
            "|    layer3.10.conv1.weight    |   36864    |\n",
            "|     layer3.10.bn1.weight     |     64     |\n",
            "|      layer3.10.bn1.bias      |     64     |\n",
            "|    layer3.10.conv2.weight    |   36864    |\n",
            "|     layer3.10.bn2.weight     |     64     |\n",
            "|      layer3.10.bn2.bias      |     64     |\n",
            "|    layer3.11.conv1.weight    |   36864    |\n",
            "|     layer3.11.bn1.weight     |     64     |\n",
            "|      layer3.11.bn1.bias      |     64     |\n",
            "|    layer3.11.conv2.weight    |   36864    |\n",
            "|     layer3.11.bn2.weight     |     64     |\n",
            "|      layer3.11.bn2.bias      |     64     |\n",
            "|    layer3.12.conv1.weight    |   36864    |\n",
            "|     layer3.12.bn1.weight     |     64     |\n",
            "|      layer3.12.bn1.bias      |     64     |\n",
            "|    layer3.12.conv2.weight    |   36864    |\n",
            "|     layer3.12.bn2.weight     |     64     |\n",
            "|      layer3.12.bn2.bias      |     64     |\n",
            "|    layer3.13.conv1.weight    |   36864    |\n",
            "|     layer3.13.bn1.weight     |     64     |\n",
            "|      layer3.13.bn1.bias      |     64     |\n",
            "|    layer3.13.conv2.weight    |   36864    |\n",
            "|     layer3.13.bn2.weight     |     64     |\n",
            "|      layer3.13.bn2.bias      |     64     |\n",
            "|    layer3.14.conv1.weight    |   36864    |\n",
            "|     layer3.14.bn1.weight     |     64     |\n",
            "|      layer3.14.bn1.bias      |     64     |\n",
            "|    layer3.14.conv2.weight    |   36864    |\n",
            "|     layer3.14.bn2.weight     |     64     |\n",
            "|      layer3.14.bn2.bias      |     64     |\n",
            "|    layer3.15.conv1.weight    |   36864    |\n",
            "|     layer3.15.bn1.weight     |     64     |\n",
            "|      layer3.15.bn1.bias      |     64     |\n",
            "|    layer3.15.conv2.weight    |   36864    |\n",
            "|     layer3.15.bn2.weight     |     64     |\n",
            "|      layer3.15.bn2.bias      |     64     |\n",
            "|    layer3.16.conv1.weight    |   36864    |\n",
            "|     layer3.16.bn1.weight     |     64     |\n",
            "|      layer3.16.bn1.bias      |     64     |\n",
            "|    layer3.16.conv2.weight    |   36864    |\n",
            "|     layer3.16.bn2.weight     |     64     |\n",
            "|      layer3.16.bn2.bias      |     64     |\n",
            "|    layer3.17.conv1.weight    |   36864    |\n",
            "|     layer3.17.bn1.weight     |     64     |\n",
            "|      layer3.17.bn1.bias      |     64     |\n",
            "|    layer3.17.conv2.weight    |   36864    |\n",
            "|     layer3.17.bn2.weight     |     64     |\n",
            "|      layer3.17.bn2.bias      |     64     |\n",
            "|    layer3.18.conv1.weight    |   36864    |\n",
            "|     layer3.18.bn1.weight     |     64     |\n",
            "|      layer3.18.bn1.bias      |     64     |\n",
            "|    layer3.18.conv2.weight    |   36864    |\n",
            "|     layer3.18.bn2.weight     |     64     |\n",
            "|      layer3.18.bn2.bias      |     64     |\n",
            "|    layer3.19.conv1.weight    |   36864    |\n",
            "|     layer3.19.bn1.weight     |     64     |\n",
            "|      layer3.19.bn1.bias      |     64     |\n",
            "|    layer3.19.conv2.weight    |   36864    |\n",
            "|     layer3.19.bn2.weight     |     64     |\n",
            "|      layer3.19.bn2.bias      |     64     |\n",
            "|    layer3.20.conv1.weight    |   36864    |\n",
            "|     layer3.20.bn1.weight     |     64     |\n",
            "|      layer3.20.bn1.bias      |     64     |\n",
            "|    layer3.20.conv2.weight    |   36864    |\n",
            "|     layer3.20.bn2.weight     |     64     |\n",
            "|      layer3.20.bn2.bias      |     64     |\n",
            "|    layer3.21.conv1.weight    |   36864    |\n",
            "|     layer3.21.bn1.weight     |     64     |\n",
            "|      layer3.21.bn1.bias      |     64     |\n",
            "|    layer3.21.conv2.weight    |   36864    |\n",
            "|     layer3.21.bn2.weight     |     64     |\n",
            "|      layer3.21.bn2.bias      |     64     |\n",
            "|    layer3.22.conv1.weight    |   36864    |\n",
            "|     layer3.22.bn1.weight     |     64     |\n",
            "|      layer3.22.bn1.bias      |     64     |\n",
            "|    layer3.22.conv2.weight    |   36864    |\n",
            "|     layer3.22.bn2.weight     |     64     |\n",
            "|      layer3.22.bn2.bias      |     64     |\n",
            "|    layer3.23.conv1.weight    |   36864    |\n",
            "|     layer3.23.bn1.weight     |     64     |\n",
            "|      layer3.23.bn1.bias      |     64     |\n",
            "|    layer3.23.conv2.weight    |   36864    |\n",
            "|     layer3.23.bn2.weight     |     64     |\n",
            "|      layer3.23.bn2.bias      |     64     |\n",
            "|    layer3.24.conv1.weight    |   36864    |\n",
            "|     layer3.24.bn1.weight     |     64     |\n",
            "|      layer3.24.bn1.bias      |     64     |\n",
            "|    layer3.24.conv2.weight    |   36864    |\n",
            "|     layer3.24.bn2.weight     |     64     |\n",
            "|      layer3.24.bn2.bias      |     64     |\n",
            "|    layer3.25.conv1.weight    |   36864    |\n",
            "|     layer3.25.bn1.weight     |     64     |\n",
            "|      layer3.25.bn1.bias      |     64     |\n",
            "|    layer3.25.conv2.weight    |   36864    |\n",
            "|     layer3.25.bn2.weight     |     64     |\n",
            "|      layer3.25.bn2.bias      |     64     |\n",
            "|    layer3.26.conv1.weight    |   36864    |\n",
            "|     layer3.26.bn1.weight     |     64     |\n",
            "|      layer3.26.bn1.bias      |     64     |\n",
            "|    layer3.26.conv2.weight    |   36864    |\n",
            "|     layer3.26.bn2.weight     |     64     |\n",
            "|      layer3.26.bn2.bias      |     64     |\n",
            "|    layer3.27.conv1.weight    |   36864    |\n",
            "|     layer3.27.bn1.weight     |     64     |\n",
            "|      layer3.27.bn1.bias      |     64     |\n",
            "|    layer3.27.conv2.weight    |   36864    |\n",
            "|     layer3.27.bn2.weight     |     64     |\n",
            "|      layer3.27.bn2.bias      |     64     |\n",
            "|    layer3.28.conv1.weight    |   36864    |\n",
            "|     layer3.28.bn1.weight     |     64     |\n",
            "|      layer3.28.bn1.bias      |     64     |\n",
            "|    layer3.28.conv2.weight    |   36864    |\n",
            "|     layer3.28.bn2.weight     |     64     |\n",
            "|      layer3.28.bn2.bias      |     64     |\n",
            "|    layer3.29.conv1.weight    |   36864    |\n",
            "|     layer3.29.bn1.weight     |     64     |\n",
            "|      layer3.29.bn1.bias      |     64     |\n",
            "|    layer3.29.conv2.weight    |   36864    |\n",
            "|     layer3.29.bn2.weight     |     64     |\n",
            "|      layer3.29.bn2.bias      |     64     |\n",
            "|    layer3.30.conv1.weight    |   36864    |\n",
            "|     layer3.30.bn1.weight     |     64     |\n",
            "|      layer3.30.bn1.bias      |     64     |\n",
            "|    layer3.30.conv2.weight    |   36864    |\n",
            "|     layer3.30.bn2.weight     |     64     |\n",
            "|      layer3.30.bn2.bias      |     64     |\n",
            "|          fc.weight           |    640     |\n",
            "|           fc.bias            |     10     |\n",
            "+------------------------------+------------+\n",
            "Total Trainable Params: 3015002\n",
            "+------------------------------+------------+\n",
            "|           Modules            | Parameters |\n",
            "+------------------------------+------------+\n",
            "|         conv.weight          |    432     |\n",
            "|          bn.weight           |     16     |\n",
            "|           bn.bias            |     16     |\n",
            "|    layer1.0.conv1.weight     |    2304    |\n",
            "|     layer1.0.bn1.weight      |     16     |\n",
            "|      layer1.0.bn1.bias       |     16     |\n",
            "|    layer1.0.conv2.weight     |    2304    |\n",
            "|     layer1.0.bn2.weight      |     16     |\n",
            "|      layer1.0.bn2.bias       |     16     |\n",
            "|    layer1.1.conv1.weight     |    2304    |\n",
            "|     layer1.1.bn1.weight      |     16     |\n",
            "|      layer1.1.bn1.bias       |     16     |\n",
            "|    layer1.1.conv2.weight     |    2304    |\n",
            "|     layer1.1.bn2.weight      |     16     |\n",
            "|      layer1.1.bn2.bias       |     16     |\n",
            "|    layer1.2.conv1.weight     |    2304    |\n",
            "|     layer1.2.bn1.weight      |     16     |\n",
            "|      layer1.2.bn1.bias       |     16     |\n",
            "|    layer1.2.conv2.weight     |    2304    |\n",
            "|     layer1.2.bn2.weight      |     16     |\n",
            "|      layer1.2.bn2.bias       |     16     |\n",
            "|    layer1.3.conv1.weight     |    2304    |\n",
            "|     layer1.3.bn1.weight      |     16     |\n",
            "|      layer1.3.bn1.bias       |     16     |\n",
            "|    layer1.3.conv2.weight     |    2304    |\n",
            "|     layer1.3.bn2.weight      |     16     |\n",
            "|      layer1.3.bn2.bias       |     16     |\n",
            "|    layer1.4.conv1.weight     |    2304    |\n",
            "|     layer1.4.bn1.weight      |     16     |\n",
            "|      layer1.4.bn1.bias       |     16     |\n",
            "|    layer1.4.conv2.weight     |    2304    |\n",
            "|     layer1.4.bn2.weight      |     16     |\n",
            "|      layer1.4.bn2.bias       |     16     |\n",
            "|    layer1.5.conv1.weight     |    2304    |\n",
            "|     layer1.5.bn1.weight      |     16     |\n",
            "|      layer1.5.bn1.bias       |     16     |\n",
            "|    layer1.5.conv2.weight     |    2304    |\n",
            "|     layer1.5.bn2.weight      |     16     |\n",
            "|      layer1.5.bn2.bias       |     16     |\n",
            "|    layer1.6.conv1.weight     |    2304    |\n",
            "|     layer1.6.bn1.weight      |     16     |\n",
            "|      layer1.6.bn1.bias       |     16     |\n",
            "|    layer1.6.conv2.weight     |    2304    |\n",
            "|     layer1.6.bn2.weight      |     16     |\n",
            "|      layer1.6.bn2.bias       |     16     |\n",
            "|    layer1.7.conv1.weight     |    2304    |\n",
            "|     layer1.7.bn1.weight      |     16     |\n",
            "|      layer1.7.bn1.bias       |     16     |\n",
            "|    layer1.7.conv2.weight     |    2304    |\n",
            "|     layer1.7.bn2.weight      |     16     |\n",
            "|      layer1.7.bn2.bias       |     16     |\n",
            "|    layer1.8.conv1.weight     |    2304    |\n",
            "|     layer1.8.bn1.weight      |     16     |\n",
            "|      layer1.8.bn1.bias       |     16     |\n",
            "|    layer1.8.conv2.weight     |    2304    |\n",
            "|     layer1.8.bn2.weight      |     16     |\n",
            "|      layer1.8.bn2.bias       |     16     |\n",
            "|    layer1.9.conv1.weight     |    2304    |\n",
            "|     layer1.9.bn1.weight      |     16     |\n",
            "|      layer1.9.bn1.bias       |     16     |\n",
            "|    layer1.9.conv2.weight     |    2304    |\n",
            "|     layer1.9.bn2.weight      |     16     |\n",
            "|      layer1.9.bn2.bias       |     16     |\n",
            "|    layer1.10.conv1.weight    |    2304    |\n",
            "|     layer1.10.bn1.weight     |     16     |\n",
            "|      layer1.10.bn1.bias      |     16     |\n",
            "|    layer1.10.conv2.weight    |    2304    |\n",
            "|     layer1.10.bn2.weight     |     16     |\n",
            "|      layer1.10.bn2.bias      |     16     |\n",
            "|    layer1.11.conv1.weight    |    2304    |\n",
            "|     layer1.11.bn1.weight     |     16     |\n",
            "|      layer1.11.bn1.bias      |     16     |\n",
            "|    layer1.11.conv2.weight    |    2304    |\n",
            "|     layer1.11.bn2.weight     |     16     |\n",
            "|      layer1.11.bn2.bias      |     16     |\n",
            "|    layer1.12.conv1.weight    |    2304    |\n",
            "|     layer1.12.bn1.weight     |     16     |\n",
            "|      layer1.12.bn1.bias      |     16     |\n",
            "|    layer1.12.conv2.weight    |    2304    |\n",
            "|     layer1.12.bn2.weight     |     16     |\n",
            "|      layer1.12.bn2.bias      |     16     |\n",
            "|    layer1.13.conv1.weight    |    2304    |\n",
            "|     layer1.13.bn1.weight     |     16     |\n",
            "|      layer1.13.bn1.bias      |     16     |\n",
            "|    layer1.13.conv2.weight    |    2304    |\n",
            "|     layer1.13.bn2.weight     |     16     |\n",
            "|      layer1.13.bn2.bias      |     16     |\n",
            "|    layer1.14.conv1.weight    |    2304    |\n",
            "|     layer1.14.bn1.weight     |     16     |\n",
            "|      layer1.14.bn1.bias      |     16     |\n",
            "|    layer1.14.conv2.weight    |    2304    |\n",
            "|     layer1.14.bn2.weight     |     16     |\n",
            "|      layer1.14.bn2.bias      |     16     |\n",
            "|    layer1.15.conv1.weight    |    2304    |\n",
            "|     layer1.15.bn1.weight     |     16     |\n",
            "|      layer1.15.bn1.bias      |     16     |\n",
            "|    layer1.15.conv2.weight    |    2304    |\n",
            "|     layer1.15.bn2.weight     |     16     |\n",
            "|      layer1.15.bn2.bias      |     16     |\n",
            "|    layer1.16.conv1.weight    |    2304    |\n",
            "|     layer1.16.bn1.weight     |     16     |\n",
            "|      layer1.16.bn1.bias      |     16     |\n",
            "|    layer1.16.conv2.weight    |    2304    |\n",
            "|     layer1.16.bn2.weight     |     16     |\n",
            "|      layer1.16.bn2.bias      |     16     |\n",
            "|    layer1.17.conv1.weight    |    2304    |\n",
            "|     layer1.17.bn1.weight     |     16     |\n",
            "|      layer1.17.bn1.bias      |     16     |\n",
            "|    layer1.17.conv2.weight    |    2304    |\n",
            "|     layer1.17.bn2.weight     |     16     |\n",
            "|      layer1.17.bn2.bias      |     16     |\n",
            "|    layer1.18.conv1.weight    |    2304    |\n",
            "|     layer1.18.bn1.weight     |     16     |\n",
            "|      layer1.18.bn1.bias      |     16     |\n",
            "|    layer1.18.conv2.weight    |    2304    |\n",
            "|     layer1.18.bn2.weight     |     16     |\n",
            "|      layer1.18.bn2.bias      |     16     |\n",
            "|    layer1.19.conv1.weight    |    2304    |\n",
            "|     layer1.19.bn1.weight     |     16     |\n",
            "|      layer1.19.bn1.bias      |     16     |\n",
            "|    layer1.19.conv2.weight    |    2304    |\n",
            "|     layer1.19.bn2.weight     |     16     |\n",
            "|      layer1.19.bn2.bias      |     16     |\n",
            "|    layer1.20.conv1.weight    |    2304    |\n",
            "|     layer1.20.bn1.weight     |     16     |\n",
            "|      layer1.20.bn1.bias      |     16     |\n",
            "|    layer1.20.conv2.weight    |    2304    |\n",
            "|     layer1.20.bn2.weight     |     16     |\n",
            "|      layer1.20.bn2.bias      |     16     |\n",
            "|    layer1.21.conv1.weight    |    2304    |\n",
            "|     layer1.21.bn1.weight     |     16     |\n",
            "|      layer1.21.bn1.bias      |     16     |\n",
            "|    layer1.21.conv2.weight    |    2304    |\n",
            "|     layer1.21.bn2.weight     |     16     |\n",
            "|      layer1.21.bn2.bias      |     16     |\n",
            "|    layer1.22.conv1.weight    |    2304    |\n",
            "|     layer1.22.bn1.weight     |     16     |\n",
            "|      layer1.22.bn1.bias      |     16     |\n",
            "|    layer1.22.conv2.weight    |    2304    |\n",
            "|     layer1.22.bn2.weight     |     16     |\n",
            "|      layer1.22.bn2.bias      |     16     |\n",
            "|    layer1.23.conv1.weight    |    2304    |\n",
            "|     layer1.23.bn1.weight     |     16     |\n",
            "|      layer1.23.bn1.bias      |     16     |\n",
            "|    layer1.23.conv2.weight    |    2304    |\n",
            "|     layer1.23.bn2.weight     |     16     |\n",
            "|      layer1.23.bn2.bias      |     16     |\n",
            "|    layer1.24.conv1.weight    |    2304    |\n",
            "|     layer1.24.bn1.weight     |     16     |\n",
            "|      layer1.24.bn1.bias      |     16     |\n",
            "|    layer1.24.conv2.weight    |    2304    |\n",
            "|     layer1.24.bn2.weight     |     16     |\n",
            "|      layer1.24.bn2.bias      |     16     |\n",
            "|    layer1.25.conv1.weight    |    2304    |\n",
            "|     layer1.25.bn1.weight     |     16     |\n",
            "|      layer1.25.bn1.bias      |     16     |\n",
            "|    layer1.25.conv2.weight    |    2304    |\n",
            "|     layer1.25.bn2.weight     |     16     |\n",
            "|      layer1.25.bn2.bias      |     16     |\n",
            "|    layer1.26.conv1.weight    |    2304    |\n",
            "|     layer1.26.bn1.weight     |     16     |\n",
            "|      layer1.26.bn1.bias      |     16     |\n",
            "|    layer1.26.conv2.weight    |    2304    |\n",
            "|     layer1.26.bn2.weight     |     16     |\n",
            "|      layer1.26.bn2.bias      |     16     |\n",
            "|    layer1.27.conv1.weight    |    2304    |\n",
            "|     layer1.27.bn1.weight     |     16     |\n",
            "|      layer1.27.bn1.bias      |     16     |\n",
            "|    layer1.27.conv2.weight    |    2304    |\n",
            "|     layer1.27.bn2.weight     |     16     |\n",
            "|      layer1.27.bn2.bias      |     16     |\n",
            "|    layer1.28.conv1.weight    |    2304    |\n",
            "|     layer1.28.bn1.weight     |     16     |\n",
            "|      layer1.28.bn1.bias      |     16     |\n",
            "|    layer1.28.conv2.weight    |    2304    |\n",
            "|     layer1.28.bn2.weight     |     16     |\n",
            "|      layer1.28.bn2.bias      |     16     |\n",
            "|    layer1.29.conv1.weight    |    2304    |\n",
            "|     layer1.29.bn1.weight     |     16     |\n",
            "|      layer1.29.bn1.bias      |     16     |\n",
            "|    layer1.29.conv2.weight    |    2304    |\n",
            "|     layer1.29.bn2.weight     |     16     |\n",
            "|      layer1.29.bn2.bias      |     16     |\n",
            "|    layer1.30.conv1.weight    |    2304    |\n",
            "|     layer1.30.bn1.weight     |     16     |\n",
            "|      layer1.30.bn1.bias      |     16     |\n",
            "|    layer1.30.conv2.weight    |    2304    |\n",
            "|     layer1.30.bn2.weight     |     16     |\n",
            "|      layer1.30.bn2.bias      |     16     |\n",
            "|    layer1.31.conv1.weight    |    2304    |\n",
            "|     layer1.31.bn1.weight     |     16     |\n",
            "|      layer1.31.bn1.bias      |     16     |\n",
            "|    layer1.31.conv2.weight    |    2304    |\n",
            "|     layer1.31.bn2.weight     |     16     |\n",
            "|      layer1.31.bn2.bias      |     16     |\n",
            "|    layer1.32.conv1.weight    |    2304    |\n",
            "|     layer1.32.bn1.weight     |     16     |\n",
            "|      layer1.32.bn1.bias      |     16     |\n",
            "|    layer1.32.conv2.weight    |    2304    |\n",
            "|     layer1.32.bn2.weight     |     16     |\n",
            "|      layer1.32.bn2.bias      |     16     |\n",
            "|    layer1.33.conv1.weight    |    2304    |\n",
            "|     layer1.33.bn1.weight     |     16     |\n",
            "|      layer1.33.bn1.bias      |     16     |\n",
            "|    layer1.33.conv2.weight    |    2304    |\n",
            "|     layer1.33.bn2.weight     |     16     |\n",
            "|      layer1.33.bn2.bias      |     16     |\n",
            "|    layer1.34.conv1.weight    |    2304    |\n",
            "|     layer1.34.bn1.weight     |     16     |\n",
            "|      layer1.34.bn1.bias      |     16     |\n",
            "|    layer1.34.conv2.weight    |    2304    |\n",
            "|     layer1.34.bn2.weight     |     16     |\n",
            "|      layer1.34.bn2.bias      |     16     |\n",
            "|    layer1.35.conv1.weight    |    2304    |\n",
            "|     layer1.35.bn1.weight     |     16     |\n",
            "|      layer1.35.bn1.bias      |     16     |\n",
            "|    layer1.35.conv2.weight    |    2304    |\n",
            "|     layer1.35.bn2.weight     |     16     |\n",
            "|      layer1.35.bn2.bias      |     16     |\n",
            "|    layer1.36.conv1.weight    |    2304    |\n",
            "|     layer1.36.bn1.weight     |     16     |\n",
            "|      layer1.36.bn1.bias      |     16     |\n",
            "|    layer1.36.conv2.weight    |    2304    |\n",
            "|     layer1.36.bn2.weight     |     16     |\n",
            "|      layer1.36.bn2.bias      |     16     |\n",
            "|    layer1.37.conv1.weight    |    2304    |\n",
            "|     layer1.37.bn1.weight     |     16     |\n",
            "|      layer1.37.bn1.bias      |     16     |\n",
            "|    layer1.37.conv2.weight    |    2304    |\n",
            "|     layer1.37.bn2.weight     |     16     |\n",
            "|      layer1.37.bn2.bias      |     16     |\n",
            "|    layer1.38.conv1.weight    |    2304    |\n",
            "|     layer1.38.bn1.weight     |     16     |\n",
            "|      layer1.38.bn1.bias      |     16     |\n",
            "|    layer1.38.conv2.weight    |    2304    |\n",
            "|     layer1.38.bn2.weight     |     16     |\n",
            "|      layer1.38.bn2.bias      |     16     |\n",
            "|    layer1.39.conv1.weight    |    2304    |\n",
            "|     layer1.39.bn1.weight     |     16     |\n",
            "|      layer1.39.bn1.bias      |     16     |\n",
            "|    layer1.39.conv2.weight    |    2304    |\n",
            "|     layer1.39.bn2.weight     |     16     |\n",
            "|      layer1.39.bn2.bias      |     16     |\n",
            "|    layer1.40.conv1.weight    |    2304    |\n",
            "|     layer1.40.bn1.weight     |     16     |\n",
            "|      layer1.40.bn1.bias      |     16     |\n",
            "|    layer1.40.conv2.weight    |    2304    |\n",
            "|     layer1.40.bn2.weight     |     16     |\n",
            "|      layer1.40.bn2.bias      |     16     |\n",
            "|    layer1.41.conv1.weight    |    2304    |\n",
            "|     layer1.41.bn1.weight     |     16     |\n",
            "|      layer1.41.bn1.bias      |     16     |\n",
            "|    layer1.41.conv2.weight    |    2304    |\n",
            "|     layer1.41.bn2.weight     |     16     |\n",
            "|      layer1.41.bn2.bias      |     16     |\n",
            "|    layer1.42.conv1.weight    |    2304    |\n",
            "|     layer1.42.bn1.weight     |     16     |\n",
            "|      layer1.42.bn1.bias      |     16     |\n",
            "|    layer1.42.conv2.weight    |    2304    |\n",
            "|     layer1.42.bn2.weight     |     16     |\n",
            "|      layer1.42.bn2.bias      |     16     |\n",
            "|    layer2.0.conv1.weight     |    4608    |\n",
            "|     layer2.0.bn1.weight      |     32     |\n",
            "|      layer2.0.bn1.bias       |     32     |\n",
            "|    layer2.0.conv2.weight     |    9216    |\n",
            "|     layer2.0.bn2.weight      |     32     |\n",
            "|      layer2.0.bn2.bias       |     32     |\n",
            "| layer2.0.downsample.0.weight |    4608    |\n",
            "| layer2.0.downsample.1.weight |     32     |\n",
            "|  layer2.0.downsample.1.bias  |     32     |\n",
            "|    layer2.1.conv1.weight     |    9216    |\n",
            "|     layer2.1.bn1.weight      |     32     |\n",
            "|      layer2.1.bn1.bias       |     32     |\n",
            "|    layer2.1.conv2.weight     |    9216    |\n",
            "|     layer2.1.bn2.weight      |     32     |\n",
            "|      layer2.1.bn2.bias       |     32     |\n",
            "|    layer2.2.conv1.weight     |    9216    |\n",
            "|     layer2.2.bn1.weight      |     32     |\n",
            "|      layer2.2.bn1.bias       |     32     |\n",
            "|    layer2.2.conv2.weight     |    9216    |\n",
            "|     layer2.2.bn2.weight      |     32     |\n",
            "|      layer2.2.bn2.bias       |     32     |\n",
            "|    layer2.3.conv1.weight     |    9216    |\n",
            "|     layer2.3.bn1.weight      |     32     |\n",
            "|      layer2.3.bn1.bias       |     32     |\n",
            "|    layer2.3.conv2.weight     |    9216    |\n",
            "|     layer2.3.bn2.weight      |     32     |\n",
            "|      layer2.3.bn2.bias       |     32     |\n",
            "|    layer2.4.conv1.weight     |    9216    |\n",
            "|     layer2.4.bn1.weight      |     32     |\n",
            "|      layer2.4.bn1.bias       |     32     |\n",
            "|    layer2.4.conv2.weight     |    9216    |\n",
            "|     layer2.4.bn2.weight      |     32     |\n",
            "|      layer2.4.bn2.bias       |     32     |\n",
            "|    layer2.5.conv1.weight     |    9216    |\n",
            "|     layer2.5.bn1.weight      |     32     |\n",
            "|      layer2.5.bn1.bias       |     32     |\n",
            "|    layer2.5.conv2.weight     |    9216    |\n",
            "|     layer2.5.bn2.weight      |     32     |\n",
            "|      layer2.5.bn2.bias       |     32     |\n",
            "|    layer2.6.conv1.weight     |    9216    |\n",
            "|     layer2.6.bn1.weight      |     32     |\n",
            "|      layer2.6.bn1.bias       |     32     |\n",
            "|    layer2.6.conv2.weight     |    9216    |\n",
            "|     layer2.6.bn2.weight      |     32     |\n",
            "|      layer2.6.bn2.bias       |     32     |\n",
            "|    layer2.7.conv1.weight     |    9216    |\n",
            "|     layer2.7.bn1.weight      |     32     |\n",
            "|      layer2.7.bn1.bias       |     32     |\n",
            "|    layer2.7.conv2.weight     |    9216    |\n",
            "|     layer2.7.bn2.weight      |     32     |\n",
            "|      layer2.7.bn2.bias       |     32     |\n",
            "|    layer2.8.conv1.weight     |    9216    |\n",
            "|     layer2.8.bn1.weight      |     32     |\n",
            "|      layer2.8.bn1.bias       |     32     |\n",
            "|    layer2.8.conv2.weight     |    9216    |\n",
            "|     layer2.8.bn2.weight      |     32     |\n",
            "|      layer2.8.bn2.bias       |     32     |\n",
            "|    layer2.9.conv1.weight     |    9216    |\n",
            "|     layer2.9.bn1.weight      |     32     |\n",
            "|      layer2.9.bn1.bias       |     32     |\n",
            "|    layer2.9.conv2.weight     |    9216    |\n",
            "|     layer2.9.bn2.weight      |     32     |\n",
            "|      layer2.9.bn2.bias       |     32     |\n",
            "|    layer2.10.conv1.weight    |    9216    |\n",
            "|     layer2.10.bn1.weight     |     32     |\n",
            "|      layer2.10.bn1.bias      |     32     |\n",
            "|    layer2.10.conv2.weight    |    9216    |\n",
            "|     layer2.10.bn2.weight     |     32     |\n",
            "|      layer2.10.bn2.bias      |     32     |\n",
            "|    layer2.11.conv1.weight    |    9216    |\n",
            "|     layer2.11.bn1.weight     |     32     |\n",
            "|      layer2.11.bn1.bias      |     32     |\n",
            "|    layer2.11.conv2.weight    |    9216    |\n",
            "|     layer2.11.bn2.weight     |     32     |\n",
            "|      layer2.11.bn2.bias      |     32     |\n",
            "|    layer2.12.conv1.weight    |    9216    |\n",
            "|     layer2.12.bn1.weight     |     32     |\n",
            "|      layer2.12.bn1.bias      |     32     |\n",
            "|    layer2.12.conv2.weight    |    9216    |\n",
            "|     layer2.12.bn2.weight     |     32     |\n",
            "|      layer2.12.bn2.bias      |     32     |\n",
            "|    layer2.13.conv1.weight    |    9216    |\n",
            "|     layer2.13.bn1.weight     |     32     |\n",
            "|      layer2.13.bn1.bias      |     32     |\n",
            "|    layer2.13.conv2.weight    |    9216    |\n",
            "|     layer2.13.bn2.weight     |     32     |\n",
            "|      layer2.13.bn2.bias      |     32     |\n",
            "|    layer2.14.conv1.weight    |    9216    |\n",
            "|     layer2.14.bn1.weight     |     32     |\n",
            "|      layer2.14.bn1.bias      |     32     |\n",
            "|    layer2.14.conv2.weight    |    9216    |\n",
            "|     layer2.14.bn2.weight     |     32     |\n",
            "|      layer2.14.bn2.bias      |     32     |\n",
            "|    layer2.15.conv1.weight    |    9216    |\n",
            "|     layer2.15.bn1.weight     |     32     |\n",
            "|      layer2.15.bn1.bias      |     32     |\n",
            "|    layer2.15.conv2.weight    |    9216    |\n",
            "|     layer2.15.bn2.weight     |     32     |\n",
            "|      layer2.15.bn2.bias      |     32     |\n",
            "|    layer2.16.conv1.weight    |    9216    |\n",
            "|     layer2.16.bn1.weight     |     32     |\n",
            "|      layer2.16.bn1.bias      |     32     |\n",
            "|    layer2.16.conv2.weight    |    9216    |\n",
            "|     layer2.16.bn2.weight     |     32     |\n",
            "|      layer2.16.bn2.bias      |     32     |\n",
            "|    layer2.17.conv1.weight    |    9216    |\n",
            "|     layer2.17.bn1.weight     |     32     |\n",
            "|      layer2.17.bn1.bias      |     32     |\n",
            "|    layer2.17.conv2.weight    |    9216    |\n",
            "|     layer2.17.bn2.weight     |     32     |\n",
            "|      layer2.17.bn2.bias      |     32     |\n",
            "|    layer2.18.conv1.weight    |    9216    |\n",
            "|     layer2.18.bn1.weight     |     32     |\n",
            "|      layer2.18.bn1.bias      |     32     |\n",
            "|    layer2.18.conv2.weight    |    9216    |\n",
            "|     layer2.18.bn2.weight     |     32     |\n",
            "|      layer2.18.bn2.bias      |     32     |\n",
            "|    layer2.19.conv1.weight    |    9216    |\n",
            "|     layer2.19.bn1.weight     |     32     |\n",
            "|      layer2.19.bn1.bias      |     32     |\n",
            "|    layer2.19.conv2.weight    |    9216    |\n",
            "|     layer2.19.bn2.weight     |     32     |\n",
            "|      layer2.19.bn2.bias      |     32     |\n",
            "|    layer2.20.conv1.weight    |    9216    |\n",
            "|     layer2.20.bn1.weight     |     32     |\n",
            "|      layer2.20.bn1.bias      |     32     |\n",
            "|    layer2.20.conv2.weight    |    9216    |\n",
            "|     layer2.20.bn2.weight     |     32     |\n",
            "|      layer2.20.bn2.bias      |     32     |\n",
            "|    layer2.21.conv1.weight    |    9216    |\n",
            "|     layer2.21.bn1.weight     |     32     |\n",
            "|      layer2.21.bn1.bias      |     32     |\n",
            "|    layer2.21.conv2.weight    |    9216    |\n",
            "|     layer2.21.bn2.weight     |     32     |\n",
            "|      layer2.21.bn2.bias      |     32     |\n",
            "|    layer2.22.conv1.weight    |    9216    |\n",
            "|     layer2.22.bn1.weight     |     32     |\n",
            "|      layer2.22.bn1.bias      |     32     |\n",
            "|    layer2.22.conv2.weight    |    9216    |\n",
            "|     layer2.22.bn2.weight     |     32     |\n",
            "|      layer2.22.bn2.bias      |     32     |\n",
            "|    layer2.23.conv1.weight    |    9216    |\n",
            "|     layer2.23.bn1.weight     |     32     |\n",
            "|      layer2.23.bn1.bias      |     32     |\n",
            "|    layer2.23.conv2.weight    |    9216    |\n",
            "|     layer2.23.bn2.weight     |     32     |\n",
            "|      layer2.23.bn2.bias      |     32     |\n",
            "|    layer2.24.conv1.weight    |    9216    |\n",
            "|     layer2.24.bn1.weight     |     32     |\n",
            "|      layer2.24.bn1.bias      |     32     |\n",
            "|    layer2.24.conv2.weight    |    9216    |\n",
            "|     layer2.24.bn2.weight     |     32     |\n",
            "|      layer2.24.bn2.bias      |     32     |\n",
            "|    layer2.25.conv1.weight    |    9216    |\n",
            "|     layer2.25.bn1.weight     |     32     |\n",
            "|      layer2.25.bn1.bias      |     32     |\n",
            "|    layer2.25.conv2.weight    |    9216    |\n",
            "|     layer2.25.bn2.weight     |     32     |\n",
            "|      layer2.25.bn2.bias      |     32     |\n",
            "|    layer2.26.conv1.weight    |    9216    |\n",
            "|     layer2.26.bn1.weight     |     32     |\n",
            "|      layer2.26.bn1.bias      |     32     |\n",
            "|    layer2.26.conv2.weight    |    9216    |\n",
            "|     layer2.26.bn2.weight     |     32     |\n",
            "|      layer2.26.bn2.bias      |     32     |\n",
            "|    layer2.27.conv1.weight    |    9216    |\n",
            "|     layer2.27.bn1.weight     |     32     |\n",
            "|      layer2.27.bn1.bias      |     32     |\n",
            "|    layer2.27.conv2.weight    |    9216    |\n",
            "|     layer2.27.bn2.weight     |     32     |\n",
            "|      layer2.27.bn2.bias      |     32     |\n",
            "|    layer2.28.conv1.weight    |    9216    |\n",
            "|     layer2.28.bn1.weight     |     32     |\n",
            "|      layer2.28.bn1.bias      |     32     |\n",
            "|    layer2.28.conv2.weight    |    9216    |\n",
            "|     layer2.28.bn2.weight     |     32     |\n",
            "|      layer2.28.bn2.bias      |     32     |\n",
            "|    layer2.29.conv1.weight    |    9216    |\n",
            "|     layer2.29.bn1.weight     |     32     |\n",
            "|      layer2.29.bn1.bias      |     32     |\n",
            "|    layer2.29.conv2.weight    |    9216    |\n",
            "|     layer2.29.bn2.weight     |     32     |\n",
            "|      layer2.29.bn2.bias      |     32     |\n",
            "|    layer2.30.conv1.weight    |    9216    |\n",
            "|     layer2.30.bn1.weight     |     32     |\n",
            "|      layer2.30.bn1.bias      |     32     |\n",
            "|    layer2.30.conv2.weight    |    9216    |\n",
            "|     layer2.30.bn2.weight     |     32     |\n",
            "|      layer2.30.bn2.bias      |     32     |\n",
            "|    layer2.31.conv1.weight    |    9216    |\n",
            "|     layer2.31.bn1.weight     |     32     |\n",
            "|      layer2.31.bn1.bias      |     32     |\n",
            "|    layer2.31.conv2.weight    |    9216    |\n",
            "|     layer2.31.bn2.weight     |     32     |\n",
            "|      layer2.31.bn2.bias      |     32     |\n",
            "|    layer2.32.conv1.weight    |    9216    |\n",
            "|     layer2.32.bn1.weight     |     32     |\n",
            "|      layer2.32.bn1.bias      |     32     |\n",
            "|    layer2.32.conv2.weight    |    9216    |\n",
            "|     layer2.32.bn2.weight     |     32     |\n",
            "|      layer2.32.bn2.bias      |     32     |\n",
            "|    layer2.33.conv1.weight    |    9216    |\n",
            "|     layer2.33.bn1.weight     |     32     |\n",
            "|      layer2.33.bn1.bias      |     32     |\n",
            "|    layer2.33.conv2.weight    |    9216    |\n",
            "|     layer2.33.bn2.weight     |     32     |\n",
            "|      layer2.33.bn2.bias      |     32     |\n",
            "|    layer2.34.conv1.weight    |    9216    |\n",
            "|     layer2.34.bn1.weight     |     32     |\n",
            "|      layer2.34.bn1.bias      |     32     |\n",
            "|    layer2.34.conv2.weight    |    9216    |\n",
            "|     layer2.34.bn2.weight     |     32     |\n",
            "|      layer2.34.bn2.bias      |     32     |\n",
            "|    layer2.35.conv1.weight    |    9216    |\n",
            "|     layer2.35.bn1.weight     |     32     |\n",
            "|      layer2.35.bn1.bias      |     32     |\n",
            "|    layer2.35.conv2.weight    |    9216    |\n",
            "|     layer2.35.bn2.weight     |     32     |\n",
            "|      layer2.35.bn2.bias      |     32     |\n",
            "|    layer2.36.conv1.weight    |    9216    |\n",
            "|     layer2.36.bn1.weight     |     32     |\n",
            "|      layer2.36.bn1.bias      |     32     |\n",
            "|    layer2.36.conv2.weight    |    9216    |\n",
            "|     layer2.36.bn2.weight     |     32     |\n",
            "|      layer2.36.bn2.bias      |     32     |\n",
            "|    layer2.37.conv1.weight    |    9216    |\n",
            "|     layer2.37.bn1.weight     |     32     |\n",
            "|      layer2.37.bn1.bias      |     32     |\n",
            "|    layer2.37.conv2.weight    |    9216    |\n",
            "|     layer2.37.bn2.weight     |     32     |\n",
            "|      layer2.37.bn2.bias      |     32     |\n",
            "|    layer2.38.conv1.weight    |    9216    |\n",
            "|     layer2.38.bn1.weight     |     32     |\n",
            "|      layer2.38.bn1.bias      |     32     |\n",
            "|    layer2.38.conv2.weight    |    9216    |\n",
            "|     layer2.38.bn2.weight     |     32     |\n",
            "|      layer2.38.bn2.bias      |     32     |\n",
            "|    layer2.39.conv1.weight    |    9216    |\n",
            "|     layer2.39.bn1.weight     |     32     |\n",
            "|      layer2.39.bn1.bias      |     32     |\n",
            "|    layer2.39.conv2.weight    |    9216    |\n",
            "|     layer2.39.bn2.weight     |     32     |\n",
            "|      layer2.39.bn2.bias      |     32     |\n",
            "|    layer2.40.conv1.weight    |    9216    |\n",
            "|     layer2.40.bn1.weight     |     32     |\n",
            "|      layer2.40.bn1.bias      |     32     |\n",
            "|    layer2.40.conv2.weight    |    9216    |\n",
            "|     layer2.40.bn2.weight     |     32     |\n",
            "|      layer2.40.bn2.bias      |     32     |\n",
            "|    layer2.41.conv1.weight    |    9216    |\n",
            "|     layer2.41.bn1.weight     |     32     |\n",
            "|      layer2.41.bn1.bias      |     32     |\n",
            "|    layer2.41.conv2.weight    |    9216    |\n",
            "|     layer2.41.bn2.weight     |     32     |\n",
            "|      layer2.41.bn2.bias      |     32     |\n",
            "|    layer2.42.conv1.weight    |    9216    |\n",
            "|     layer2.42.bn1.weight     |     32     |\n",
            "|      layer2.42.bn1.bias      |     32     |\n",
            "|    layer2.42.conv2.weight    |    9216    |\n",
            "|     layer2.42.bn2.weight     |     32     |\n",
            "|      layer2.42.bn2.bias      |     32     |\n",
            "|    layer3.0.conv1.weight     |   18432    |\n",
            "|     layer3.0.bn1.weight      |     64     |\n",
            "|      layer3.0.bn1.bias       |     64     |\n",
            "|    layer3.0.conv2.weight     |   36864    |\n",
            "|     layer3.0.bn2.weight      |     64     |\n",
            "|      layer3.0.bn2.bias       |     64     |\n",
            "| layer3.0.downsample.0.weight |   18432    |\n",
            "| layer3.0.downsample.1.weight |     64     |\n",
            "|  layer3.0.downsample.1.bias  |     64     |\n",
            "|    layer3.1.conv1.weight     |   36864    |\n",
            "|     layer3.1.bn1.weight      |     64     |\n",
            "|      layer3.1.bn1.bias       |     64     |\n",
            "|    layer3.1.conv2.weight     |   36864    |\n",
            "|     layer3.1.bn2.weight      |     64     |\n",
            "|      layer3.1.bn2.bias       |     64     |\n",
            "|    layer3.2.conv1.weight     |   36864    |\n",
            "|     layer3.2.bn1.weight      |     64     |\n",
            "|      layer3.2.bn1.bias       |     64     |\n",
            "|    layer3.2.conv2.weight     |   36864    |\n",
            "|     layer3.2.bn2.weight      |     64     |\n",
            "|      layer3.2.bn2.bias       |     64     |\n",
            "|    layer3.3.conv1.weight     |   36864    |\n",
            "|     layer3.3.bn1.weight      |     64     |\n",
            "|      layer3.3.bn1.bias       |     64     |\n",
            "|    layer3.3.conv2.weight     |   36864    |\n",
            "|     layer3.3.bn2.weight      |     64     |\n",
            "|      layer3.3.bn2.bias       |     64     |\n",
            "|    layer3.4.conv1.weight     |   36864    |\n",
            "|     layer3.4.bn1.weight      |     64     |\n",
            "|      layer3.4.bn1.bias       |     64     |\n",
            "|    layer3.4.conv2.weight     |   36864    |\n",
            "|     layer3.4.bn2.weight      |     64     |\n",
            "|      layer3.4.bn2.bias       |     64     |\n",
            "|    layer3.5.conv1.weight     |   36864    |\n",
            "|     layer3.5.bn1.weight      |     64     |\n",
            "|      layer3.5.bn1.bias       |     64     |\n",
            "|    layer3.5.conv2.weight     |   36864    |\n",
            "|     layer3.5.bn2.weight      |     64     |\n",
            "|      layer3.5.bn2.bias       |     64     |\n",
            "|    layer3.6.conv1.weight     |   36864    |\n",
            "|     layer3.6.bn1.weight      |     64     |\n",
            "|      layer3.6.bn1.bias       |     64     |\n",
            "|    layer3.6.conv2.weight     |   36864    |\n",
            "|     layer3.6.bn2.weight      |     64     |\n",
            "|      layer3.6.bn2.bias       |     64     |\n",
            "|    layer3.7.conv1.weight     |   36864    |\n",
            "|     layer3.7.bn1.weight      |     64     |\n",
            "|      layer3.7.bn1.bias       |     64     |\n",
            "|    layer3.7.conv2.weight     |   36864    |\n",
            "|     layer3.7.bn2.weight      |     64     |\n",
            "|      layer3.7.bn2.bias       |     64     |\n",
            "|    layer3.8.conv1.weight     |   36864    |\n",
            "|     layer3.8.bn1.weight      |     64     |\n",
            "|      layer3.8.bn1.bias       |     64     |\n",
            "|    layer3.8.conv2.weight     |   36864    |\n",
            "|     layer3.8.bn2.weight      |     64     |\n",
            "|      layer3.8.bn2.bias       |     64     |\n",
            "|    layer3.9.conv1.weight     |   36864    |\n",
            "|     layer3.9.bn1.weight      |     64     |\n",
            "|      layer3.9.bn1.bias       |     64     |\n",
            "|    layer3.9.conv2.weight     |   36864    |\n",
            "|     layer3.9.bn2.weight      |     64     |\n",
            "|      layer3.9.bn2.bias       |     64     |\n",
            "|    layer3.10.conv1.weight    |   36864    |\n",
            "|     layer3.10.bn1.weight     |     64     |\n",
            "|      layer3.10.bn1.bias      |     64     |\n",
            "|    layer3.10.conv2.weight    |   36864    |\n",
            "|     layer3.10.bn2.weight     |     64     |\n",
            "|      layer3.10.bn2.bias      |     64     |\n",
            "|    layer3.11.conv1.weight    |   36864    |\n",
            "|     layer3.11.bn1.weight     |     64     |\n",
            "|      layer3.11.bn1.bias      |     64     |\n",
            "|    layer3.11.conv2.weight    |   36864    |\n",
            "|     layer3.11.bn2.weight     |     64     |\n",
            "|      layer3.11.bn2.bias      |     64     |\n",
            "|    layer3.12.conv1.weight    |   36864    |\n",
            "|     layer3.12.bn1.weight     |     64     |\n",
            "|      layer3.12.bn1.bias      |     64     |\n",
            "|    layer3.12.conv2.weight    |   36864    |\n",
            "|     layer3.12.bn2.weight     |     64     |\n",
            "|      layer3.12.bn2.bias      |     64     |\n",
            "|    layer3.13.conv1.weight    |   36864    |\n",
            "|     layer3.13.bn1.weight     |     64     |\n",
            "|      layer3.13.bn1.bias      |     64     |\n",
            "|    layer3.13.conv2.weight    |   36864    |\n",
            "|     layer3.13.bn2.weight     |     64     |\n",
            "|      layer3.13.bn2.bias      |     64     |\n",
            "|    layer3.14.conv1.weight    |   36864    |\n",
            "|     layer3.14.bn1.weight     |     64     |\n",
            "|      layer3.14.bn1.bias      |     64     |\n",
            "|    layer3.14.conv2.weight    |   36864    |\n",
            "|     layer3.14.bn2.weight     |     64     |\n",
            "|      layer3.14.bn2.bias      |     64     |\n",
            "|    layer3.15.conv1.weight    |   36864    |\n",
            "|     layer3.15.bn1.weight     |     64     |\n",
            "|      layer3.15.bn1.bias      |     64     |\n",
            "|    layer3.15.conv2.weight    |   36864    |\n",
            "|     layer3.15.bn2.weight     |     64     |\n",
            "|      layer3.15.bn2.bias      |     64     |\n",
            "|    layer3.16.conv1.weight    |   36864    |\n",
            "|     layer3.16.bn1.weight     |     64     |\n",
            "|      layer3.16.bn1.bias      |     64     |\n",
            "|    layer3.16.conv2.weight    |   36864    |\n",
            "|     layer3.16.bn2.weight     |     64     |\n",
            "|      layer3.16.bn2.bias      |     64     |\n",
            "|    layer3.17.conv1.weight    |   36864    |\n",
            "|     layer3.17.bn1.weight     |     64     |\n",
            "|      layer3.17.bn1.bias      |     64     |\n",
            "|    layer3.17.conv2.weight    |   36864    |\n",
            "|     layer3.17.bn2.weight     |     64     |\n",
            "|      layer3.17.bn2.bias      |     64     |\n",
            "|    layer3.18.conv1.weight    |   36864    |\n",
            "|     layer3.18.bn1.weight     |     64     |\n",
            "|      layer3.18.bn1.bias      |     64     |\n",
            "|    layer3.18.conv2.weight    |   36864    |\n",
            "|     layer3.18.bn2.weight     |     64     |\n",
            "|      layer3.18.bn2.bias      |     64     |\n",
            "|    layer3.19.conv1.weight    |   36864    |\n",
            "|     layer3.19.bn1.weight     |     64     |\n",
            "|      layer3.19.bn1.bias      |     64     |\n",
            "|    layer3.19.conv2.weight    |   36864    |\n",
            "|     layer3.19.bn2.weight     |     64     |\n",
            "|      layer3.19.bn2.bias      |     64     |\n",
            "|    layer3.20.conv1.weight    |   36864    |\n",
            "|     layer3.20.bn1.weight     |     64     |\n",
            "|      layer3.20.bn1.bias      |     64     |\n",
            "|    layer3.20.conv2.weight    |   36864    |\n",
            "|     layer3.20.bn2.weight     |     64     |\n",
            "|      layer3.20.bn2.bias      |     64     |\n",
            "|    layer3.21.conv1.weight    |   36864    |\n",
            "|     layer3.21.bn1.weight     |     64     |\n",
            "|      layer3.21.bn1.bias      |     64     |\n",
            "|    layer3.21.conv2.weight    |   36864    |\n",
            "|     layer3.21.bn2.weight     |     64     |\n",
            "|      layer3.21.bn2.bias      |     64     |\n",
            "|    layer3.22.conv1.weight    |   36864    |\n",
            "|     layer3.22.bn1.weight     |     64     |\n",
            "|      layer3.22.bn1.bias      |     64     |\n",
            "|    layer3.22.conv2.weight    |   36864    |\n",
            "|     layer3.22.bn2.weight     |     64     |\n",
            "|      layer3.22.bn2.bias      |     64     |\n",
            "|    layer3.23.conv1.weight    |   36864    |\n",
            "|     layer3.23.bn1.weight     |     64     |\n",
            "|      layer3.23.bn1.bias      |     64     |\n",
            "|    layer3.23.conv2.weight    |   36864    |\n",
            "|     layer3.23.bn2.weight     |     64     |\n",
            "|      layer3.23.bn2.bias      |     64     |\n",
            "|    layer3.24.conv1.weight    |   36864    |\n",
            "|     layer3.24.bn1.weight     |     64     |\n",
            "|      layer3.24.bn1.bias      |     64     |\n",
            "|    layer3.24.conv2.weight    |   36864    |\n",
            "|     layer3.24.bn2.weight     |     64     |\n",
            "|      layer3.24.bn2.bias      |     64     |\n",
            "|    layer3.25.conv1.weight    |   36864    |\n",
            "|     layer3.25.bn1.weight     |     64     |\n",
            "|      layer3.25.bn1.bias      |     64     |\n",
            "|    layer3.25.conv2.weight    |   36864    |\n",
            "|     layer3.25.bn2.weight     |     64     |\n",
            "|      layer3.25.bn2.bias      |     64     |\n",
            "|    layer3.26.conv1.weight    |   36864    |\n",
            "|     layer3.26.bn1.weight     |     64     |\n",
            "|      layer3.26.bn1.bias      |     64     |\n",
            "|    layer3.26.conv2.weight    |   36864    |\n",
            "|     layer3.26.bn2.weight     |     64     |\n",
            "|      layer3.26.bn2.bias      |     64     |\n",
            "|    layer3.27.conv1.weight    |   36864    |\n",
            "|     layer3.27.bn1.weight     |     64     |\n",
            "|      layer3.27.bn1.bias      |     64     |\n",
            "|    layer3.27.conv2.weight    |   36864    |\n",
            "|     layer3.27.bn2.weight     |     64     |\n",
            "|      layer3.27.bn2.bias      |     64     |\n",
            "|    layer3.28.conv1.weight    |   36864    |\n",
            "|     layer3.28.bn1.weight     |     64     |\n",
            "|      layer3.28.bn1.bias      |     64     |\n",
            "|    layer3.28.conv2.weight    |   36864    |\n",
            "|     layer3.28.bn2.weight     |     64     |\n",
            "|      layer3.28.bn2.bias      |     64     |\n",
            "|    layer3.29.conv1.weight    |   36864    |\n",
            "|     layer3.29.bn1.weight     |     64     |\n",
            "|      layer3.29.bn1.bias      |     64     |\n",
            "|    layer3.29.conv2.weight    |   36864    |\n",
            "|     layer3.29.bn2.weight     |     64     |\n",
            "|      layer3.29.bn2.bias      |     64     |\n",
            "|    layer3.30.conv1.weight    |   36864    |\n",
            "|     layer3.30.bn1.weight     |     64     |\n",
            "|      layer3.30.bn1.bias      |     64     |\n",
            "|    layer3.30.conv2.weight    |   36864    |\n",
            "|     layer3.30.bn2.weight     |     64     |\n",
            "|      layer3.30.bn2.bias      |     64     |\n",
            "|    layer3.31.conv1.weight    |   36864    |\n",
            "|     layer3.31.bn1.weight     |     64     |\n",
            "|      layer3.31.bn1.bias      |     64     |\n",
            "|    layer3.31.conv2.weight    |   36864    |\n",
            "|     layer3.31.bn2.weight     |     64     |\n",
            "|      layer3.31.bn2.bias      |     64     |\n",
            "|    layer3.32.conv1.weight    |   36864    |\n",
            "|     layer3.32.bn1.weight     |     64     |\n",
            "|      layer3.32.bn1.bias      |     64     |\n",
            "|    layer3.32.conv2.weight    |   36864    |\n",
            "|     layer3.32.bn2.weight     |     64     |\n",
            "|      layer3.32.bn2.bias      |     64     |\n",
            "|    layer3.33.conv1.weight    |   36864    |\n",
            "|     layer3.33.bn1.weight     |     64     |\n",
            "|      layer3.33.bn1.bias      |     64     |\n",
            "|    layer3.33.conv2.weight    |   36864    |\n",
            "|     layer3.33.bn2.weight     |     64     |\n",
            "|      layer3.33.bn2.bias      |     64     |\n",
            "|    layer3.34.conv1.weight    |   36864    |\n",
            "|     layer3.34.bn1.weight     |     64     |\n",
            "|      layer3.34.bn1.bias      |     64     |\n",
            "|    layer3.34.conv2.weight    |   36864    |\n",
            "|     layer3.34.bn2.weight     |     64     |\n",
            "|      layer3.34.bn2.bias      |     64     |\n",
            "|    layer3.35.conv1.weight    |   36864    |\n",
            "|     layer3.35.bn1.weight     |     64     |\n",
            "|      layer3.35.bn1.bias      |     64     |\n",
            "|    layer3.35.conv2.weight    |   36864    |\n",
            "|     layer3.35.bn2.weight     |     64     |\n",
            "|      layer3.35.bn2.bias      |     64     |\n",
            "|    layer3.36.conv1.weight    |   36864    |\n",
            "|     layer3.36.bn1.weight     |     64     |\n",
            "|      layer3.36.bn1.bias      |     64     |\n",
            "|    layer3.36.conv2.weight    |   36864    |\n",
            "|     layer3.36.bn2.weight     |     64     |\n",
            "|      layer3.36.bn2.bias      |     64     |\n",
            "|    layer3.37.conv1.weight    |   36864    |\n",
            "|     layer3.37.bn1.weight     |     64     |\n",
            "|      layer3.37.bn1.bias      |     64     |\n",
            "|    layer3.37.conv2.weight    |   36864    |\n",
            "|     layer3.37.bn2.weight     |     64     |\n",
            "|      layer3.37.bn2.bias      |     64     |\n",
            "|    layer3.38.conv1.weight    |   36864    |\n",
            "|     layer3.38.bn1.weight     |     64     |\n",
            "|      layer3.38.bn1.bias      |     64     |\n",
            "|    layer3.38.conv2.weight    |   36864    |\n",
            "|     layer3.38.bn2.weight     |     64     |\n",
            "|      layer3.38.bn2.bias      |     64     |\n",
            "|    layer3.39.conv1.weight    |   36864    |\n",
            "|     layer3.39.bn1.weight     |     64     |\n",
            "|      layer3.39.bn1.bias      |     64     |\n",
            "|    layer3.39.conv2.weight    |   36864    |\n",
            "|     layer3.39.bn2.weight     |     64     |\n",
            "|      layer3.39.bn2.bias      |     64     |\n",
            "|    layer3.40.conv1.weight    |   36864    |\n",
            "|     layer3.40.bn1.weight     |     64     |\n",
            "|      layer3.40.bn1.bias      |     64     |\n",
            "|    layer3.40.conv2.weight    |   36864    |\n",
            "|     layer3.40.bn2.weight     |     64     |\n",
            "|      layer3.40.bn2.bias      |     64     |\n",
            "|    layer3.41.conv1.weight    |   36864    |\n",
            "|     layer3.41.bn1.weight     |     64     |\n",
            "|      layer3.41.bn1.bias      |     64     |\n",
            "|    layer3.41.conv2.weight    |   36864    |\n",
            "|     layer3.41.bn2.weight     |     64     |\n",
            "|      layer3.41.bn2.bias      |     64     |\n",
            "|    layer3.42.conv1.weight    |   36864    |\n",
            "|     layer3.42.bn1.weight     |     64     |\n",
            "|      layer3.42.bn1.bias      |     64     |\n",
            "|    layer3.42.conv2.weight    |   36864    |\n",
            "|     layer3.42.bn2.weight     |     64     |\n",
            "|      layer3.42.bn2.bias      |     64     |\n",
            "|          fc.weight           |    640     |\n",
            "|           fc.bias            |     10     |\n",
            "+------------------------------+------------+\n",
            "Total Trainable Params: 4181594\n",
            "+------------------------------+------------+\n",
            "|           Modules            | Parameters |\n",
            "+------------------------------+------------+\n",
            "|         conv.weight          |    432     |\n",
            "|          bn.weight           |     16     |\n",
            "|           bn.bias            |     16     |\n",
            "|    layer1.0.conv1.weight     |    2304    |\n",
            "|     layer1.0.bn1.weight      |     16     |\n",
            "|      layer1.0.bn1.bias       |     16     |\n",
            "|    layer1.0.conv2.weight     |    2304    |\n",
            "|     layer1.0.bn2.weight      |     16     |\n",
            "|      layer1.0.bn2.bias       |     16     |\n",
            "|    layer1.1.conv1.weight     |    2304    |\n",
            "|     layer1.1.bn1.weight      |     16     |\n",
            "|      layer1.1.bn1.bias       |     16     |\n",
            "|    layer1.1.conv2.weight     |    2304    |\n",
            "|     layer1.1.bn2.weight      |     16     |\n",
            "|      layer1.1.bn2.bias       |     16     |\n",
            "|    layer1.2.conv1.weight     |    2304    |\n",
            "|     layer1.2.bn1.weight      |     16     |\n",
            "|      layer1.2.bn1.bias       |     16     |\n",
            "|    layer1.2.conv2.weight     |    2304    |\n",
            "|     layer1.2.bn2.weight      |     16     |\n",
            "|      layer1.2.bn2.bias       |     16     |\n",
            "|    layer1.3.conv1.weight     |    2304    |\n",
            "|     layer1.3.bn1.weight      |     16     |\n",
            "|      layer1.3.bn1.bias       |     16     |\n",
            "|    layer1.3.conv2.weight     |    2304    |\n",
            "|     layer1.3.bn2.weight      |     16     |\n",
            "|      layer1.3.bn2.bias       |     16     |\n",
            "|    layer1.4.conv1.weight     |    2304    |\n",
            "|     layer1.4.bn1.weight      |     16     |\n",
            "|      layer1.4.bn1.bias       |     16     |\n",
            "|    layer1.4.conv2.weight     |    2304    |\n",
            "|     layer1.4.bn2.weight      |     16     |\n",
            "|      layer1.4.bn2.bias       |     16     |\n",
            "|    layer1.5.conv1.weight     |    2304    |\n",
            "|     layer1.5.bn1.weight      |     16     |\n",
            "|      layer1.5.bn1.bias       |     16     |\n",
            "|    layer1.5.conv2.weight     |    2304    |\n",
            "|     layer1.5.bn2.weight      |     16     |\n",
            "|      layer1.5.bn2.bias       |     16     |\n",
            "|    layer1.6.conv1.weight     |    2304    |\n",
            "|     layer1.6.bn1.weight      |     16     |\n",
            "|      layer1.6.bn1.bias       |     16     |\n",
            "|    layer1.6.conv2.weight     |    2304    |\n",
            "|     layer1.6.bn2.weight      |     16     |\n",
            "|      layer1.6.bn2.bias       |     16     |\n",
            "|    layer1.7.conv1.weight     |    2304    |\n",
            "|     layer1.7.bn1.weight      |     16     |\n",
            "|      layer1.7.bn1.bias       |     16     |\n",
            "|    layer1.7.conv2.weight     |    2304    |\n",
            "|     layer1.7.bn2.weight      |     16     |\n",
            "|      layer1.7.bn2.bias       |     16     |\n",
            "|    layer1.8.conv1.weight     |    2304    |\n",
            "|     layer1.8.bn1.weight      |     16     |\n",
            "|      layer1.8.bn1.bias       |     16     |\n",
            "|    layer1.8.conv2.weight     |    2304    |\n",
            "|     layer1.8.bn2.weight      |     16     |\n",
            "|      layer1.8.bn2.bias       |     16     |\n",
            "|    layer1.9.conv1.weight     |    2304    |\n",
            "|     layer1.9.bn1.weight      |     16     |\n",
            "|      layer1.9.bn1.bias       |     16     |\n",
            "|    layer1.9.conv2.weight     |    2304    |\n",
            "|     layer1.9.bn2.weight      |     16     |\n",
            "|      layer1.9.bn2.bias       |     16     |\n",
            "|    layer1.10.conv1.weight    |    2304    |\n",
            "|     layer1.10.bn1.weight     |     16     |\n",
            "|      layer1.10.bn1.bias      |     16     |\n",
            "|    layer1.10.conv2.weight    |    2304    |\n",
            "|     layer1.10.bn2.weight     |     16     |\n",
            "|      layer1.10.bn2.bias      |     16     |\n",
            "|    layer1.11.conv1.weight    |    2304    |\n",
            "|     layer1.11.bn1.weight     |     16     |\n",
            "|      layer1.11.bn1.bias      |     16     |\n",
            "|    layer1.11.conv2.weight    |    2304    |\n",
            "|     layer1.11.bn2.weight     |     16     |\n",
            "|      layer1.11.bn2.bias      |     16     |\n",
            "|    layer1.12.conv1.weight    |    2304    |\n",
            "|     layer1.12.bn1.weight     |     16     |\n",
            "|      layer1.12.bn1.bias      |     16     |\n",
            "|    layer1.12.conv2.weight    |    2304    |\n",
            "|     layer1.12.bn2.weight     |     16     |\n",
            "|      layer1.12.bn2.bias      |     16     |\n",
            "|    layer1.13.conv1.weight    |    2304    |\n",
            "|     layer1.13.bn1.weight     |     16     |\n",
            "|      layer1.13.bn1.bias      |     16     |\n",
            "|    layer1.13.conv2.weight    |    2304    |\n",
            "|     layer1.13.bn2.weight     |     16     |\n",
            "|      layer1.13.bn2.bias      |     16     |\n",
            "|    layer1.14.conv1.weight    |    2304    |\n",
            "|     layer1.14.bn1.weight     |     16     |\n",
            "|      layer1.14.bn1.bias      |     16     |\n",
            "|    layer1.14.conv2.weight    |    2304    |\n",
            "|     layer1.14.bn2.weight     |     16     |\n",
            "|      layer1.14.bn2.bias      |     16     |\n",
            "|    layer1.15.conv1.weight    |    2304    |\n",
            "|     layer1.15.bn1.weight     |     16     |\n",
            "|      layer1.15.bn1.bias      |     16     |\n",
            "|    layer1.15.conv2.weight    |    2304    |\n",
            "|     layer1.15.bn2.weight     |     16     |\n",
            "|      layer1.15.bn2.bias      |     16     |\n",
            "|    layer1.16.conv1.weight    |    2304    |\n",
            "|     layer1.16.bn1.weight     |     16     |\n",
            "|      layer1.16.bn1.bias      |     16     |\n",
            "|    layer1.16.conv2.weight    |    2304    |\n",
            "|     layer1.16.bn2.weight     |     16     |\n",
            "|      layer1.16.bn2.bias      |     16     |\n",
            "|    layer1.17.conv1.weight    |    2304    |\n",
            "|     layer1.17.bn1.weight     |     16     |\n",
            "|      layer1.17.bn1.bias      |     16     |\n",
            "|    layer1.17.conv2.weight    |    2304    |\n",
            "|     layer1.17.bn2.weight     |     16     |\n",
            "|      layer1.17.bn2.bias      |     16     |\n",
            "|    layer1.18.conv1.weight    |    2304    |\n",
            "|     layer1.18.bn1.weight     |     16     |\n",
            "|      layer1.18.bn1.bias      |     16     |\n",
            "|    layer1.18.conv2.weight    |    2304    |\n",
            "|     layer1.18.bn2.weight     |     16     |\n",
            "|      layer1.18.bn2.bias      |     16     |\n",
            "|    layer1.19.conv1.weight    |    2304    |\n",
            "|     layer1.19.bn1.weight     |     16     |\n",
            "|      layer1.19.bn1.bias      |     16     |\n",
            "|    layer1.19.conv2.weight    |    2304    |\n",
            "|     layer1.19.bn2.weight     |     16     |\n",
            "|      layer1.19.bn2.bias      |     16     |\n",
            "|    layer1.20.conv1.weight    |    2304    |\n",
            "|     layer1.20.bn1.weight     |     16     |\n",
            "|      layer1.20.bn1.bias      |     16     |\n",
            "|    layer1.20.conv2.weight    |    2304    |\n",
            "|     layer1.20.bn2.weight     |     16     |\n",
            "|      layer1.20.bn2.bias      |     16     |\n",
            "|    layer1.21.conv1.weight    |    2304    |\n",
            "|     layer1.21.bn1.weight     |     16     |\n",
            "|      layer1.21.bn1.bias      |     16     |\n",
            "|    layer1.21.conv2.weight    |    2304    |\n",
            "|     layer1.21.bn2.weight     |     16     |\n",
            "|      layer1.21.bn2.bias      |     16     |\n",
            "|    layer1.22.conv1.weight    |    2304    |\n",
            "|     layer1.22.bn1.weight     |     16     |\n",
            "|      layer1.22.bn1.bias      |     16     |\n",
            "|    layer1.22.conv2.weight    |    2304    |\n",
            "|     layer1.22.bn2.weight     |     16     |\n",
            "|      layer1.22.bn2.bias      |     16     |\n",
            "|    layer1.23.conv1.weight    |    2304    |\n",
            "|     layer1.23.bn1.weight     |     16     |\n",
            "|      layer1.23.bn1.bias      |     16     |\n",
            "|    layer1.23.conv2.weight    |    2304    |\n",
            "|     layer1.23.bn2.weight     |     16     |\n",
            "|      layer1.23.bn2.bias      |     16     |\n",
            "|    layer1.24.conv1.weight    |    2304    |\n",
            "|     layer1.24.bn1.weight     |     16     |\n",
            "|      layer1.24.bn1.bias      |     16     |\n",
            "|    layer1.24.conv2.weight    |    2304    |\n",
            "|     layer1.24.bn2.weight     |     16     |\n",
            "|      layer1.24.bn2.bias      |     16     |\n",
            "|    layer1.25.conv1.weight    |    2304    |\n",
            "|     layer1.25.bn1.weight     |     16     |\n",
            "|      layer1.25.bn1.bias      |     16     |\n",
            "|    layer1.25.conv2.weight    |    2304    |\n",
            "|     layer1.25.bn2.weight     |     16     |\n",
            "|      layer1.25.bn2.bias      |     16     |\n",
            "|    layer1.26.conv1.weight    |    2304    |\n",
            "|     layer1.26.bn1.weight     |     16     |\n",
            "|      layer1.26.bn1.bias      |     16     |\n",
            "|    layer1.26.conv2.weight    |    2304    |\n",
            "|     layer1.26.bn2.weight     |     16     |\n",
            "|      layer1.26.bn2.bias      |     16     |\n",
            "|    layer1.27.conv1.weight    |    2304    |\n",
            "|     layer1.27.bn1.weight     |     16     |\n",
            "|      layer1.27.bn1.bias      |     16     |\n",
            "|    layer1.27.conv2.weight    |    2304    |\n",
            "|     layer1.27.bn2.weight     |     16     |\n",
            "|      layer1.27.bn2.bias      |     16     |\n",
            "|    layer1.28.conv1.weight    |    2304    |\n",
            "|     layer1.28.bn1.weight     |     16     |\n",
            "|      layer1.28.bn1.bias      |     16     |\n",
            "|    layer1.28.conv2.weight    |    2304    |\n",
            "|     layer1.28.bn2.weight     |     16     |\n",
            "|      layer1.28.bn2.bias      |     16     |\n",
            "|    layer1.29.conv1.weight    |    2304    |\n",
            "|     layer1.29.bn1.weight     |     16     |\n",
            "|      layer1.29.bn1.bias      |     16     |\n",
            "|    layer1.29.conv2.weight    |    2304    |\n",
            "|     layer1.29.bn2.weight     |     16     |\n",
            "|      layer1.29.bn2.bias      |     16     |\n",
            "|    layer1.30.conv1.weight    |    2304    |\n",
            "|     layer1.30.bn1.weight     |     16     |\n",
            "|      layer1.30.bn1.bias      |     16     |\n",
            "|    layer1.30.conv2.weight    |    2304    |\n",
            "|     layer1.30.bn2.weight     |     16     |\n",
            "|      layer1.30.bn2.bias      |     16     |\n",
            "|    layer1.31.conv1.weight    |    2304    |\n",
            "|     layer1.31.bn1.weight     |     16     |\n",
            "|      layer1.31.bn1.bias      |     16     |\n",
            "|    layer1.31.conv2.weight    |    2304    |\n",
            "|     layer1.31.bn2.weight     |     16     |\n",
            "|      layer1.31.bn2.bias      |     16     |\n",
            "|    layer1.32.conv1.weight    |    2304    |\n",
            "|     layer1.32.bn1.weight     |     16     |\n",
            "|      layer1.32.bn1.bias      |     16     |\n",
            "|    layer1.32.conv2.weight    |    2304    |\n",
            "|     layer1.32.bn2.weight     |     16     |\n",
            "|      layer1.32.bn2.bias      |     16     |\n",
            "|    layer1.33.conv1.weight    |    2304    |\n",
            "|     layer1.33.bn1.weight     |     16     |\n",
            "|      layer1.33.bn1.bias      |     16     |\n",
            "|    layer1.33.conv2.weight    |    2304    |\n",
            "|     layer1.33.bn2.weight     |     16     |\n",
            "|      layer1.33.bn2.bias      |     16     |\n",
            "|    layer1.34.conv1.weight    |    2304    |\n",
            "|     layer1.34.bn1.weight     |     16     |\n",
            "|      layer1.34.bn1.bias      |     16     |\n",
            "|    layer1.34.conv2.weight    |    2304    |\n",
            "|     layer1.34.bn2.weight     |     16     |\n",
            "|      layer1.34.bn2.bias      |     16     |\n",
            "|    layer1.35.conv1.weight    |    2304    |\n",
            "|     layer1.35.bn1.weight     |     16     |\n",
            "|      layer1.35.bn1.bias      |     16     |\n",
            "|    layer1.35.conv2.weight    |    2304    |\n",
            "|     layer1.35.bn2.weight     |     16     |\n",
            "|      layer1.35.bn2.bias      |     16     |\n",
            "|    layer1.36.conv1.weight    |    2304    |\n",
            "|     layer1.36.bn1.weight     |     16     |\n",
            "|      layer1.36.bn1.bias      |     16     |\n",
            "|    layer1.36.conv2.weight    |    2304    |\n",
            "|     layer1.36.bn2.weight     |     16     |\n",
            "|      layer1.36.bn2.bias      |     16     |\n",
            "|    layer1.37.conv1.weight    |    2304    |\n",
            "|     layer1.37.bn1.weight     |     16     |\n",
            "|      layer1.37.bn1.bias      |     16     |\n",
            "|    layer1.37.conv2.weight    |    2304    |\n",
            "|     layer1.37.bn2.weight     |     16     |\n",
            "|      layer1.37.bn2.bias      |     16     |\n",
            "|    layer1.38.conv1.weight    |    2304    |\n",
            "|     layer1.38.bn1.weight     |     16     |\n",
            "|      layer1.38.bn1.bias      |     16     |\n",
            "|    layer1.38.conv2.weight    |    2304    |\n",
            "|     layer1.38.bn2.weight     |     16     |\n",
            "|      layer1.38.bn2.bias      |     16     |\n",
            "|    layer1.39.conv1.weight    |    2304    |\n",
            "|     layer1.39.bn1.weight     |     16     |\n",
            "|      layer1.39.bn1.bias      |     16     |\n",
            "|    layer1.39.conv2.weight    |    2304    |\n",
            "|     layer1.39.bn2.weight     |     16     |\n",
            "|      layer1.39.bn2.bias      |     16     |\n",
            "|    layer1.40.conv1.weight    |    2304    |\n",
            "|     layer1.40.bn1.weight     |     16     |\n",
            "|      layer1.40.bn1.bias      |     16     |\n",
            "|    layer1.40.conv2.weight    |    2304    |\n",
            "|     layer1.40.bn2.weight     |     16     |\n",
            "|      layer1.40.bn2.bias      |     16     |\n",
            "|    layer1.41.conv1.weight    |    2304    |\n",
            "|     layer1.41.bn1.weight     |     16     |\n",
            "|      layer1.41.bn1.bias      |     16     |\n",
            "|    layer1.41.conv2.weight    |    2304    |\n",
            "|     layer1.41.bn2.weight     |     16     |\n",
            "|      layer1.41.bn2.bias      |     16     |\n",
            "|    layer1.42.conv1.weight    |    2304    |\n",
            "|     layer1.42.bn1.weight     |     16     |\n",
            "|      layer1.42.bn1.bias      |     16     |\n",
            "|    layer1.42.conv2.weight    |    2304    |\n",
            "|     layer1.42.bn2.weight     |     16     |\n",
            "|      layer1.42.bn2.bias      |     16     |\n",
            "|    layer1.43.conv1.weight    |    2304    |\n",
            "|     layer1.43.bn1.weight     |     16     |\n",
            "|      layer1.43.bn1.bias      |     16     |\n",
            "|    layer1.43.conv2.weight    |    2304    |\n",
            "|     layer1.43.bn2.weight     |     16     |\n",
            "|      layer1.43.bn2.bias      |     16     |\n",
            "|    layer1.44.conv1.weight    |    2304    |\n",
            "|     layer1.44.bn1.weight     |     16     |\n",
            "|      layer1.44.bn1.bias      |     16     |\n",
            "|    layer1.44.conv2.weight    |    2304    |\n",
            "|     layer1.44.bn2.weight     |     16     |\n",
            "|      layer1.44.bn2.bias      |     16     |\n",
            "|    layer1.45.conv1.weight    |    2304    |\n",
            "|     layer1.45.bn1.weight     |     16     |\n",
            "|      layer1.45.bn1.bias      |     16     |\n",
            "|    layer1.45.conv2.weight    |    2304    |\n",
            "|     layer1.45.bn2.weight     |     16     |\n",
            "|      layer1.45.bn2.bias      |     16     |\n",
            "|    layer1.46.conv1.weight    |    2304    |\n",
            "|     layer1.46.bn1.weight     |     16     |\n",
            "|      layer1.46.bn1.bias      |     16     |\n",
            "|    layer1.46.conv2.weight    |    2304    |\n",
            "|     layer1.46.bn2.weight     |     16     |\n",
            "|      layer1.46.bn2.bias      |     16     |\n",
            "|    layer1.47.conv1.weight    |    2304    |\n",
            "|     layer1.47.bn1.weight     |     16     |\n",
            "|      layer1.47.bn1.bias      |     16     |\n",
            "|    layer1.47.conv2.weight    |    2304    |\n",
            "|     layer1.47.bn2.weight     |     16     |\n",
            "|      layer1.47.bn2.bias      |     16     |\n",
            "|    layer1.48.conv1.weight    |    2304    |\n",
            "|     layer1.48.bn1.weight     |     16     |\n",
            "|      layer1.48.bn1.bias      |     16     |\n",
            "|    layer1.48.conv2.weight    |    2304    |\n",
            "|     layer1.48.bn2.weight     |     16     |\n",
            "|      layer1.48.bn2.bias      |     16     |\n",
            "|    layer1.49.conv1.weight    |    2304    |\n",
            "|     layer1.49.bn1.weight     |     16     |\n",
            "|      layer1.49.bn1.bias      |     16     |\n",
            "|    layer1.49.conv2.weight    |    2304    |\n",
            "|     layer1.49.bn2.weight     |     16     |\n",
            "|      layer1.49.bn2.bias      |     16     |\n",
            "|    layer1.50.conv1.weight    |    2304    |\n",
            "|     layer1.50.bn1.weight     |     16     |\n",
            "|      layer1.50.bn1.bias      |     16     |\n",
            "|    layer1.50.conv2.weight    |    2304    |\n",
            "|     layer1.50.bn2.weight     |     16     |\n",
            "|      layer1.50.bn2.bias      |     16     |\n",
            "|    layer1.51.conv1.weight    |    2304    |\n",
            "|     layer1.51.bn1.weight     |     16     |\n",
            "|      layer1.51.bn1.bias      |     16     |\n",
            "|    layer1.51.conv2.weight    |    2304    |\n",
            "|     layer1.51.bn2.weight     |     16     |\n",
            "|      layer1.51.bn2.bias      |     16     |\n",
            "|    layer1.52.conv1.weight    |    2304    |\n",
            "|     layer1.52.bn1.weight     |     16     |\n",
            "|      layer1.52.bn1.bias      |     16     |\n",
            "|    layer1.52.conv2.weight    |    2304    |\n",
            "|     layer1.52.bn2.weight     |     16     |\n",
            "|      layer1.52.bn2.bias      |     16     |\n",
            "|    layer1.53.conv1.weight    |    2304    |\n",
            "|     layer1.53.bn1.weight     |     16     |\n",
            "|      layer1.53.bn1.bias      |     16     |\n",
            "|    layer1.53.conv2.weight    |    2304    |\n",
            "|     layer1.53.bn2.weight     |     16     |\n",
            "|      layer1.53.bn2.bias      |     16     |\n",
            "|    layer1.54.conv1.weight    |    2304    |\n",
            "|     layer1.54.bn1.weight     |     16     |\n",
            "|      layer1.54.bn1.bias      |     16     |\n",
            "|    layer1.54.conv2.weight    |    2304    |\n",
            "|     layer1.54.bn2.weight     |     16     |\n",
            "|      layer1.54.bn2.bias      |     16     |\n",
            "|    layer2.0.conv1.weight     |    4608    |\n",
            "|     layer2.0.bn1.weight      |     32     |\n",
            "|      layer2.0.bn1.bias       |     32     |\n",
            "|    layer2.0.conv2.weight     |    9216    |\n",
            "|     layer2.0.bn2.weight      |     32     |\n",
            "|      layer2.0.bn2.bias       |     32     |\n",
            "| layer2.0.downsample.0.weight |    4608    |\n",
            "| layer2.0.downsample.1.weight |     32     |\n",
            "|  layer2.0.downsample.1.bias  |     32     |\n",
            "|    layer2.1.conv1.weight     |    9216    |\n",
            "|     layer2.1.bn1.weight      |     32     |\n",
            "|      layer2.1.bn1.bias       |     32     |\n",
            "|    layer2.1.conv2.weight     |    9216    |\n",
            "|     layer2.1.bn2.weight      |     32     |\n",
            "|      layer2.1.bn2.bias       |     32     |\n",
            "|    layer2.2.conv1.weight     |    9216    |\n",
            "|     layer2.2.bn1.weight      |     32     |\n",
            "|      layer2.2.bn1.bias       |     32     |\n",
            "|    layer2.2.conv2.weight     |    9216    |\n",
            "|     layer2.2.bn2.weight      |     32     |\n",
            "|      layer2.2.bn2.bias       |     32     |\n",
            "|    layer2.3.conv1.weight     |    9216    |\n",
            "|     layer2.3.bn1.weight      |     32     |\n",
            "|      layer2.3.bn1.bias       |     32     |\n",
            "|    layer2.3.conv2.weight     |    9216    |\n",
            "|     layer2.3.bn2.weight      |     32     |\n",
            "|      layer2.3.bn2.bias       |     32     |\n",
            "|    layer2.4.conv1.weight     |    9216    |\n",
            "|     layer2.4.bn1.weight      |     32     |\n",
            "|      layer2.4.bn1.bias       |     32     |\n",
            "|    layer2.4.conv2.weight     |    9216    |\n",
            "|     layer2.4.bn2.weight      |     32     |\n",
            "|      layer2.4.bn2.bias       |     32     |\n",
            "|    layer2.5.conv1.weight     |    9216    |\n",
            "|     layer2.5.bn1.weight      |     32     |\n",
            "|      layer2.5.bn1.bias       |     32     |\n",
            "|    layer2.5.conv2.weight     |    9216    |\n",
            "|     layer2.5.bn2.weight      |     32     |\n",
            "|      layer2.5.bn2.bias       |     32     |\n",
            "|    layer2.6.conv1.weight     |    9216    |\n",
            "|     layer2.6.bn1.weight      |     32     |\n",
            "|      layer2.6.bn1.bias       |     32     |\n",
            "|    layer2.6.conv2.weight     |    9216    |\n",
            "|     layer2.6.bn2.weight      |     32     |\n",
            "|      layer2.6.bn2.bias       |     32     |\n",
            "|    layer2.7.conv1.weight     |    9216    |\n",
            "|     layer2.7.bn1.weight      |     32     |\n",
            "|      layer2.7.bn1.bias       |     32     |\n",
            "|    layer2.7.conv2.weight     |    9216    |\n",
            "|     layer2.7.bn2.weight      |     32     |\n",
            "|      layer2.7.bn2.bias       |     32     |\n",
            "|    layer2.8.conv1.weight     |    9216    |\n",
            "|     layer2.8.bn1.weight      |     32     |\n",
            "|      layer2.8.bn1.bias       |     32     |\n",
            "|    layer2.8.conv2.weight     |    9216    |\n",
            "|     layer2.8.bn2.weight      |     32     |\n",
            "|      layer2.8.bn2.bias       |     32     |\n",
            "|    layer2.9.conv1.weight     |    9216    |\n",
            "|     layer2.9.bn1.weight      |     32     |\n",
            "|      layer2.9.bn1.bias       |     32     |\n",
            "|    layer2.9.conv2.weight     |    9216    |\n",
            "|     layer2.9.bn2.weight      |     32     |\n",
            "|      layer2.9.bn2.bias       |     32     |\n",
            "|    layer2.10.conv1.weight    |    9216    |\n",
            "|     layer2.10.bn1.weight     |     32     |\n",
            "|      layer2.10.bn1.bias      |     32     |\n",
            "|    layer2.10.conv2.weight    |    9216    |\n",
            "|     layer2.10.bn2.weight     |     32     |\n",
            "|      layer2.10.bn2.bias      |     32     |\n",
            "|    layer2.11.conv1.weight    |    9216    |\n",
            "|     layer2.11.bn1.weight     |     32     |\n",
            "|      layer2.11.bn1.bias      |     32     |\n",
            "|    layer2.11.conv2.weight    |    9216    |\n",
            "|     layer2.11.bn2.weight     |     32     |\n",
            "|      layer2.11.bn2.bias      |     32     |\n",
            "|    layer2.12.conv1.weight    |    9216    |\n",
            "|     layer2.12.bn1.weight     |     32     |\n",
            "|      layer2.12.bn1.bias      |     32     |\n",
            "|    layer2.12.conv2.weight    |    9216    |\n",
            "|     layer2.12.bn2.weight     |     32     |\n",
            "|      layer2.12.bn2.bias      |     32     |\n",
            "|    layer2.13.conv1.weight    |    9216    |\n",
            "|     layer2.13.bn1.weight     |     32     |\n",
            "|      layer2.13.bn1.bias      |     32     |\n",
            "|    layer2.13.conv2.weight    |    9216    |\n",
            "|     layer2.13.bn2.weight     |     32     |\n",
            "|      layer2.13.bn2.bias      |     32     |\n",
            "|    layer2.14.conv1.weight    |    9216    |\n",
            "|     layer2.14.bn1.weight     |     32     |\n",
            "|      layer2.14.bn1.bias      |     32     |\n",
            "|    layer2.14.conv2.weight    |    9216    |\n",
            "|     layer2.14.bn2.weight     |     32     |\n",
            "|      layer2.14.bn2.bias      |     32     |\n",
            "|    layer2.15.conv1.weight    |    9216    |\n",
            "|     layer2.15.bn1.weight     |     32     |\n",
            "|      layer2.15.bn1.bias      |     32     |\n",
            "|    layer2.15.conv2.weight    |    9216    |\n",
            "|     layer2.15.bn2.weight     |     32     |\n",
            "|      layer2.15.bn2.bias      |     32     |\n",
            "|    layer2.16.conv1.weight    |    9216    |\n",
            "|     layer2.16.bn1.weight     |     32     |\n",
            "|      layer2.16.bn1.bias      |     32     |\n",
            "|    layer2.16.conv2.weight    |    9216    |\n",
            "|     layer2.16.bn2.weight     |     32     |\n",
            "|      layer2.16.bn2.bias      |     32     |\n",
            "|    layer2.17.conv1.weight    |    9216    |\n",
            "|     layer2.17.bn1.weight     |     32     |\n",
            "|      layer2.17.bn1.bias      |     32     |\n",
            "|    layer2.17.conv2.weight    |    9216    |\n",
            "|     layer2.17.bn2.weight     |     32     |\n",
            "|      layer2.17.bn2.bias      |     32     |\n",
            "|    layer2.18.conv1.weight    |    9216    |\n",
            "|     layer2.18.bn1.weight     |     32     |\n",
            "|      layer2.18.bn1.bias      |     32     |\n",
            "|    layer2.18.conv2.weight    |    9216    |\n",
            "|     layer2.18.bn2.weight     |     32     |\n",
            "|      layer2.18.bn2.bias      |     32     |\n",
            "|    layer2.19.conv1.weight    |    9216    |\n",
            "|     layer2.19.bn1.weight     |     32     |\n",
            "|      layer2.19.bn1.bias      |     32     |\n",
            "|    layer2.19.conv2.weight    |    9216    |\n",
            "|     layer2.19.bn2.weight     |     32     |\n",
            "|      layer2.19.bn2.bias      |     32     |\n",
            "|    layer2.20.conv1.weight    |    9216    |\n",
            "|     layer2.20.bn1.weight     |     32     |\n",
            "|      layer2.20.bn1.bias      |     32     |\n",
            "|    layer2.20.conv2.weight    |    9216    |\n",
            "|     layer2.20.bn2.weight     |     32     |\n",
            "|      layer2.20.bn2.bias      |     32     |\n",
            "|    layer2.21.conv1.weight    |    9216    |\n",
            "|     layer2.21.bn1.weight     |     32     |\n",
            "|      layer2.21.bn1.bias      |     32     |\n",
            "|    layer2.21.conv2.weight    |    9216    |\n",
            "|     layer2.21.bn2.weight     |     32     |\n",
            "|      layer2.21.bn2.bias      |     32     |\n",
            "|    layer2.22.conv1.weight    |    9216    |\n",
            "|     layer2.22.bn1.weight     |     32     |\n",
            "|      layer2.22.bn1.bias      |     32     |\n",
            "|    layer2.22.conv2.weight    |    9216    |\n",
            "|     layer2.22.bn2.weight     |     32     |\n",
            "|      layer2.22.bn2.bias      |     32     |\n",
            "|    layer2.23.conv1.weight    |    9216    |\n",
            "|     layer2.23.bn1.weight     |     32     |\n",
            "|      layer2.23.bn1.bias      |     32     |\n",
            "|    layer2.23.conv2.weight    |    9216    |\n",
            "|     layer2.23.bn2.weight     |     32     |\n",
            "|      layer2.23.bn2.bias      |     32     |\n",
            "|    layer2.24.conv1.weight    |    9216    |\n",
            "|     layer2.24.bn1.weight     |     32     |\n",
            "|      layer2.24.bn1.bias      |     32     |\n",
            "|    layer2.24.conv2.weight    |    9216    |\n",
            "|     layer2.24.bn2.weight     |     32     |\n",
            "|      layer2.24.bn2.bias      |     32     |\n",
            "|    layer2.25.conv1.weight    |    9216    |\n",
            "|     layer2.25.bn1.weight     |     32     |\n",
            "|      layer2.25.bn1.bias      |     32     |\n",
            "|    layer2.25.conv2.weight    |    9216    |\n",
            "|     layer2.25.bn2.weight     |     32     |\n",
            "|      layer2.25.bn2.bias      |     32     |\n",
            "|    layer2.26.conv1.weight    |    9216    |\n",
            "|     layer2.26.bn1.weight     |     32     |\n",
            "|      layer2.26.bn1.bias      |     32     |\n",
            "|    layer2.26.conv2.weight    |    9216    |\n",
            "|     layer2.26.bn2.weight     |     32     |\n",
            "|      layer2.26.bn2.bias      |     32     |\n",
            "|    layer2.27.conv1.weight    |    9216    |\n",
            "|     layer2.27.bn1.weight     |     32     |\n",
            "|      layer2.27.bn1.bias      |     32     |\n",
            "|    layer2.27.conv2.weight    |    9216    |\n",
            "|     layer2.27.bn2.weight     |     32     |\n",
            "|      layer2.27.bn2.bias      |     32     |\n",
            "|    layer2.28.conv1.weight    |    9216    |\n",
            "|     layer2.28.bn1.weight     |     32     |\n",
            "|      layer2.28.bn1.bias      |     32     |\n",
            "|    layer2.28.conv2.weight    |    9216    |\n",
            "|     layer2.28.bn2.weight     |     32     |\n",
            "|      layer2.28.bn2.bias      |     32     |\n",
            "|    layer2.29.conv1.weight    |    9216    |\n",
            "|     layer2.29.bn1.weight     |     32     |\n",
            "|      layer2.29.bn1.bias      |     32     |\n",
            "|    layer2.29.conv2.weight    |    9216    |\n",
            "|     layer2.29.bn2.weight     |     32     |\n",
            "|      layer2.29.bn2.bias      |     32     |\n",
            "|    layer2.30.conv1.weight    |    9216    |\n",
            "|     layer2.30.bn1.weight     |     32     |\n",
            "|      layer2.30.bn1.bias      |     32     |\n",
            "|    layer2.30.conv2.weight    |    9216    |\n",
            "|     layer2.30.bn2.weight     |     32     |\n",
            "|      layer2.30.bn2.bias      |     32     |\n",
            "|    layer2.31.conv1.weight    |    9216    |\n",
            "|     layer2.31.bn1.weight     |     32     |\n",
            "|      layer2.31.bn1.bias      |     32     |\n",
            "|    layer2.31.conv2.weight    |    9216    |\n",
            "|     layer2.31.bn2.weight     |     32     |\n",
            "|      layer2.31.bn2.bias      |     32     |\n",
            "|    layer2.32.conv1.weight    |    9216    |\n",
            "|     layer2.32.bn1.weight     |     32     |\n",
            "|      layer2.32.bn1.bias      |     32     |\n",
            "|    layer2.32.conv2.weight    |    9216    |\n",
            "|     layer2.32.bn2.weight     |     32     |\n",
            "|      layer2.32.bn2.bias      |     32     |\n",
            "|    layer2.33.conv1.weight    |    9216    |\n",
            "|     layer2.33.bn1.weight     |     32     |\n",
            "|      layer2.33.bn1.bias      |     32     |\n",
            "|    layer2.33.conv2.weight    |    9216    |\n",
            "|     layer2.33.bn2.weight     |     32     |\n",
            "|      layer2.33.bn2.bias      |     32     |\n",
            "|    layer2.34.conv1.weight    |    9216    |\n",
            "|     layer2.34.bn1.weight     |     32     |\n",
            "|      layer2.34.bn1.bias      |     32     |\n",
            "|    layer2.34.conv2.weight    |    9216    |\n",
            "|     layer2.34.bn2.weight     |     32     |\n",
            "|      layer2.34.bn2.bias      |     32     |\n",
            "|    layer2.35.conv1.weight    |    9216    |\n",
            "|     layer2.35.bn1.weight     |     32     |\n",
            "|      layer2.35.bn1.bias      |     32     |\n",
            "|    layer2.35.conv2.weight    |    9216    |\n",
            "|     layer2.35.bn2.weight     |     32     |\n",
            "|      layer2.35.bn2.bias      |     32     |\n",
            "|    layer2.36.conv1.weight    |    9216    |\n",
            "|     layer2.36.bn1.weight     |     32     |\n",
            "|      layer2.36.bn1.bias      |     32     |\n",
            "|    layer2.36.conv2.weight    |    9216    |\n",
            "|     layer2.36.bn2.weight     |     32     |\n",
            "|      layer2.36.bn2.bias      |     32     |\n",
            "|    layer2.37.conv1.weight    |    9216    |\n",
            "|     layer2.37.bn1.weight     |     32     |\n",
            "|      layer2.37.bn1.bias      |     32     |\n",
            "|    layer2.37.conv2.weight    |    9216    |\n",
            "|     layer2.37.bn2.weight     |     32     |\n",
            "|      layer2.37.bn2.bias      |     32     |\n",
            "|    layer2.38.conv1.weight    |    9216    |\n",
            "|     layer2.38.bn1.weight     |     32     |\n",
            "|      layer2.38.bn1.bias      |     32     |\n",
            "|    layer2.38.conv2.weight    |    9216    |\n",
            "|     layer2.38.bn2.weight     |     32     |\n",
            "|      layer2.38.bn2.bias      |     32     |\n",
            "|    layer2.39.conv1.weight    |    9216    |\n",
            "|     layer2.39.bn1.weight     |     32     |\n",
            "|      layer2.39.bn1.bias      |     32     |\n",
            "|    layer2.39.conv2.weight    |    9216    |\n",
            "|     layer2.39.bn2.weight     |     32     |\n",
            "|      layer2.39.bn2.bias      |     32     |\n",
            "|    layer2.40.conv1.weight    |    9216    |\n",
            "|     layer2.40.bn1.weight     |     32     |\n",
            "|      layer2.40.bn1.bias      |     32     |\n",
            "|    layer2.40.conv2.weight    |    9216    |\n",
            "|     layer2.40.bn2.weight     |     32     |\n",
            "|      layer2.40.bn2.bias      |     32     |\n",
            "|    layer2.41.conv1.weight    |    9216    |\n",
            "|     layer2.41.bn1.weight     |     32     |\n",
            "|      layer2.41.bn1.bias      |     32     |\n",
            "|    layer2.41.conv2.weight    |    9216    |\n",
            "|     layer2.41.bn2.weight     |     32     |\n",
            "|      layer2.41.bn2.bias      |     32     |\n",
            "|    layer2.42.conv1.weight    |    9216    |\n",
            "|     layer2.42.bn1.weight     |     32     |\n",
            "|      layer2.42.bn1.bias      |     32     |\n",
            "|    layer2.42.conv2.weight    |    9216    |\n",
            "|     layer2.42.bn2.weight     |     32     |\n",
            "|      layer2.42.bn2.bias      |     32     |\n",
            "|    layer2.43.conv1.weight    |    9216    |\n",
            "|     layer2.43.bn1.weight     |     32     |\n",
            "|      layer2.43.bn1.bias      |     32     |\n",
            "|    layer2.43.conv2.weight    |    9216    |\n",
            "|     layer2.43.bn2.weight     |     32     |\n",
            "|      layer2.43.bn2.bias      |     32     |\n",
            "|    layer2.44.conv1.weight    |    9216    |\n",
            "|     layer2.44.bn1.weight     |     32     |\n",
            "|      layer2.44.bn1.bias      |     32     |\n",
            "|    layer2.44.conv2.weight    |    9216    |\n",
            "|     layer2.44.bn2.weight     |     32     |\n",
            "|      layer2.44.bn2.bias      |     32     |\n",
            "|    layer2.45.conv1.weight    |    9216    |\n",
            "|     layer2.45.bn1.weight     |     32     |\n",
            "|      layer2.45.bn1.bias      |     32     |\n",
            "|    layer2.45.conv2.weight    |    9216    |\n",
            "|     layer2.45.bn2.weight     |     32     |\n",
            "|      layer2.45.bn2.bias      |     32     |\n",
            "|    layer2.46.conv1.weight    |    9216    |\n",
            "|     layer2.46.bn1.weight     |     32     |\n",
            "|      layer2.46.bn1.bias      |     32     |\n",
            "|    layer2.46.conv2.weight    |    9216    |\n",
            "|     layer2.46.bn2.weight     |     32     |\n",
            "|      layer2.46.bn2.bias      |     32     |\n",
            "|    layer2.47.conv1.weight    |    9216    |\n",
            "|     layer2.47.bn1.weight     |     32     |\n",
            "|      layer2.47.bn1.bias      |     32     |\n",
            "|    layer2.47.conv2.weight    |    9216    |\n",
            "|     layer2.47.bn2.weight     |     32     |\n",
            "|      layer2.47.bn2.bias      |     32     |\n",
            "|    layer2.48.conv1.weight    |    9216    |\n",
            "|     layer2.48.bn1.weight     |     32     |\n",
            "|      layer2.48.bn1.bias      |     32     |\n",
            "|    layer2.48.conv2.weight    |    9216    |\n",
            "|     layer2.48.bn2.weight     |     32     |\n",
            "|      layer2.48.bn2.bias      |     32     |\n",
            "|    layer2.49.conv1.weight    |    9216    |\n",
            "|     layer2.49.bn1.weight     |     32     |\n",
            "|      layer2.49.bn1.bias      |     32     |\n",
            "|    layer2.49.conv2.weight    |    9216    |\n",
            "|     layer2.49.bn2.weight     |     32     |\n",
            "|      layer2.49.bn2.bias      |     32     |\n",
            "|    layer2.50.conv1.weight    |    9216    |\n",
            "|     layer2.50.bn1.weight     |     32     |\n",
            "|      layer2.50.bn1.bias      |     32     |\n",
            "|    layer2.50.conv2.weight    |    9216    |\n",
            "|     layer2.50.bn2.weight     |     32     |\n",
            "|      layer2.50.bn2.bias      |     32     |\n",
            "|    layer2.51.conv1.weight    |    9216    |\n",
            "|     layer2.51.bn1.weight     |     32     |\n",
            "|      layer2.51.bn1.bias      |     32     |\n",
            "|    layer2.51.conv2.weight    |    9216    |\n",
            "|     layer2.51.bn2.weight     |     32     |\n",
            "|      layer2.51.bn2.bias      |     32     |\n",
            "|    layer2.52.conv1.weight    |    9216    |\n",
            "|     layer2.52.bn1.weight     |     32     |\n",
            "|      layer2.52.bn1.bias      |     32     |\n",
            "|    layer2.52.conv2.weight    |    9216    |\n",
            "|     layer2.52.bn2.weight     |     32     |\n",
            "|      layer2.52.bn2.bias      |     32     |\n",
            "|    layer2.53.conv1.weight    |    9216    |\n",
            "|     layer2.53.bn1.weight     |     32     |\n",
            "|      layer2.53.bn1.bias      |     32     |\n",
            "|    layer2.53.conv2.weight    |    9216    |\n",
            "|     layer2.53.bn2.weight     |     32     |\n",
            "|      layer2.53.bn2.bias      |     32     |\n",
            "|    layer2.54.conv1.weight    |    9216    |\n",
            "|     layer2.54.bn1.weight     |     32     |\n",
            "|      layer2.54.bn1.bias      |     32     |\n",
            "|    layer2.54.conv2.weight    |    9216    |\n",
            "|     layer2.54.bn2.weight     |     32     |\n",
            "|      layer2.54.bn2.bias      |     32     |\n",
            "|    layer3.0.conv1.weight     |   18432    |\n",
            "|     layer3.0.bn1.weight      |     64     |\n",
            "|      layer3.0.bn1.bias       |     64     |\n",
            "|    layer3.0.conv2.weight     |   36864    |\n",
            "|     layer3.0.bn2.weight      |     64     |\n",
            "|      layer3.0.bn2.bias       |     64     |\n",
            "| layer3.0.downsample.0.weight |   18432    |\n",
            "| layer3.0.downsample.1.weight |     64     |\n",
            "|  layer3.0.downsample.1.bias  |     64     |\n",
            "|    layer3.1.conv1.weight     |   36864    |\n",
            "|     layer3.1.bn1.weight      |     64     |\n",
            "|      layer3.1.bn1.bias       |     64     |\n",
            "|    layer3.1.conv2.weight     |   36864    |\n",
            "|     layer3.1.bn2.weight      |     64     |\n",
            "|      layer3.1.bn2.bias       |     64     |\n",
            "|    layer3.2.conv1.weight     |   36864    |\n",
            "|     layer3.2.bn1.weight      |     64     |\n",
            "|      layer3.2.bn1.bias       |     64     |\n",
            "|    layer3.2.conv2.weight     |   36864    |\n",
            "|     layer3.2.bn2.weight      |     64     |\n",
            "|      layer3.2.bn2.bias       |     64     |\n",
            "|    layer3.3.conv1.weight     |   36864    |\n",
            "|     layer3.3.bn1.weight      |     64     |\n",
            "|      layer3.3.bn1.bias       |     64     |\n",
            "|    layer3.3.conv2.weight     |   36864    |\n",
            "|     layer3.3.bn2.weight      |     64     |\n",
            "|      layer3.3.bn2.bias       |     64     |\n",
            "|    layer3.4.conv1.weight     |   36864    |\n",
            "|     layer3.4.bn1.weight      |     64     |\n",
            "|      layer3.4.bn1.bias       |     64     |\n",
            "|    layer3.4.conv2.weight     |   36864    |\n",
            "|     layer3.4.bn2.weight      |     64     |\n",
            "|      layer3.4.bn2.bias       |     64     |\n",
            "|    layer3.5.conv1.weight     |   36864    |\n",
            "|     layer3.5.bn1.weight      |     64     |\n",
            "|      layer3.5.bn1.bias       |     64     |\n",
            "|    layer3.5.conv2.weight     |   36864    |\n",
            "|     layer3.5.bn2.weight      |     64     |\n",
            "|      layer3.5.bn2.bias       |     64     |\n",
            "|    layer3.6.conv1.weight     |   36864    |\n",
            "|     layer3.6.bn1.weight      |     64     |\n",
            "|      layer3.6.bn1.bias       |     64     |\n",
            "|    layer3.6.conv2.weight     |   36864    |\n",
            "|     layer3.6.bn2.weight      |     64     |\n",
            "|      layer3.6.bn2.bias       |     64     |\n",
            "|    layer3.7.conv1.weight     |   36864    |\n",
            "|     layer3.7.bn1.weight      |     64     |\n",
            "|      layer3.7.bn1.bias       |     64     |\n",
            "|    layer3.7.conv2.weight     |   36864    |\n",
            "|     layer3.7.bn2.weight      |     64     |\n",
            "|      layer3.7.bn2.bias       |     64     |\n",
            "|    layer3.8.conv1.weight     |   36864    |\n",
            "|     layer3.8.bn1.weight      |     64     |\n",
            "|      layer3.8.bn1.bias       |     64     |\n",
            "|    layer3.8.conv2.weight     |   36864    |\n",
            "|     layer3.8.bn2.weight      |     64     |\n",
            "|      layer3.8.bn2.bias       |     64     |\n",
            "|    layer3.9.conv1.weight     |   36864    |\n",
            "|     layer3.9.bn1.weight      |     64     |\n",
            "|      layer3.9.bn1.bias       |     64     |\n",
            "|    layer3.9.conv2.weight     |   36864    |\n",
            "|     layer3.9.bn2.weight      |     64     |\n",
            "|      layer3.9.bn2.bias       |     64     |\n",
            "|    layer3.10.conv1.weight    |   36864    |\n",
            "|     layer3.10.bn1.weight     |     64     |\n",
            "|      layer3.10.bn1.bias      |     64     |\n",
            "|    layer3.10.conv2.weight    |   36864    |\n",
            "|     layer3.10.bn2.weight     |     64     |\n",
            "|      layer3.10.bn2.bias      |     64     |\n",
            "|    layer3.11.conv1.weight    |   36864    |\n",
            "|     layer3.11.bn1.weight     |     64     |\n",
            "|      layer3.11.bn1.bias      |     64     |\n",
            "|    layer3.11.conv2.weight    |   36864    |\n",
            "|     layer3.11.bn2.weight     |     64     |\n",
            "|      layer3.11.bn2.bias      |     64     |\n",
            "|    layer3.12.conv1.weight    |   36864    |\n",
            "|     layer3.12.bn1.weight     |     64     |\n",
            "|      layer3.12.bn1.bias      |     64     |\n",
            "|    layer3.12.conv2.weight    |   36864    |\n",
            "|     layer3.12.bn2.weight     |     64     |\n",
            "|      layer3.12.bn2.bias      |     64     |\n",
            "|    layer3.13.conv1.weight    |   36864    |\n",
            "|     layer3.13.bn1.weight     |     64     |\n",
            "|      layer3.13.bn1.bias      |     64     |\n",
            "|    layer3.13.conv2.weight    |   36864    |\n",
            "|     layer3.13.bn2.weight     |     64     |\n",
            "|      layer3.13.bn2.bias      |     64     |\n",
            "|    layer3.14.conv1.weight    |   36864    |\n",
            "|     layer3.14.bn1.weight     |     64     |\n",
            "|      layer3.14.bn1.bias      |     64     |\n",
            "|    layer3.14.conv2.weight    |   36864    |\n",
            "|     layer3.14.bn2.weight     |     64     |\n",
            "|      layer3.14.bn2.bias      |     64     |\n",
            "|    layer3.15.conv1.weight    |   36864    |\n",
            "|     layer3.15.bn1.weight     |     64     |\n",
            "|      layer3.15.bn1.bias      |     64     |\n",
            "|    layer3.15.conv2.weight    |   36864    |\n",
            "|     layer3.15.bn2.weight     |     64     |\n",
            "|      layer3.15.bn2.bias      |     64     |\n",
            "|    layer3.16.conv1.weight    |   36864    |\n",
            "|     layer3.16.bn1.weight     |     64     |\n",
            "|      layer3.16.bn1.bias      |     64     |\n",
            "|    layer3.16.conv2.weight    |   36864    |\n",
            "|     layer3.16.bn2.weight     |     64     |\n",
            "|      layer3.16.bn2.bias      |     64     |\n",
            "|    layer3.17.conv1.weight    |   36864    |\n",
            "|     layer3.17.bn1.weight     |     64     |\n",
            "|      layer3.17.bn1.bias      |     64     |\n",
            "|    layer3.17.conv2.weight    |   36864    |\n",
            "|     layer3.17.bn2.weight     |     64     |\n",
            "|      layer3.17.bn2.bias      |     64     |\n",
            "|    layer3.18.conv1.weight    |   36864    |\n",
            "|     layer3.18.bn1.weight     |     64     |\n",
            "|      layer3.18.bn1.bias      |     64     |\n",
            "|    layer3.18.conv2.weight    |   36864    |\n",
            "|     layer3.18.bn2.weight     |     64     |\n",
            "|      layer3.18.bn2.bias      |     64     |\n",
            "|    layer3.19.conv1.weight    |   36864    |\n",
            "|     layer3.19.bn1.weight     |     64     |\n",
            "|      layer3.19.bn1.bias      |     64     |\n",
            "|    layer3.19.conv2.weight    |   36864    |\n",
            "|     layer3.19.bn2.weight     |     64     |\n",
            "|      layer3.19.bn2.bias      |     64     |\n",
            "|    layer3.20.conv1.weight    |   36864    |\n",
            "|     layer3.20.bn1.weight     |     64     |\n",
            "|      layer3.20.bn1.bias      |     64     |\n",
            "|    layer3.20.conv2.weight    |   36864    |\n",
            "|     layer3.20.bn2.weight     |     64     |\n",
            "|      layer3.20.bn2.bias      |     64     |\n",
            "|    layer3.21.conv1.weight    |   36864    |\n",
            "|     layer3.21.bn1.weight     |     64     |\n",
            "|      layer3.21.bn1.bias      |     64     |\n",
            "|    layer3.21.conv2.weight    |   36864    |\n",
            "|     layer3.21.bn2.weight     |     64     |\n",
            "|      layer3.21.bn2.bias      |     64     |\n",
            "|    layer3.22.conv1.weight    |   36864    |\n",
            "|     layer3.22.bn1.weight     |     64     |\n",
            "|      layer3.22.bn1.bias      |     64     |\n",
            "|    layer3.22.conv2.weight    |   36864    |\n",
            "|     layer3.22.bn2.weight     |     64     |\n",
            "|      layer3.22.bn2.bias      |     64     |\n",
            "|    layer3.23.conv1.weight    |   36864    |\n",
            "|     layer3.23.bn1.weight     |     64     |\n",
            "|      layer3.23.bn1.bias      |     64     |\n",
            "|    layer3.23.conv2.weight    |   36864    |\n",
            "|     layer3.23.bn2.weight     |     64     |\n",
            "|      layer3.23.bn2.bias      |     64     |\n",
            "|    layer3.24.conv1.weight    |   36864    |\n",
            "|     layer3.24.bn1.weight     |     64     |\n",
            "|      layer3.24.bn1.bias      |     64     |\n",
            "|    layer3.24.conv2.weight    |   36864    |\n",
            "|     layer3.24.bn2.weight     |     64     |\n",
            "|      layer3.24.bn2.bias      |     64     |\n",
            "|    layer3.25.conv1.weight    |   36864    |\n",
            "|     layer3.25.bn1.weight     |     64     |\n",
            "|      layer3.25.bn1.bias      |     64     |\n",
            "|    layer3.25.conv2.weight    |   36864    |\n",
            "|     layer3.25.bn2.weight     |     64     |\n",
            "|      layer3.25.bn2.bias      |     64     |\n",
            "|    layer3.26.conv1.weight    |   36864    |\n",
            "|     layer3.26.bn1.weight     |     64     |\n",
            "|      layer3.26.bn1.bias      |     64     |\n",
            "|    layer3.26.conv2.weight    |   36864    |\n",
            "|     layer3.26.bn2.weight     |     64     |\n",
            "|      layer3.26.bn2.bias      |     64     |\n",
            "|    layer3.27.conv1.weight    |   36864    |\n",
            "|     layer3.27.bn1.weight     |     64     |\n",
            "|      layer3.27.bn1.bias      |     64     |\n",
            "|    layer3.27.conv2.weight    |   36864    |\n",
            "|     layer3.27.bn2.weight     |     64     |\n",
            "|      layer3.27.bn2.bias      |     64     |\n",
            "|    layer3.28.conv1.weight    |   36864    |\n",
            "|     layer3.28.bn1.weight     |     64     |\n",
            "|      layer3.28.bn1.bias      |     64     |\n",
            "|    layer3.28.conv2.weight    |   36864    |\n",
            "|     layer3.28.bn2.weight     |     64     |\n",
            "|      layer3.28.bn2.bias      |     64     |\n",
            "|    layer3.29.conv1.weight    |   36864    |\n",
            "|     layer3.29.bn1.weight     |     64     |\n",
            "|      layer3.29.bn1.bias      |     64     |\n",
            "|    layer3.29.conv2.weight    |   36864    |\n",
            "|     layer3.29.bn2.weight     |     64     |\n",
            "|      layer3.29.bn2.bias      |     64     |\n",
            "|    layer3.30.conv1.weight    |   36864    |\n",
            "|     layer3.30.bn1.weight     |     64     |\n",
            "|      layer3.30.bn1.bias      |     64     |\n",
            "|    layer3.30.conv2.weight    |   36864    |\n",
            "|     layer3.30.bn2.weight     |     64     |\n",
            "|      layer3.30.bn2.bias      |     64     |\n",
            "|    layer3.31.conv1.weight    |   36864    |\n",
            "|     layer3.31.bn1.weight     |     64     |\n",
            "|      layer3.31.bn1.bias      |     64     |\n",
            "|    layer3.31.conv2.weight    |   36864    |\n",
            "|     layer3.31.bn2.weight     |     64     |\n",
            "|      layer3.31.bn2.bias      |     64     |\n",
            "|    layer3.32.conv1.weight    |   36864    |\n",
            "|     layer3.32.bn1.weight     |     64     |\n",
            "|      layer3.32.bn1.bias      |     64     |\n",
            "|    layer3.32.conv2.weight    |   36864    |\n",
            "|     layer3.32.bn2.weight     |     64     |\n",
            "|      layer3.32.bn2.bias      |     64     |\n",
            "|    layer3.33.conv1.weight    |   36864    |\n",
            "|     layer3.33.bn1.weight     |     64     |\n",
            "|      layer3.33.bn1.bias      |     64     |\n",
            "|    layer3.33.conv2.weight    |   36864    |\n",
            "|     layer3.33.bn2.weight     |     64     |\n",
            "|      layer3.33.bn2.bias      |     64     |\n",
            "|    layer3.34.conv1.weight    |   36864    |\n",
            "|     layer3.34.bn1.weight     |     64     |\n",
            "|      layer3.34.bn1.bias      |     64     |\n",
            "|    layer3.34.conv2.weight    |   36864    |\n",
            "|     layer3.34.bn2.weight     |     64     |\n",
            "|      layer3.34.bn2.bias      |     64     |\n",
            "|    layer3.35.conv1.weight    |   36864    |\n",
            "|     layer3.35.bn1.weight     |     64     |\n",
            "|      layer3.35.bn1.bias      |     64     |\n",
            "|    layer3.35.conv2.weight    |   36864    |\n",
            "|     layer3.35.bn2.weight     |     64     |\n",
            "|      layer3.35.bn2.bias      |     64     |\n",
            "|    layer3.36.conv1.weight    |   36864    |\n",
            "|     layer3.36.bn1.weight     |     64     |\n",
            "|      layer3.36.bn1.bias      |     64     |\n",
            "|    layer3.36.conv2.weight    |   36864    |\n",
            "|     layer3.36.bn2.weight     |     64     |\n",
            "|      layer3.36.bn2.bias      |     64     |\n",
            "|    layer3.37.conv1.weight    |   36864    |\n",
            "|     layer3.37.bn1.weight     |     64     |\n",
            "|      layer3.37.bn1.bias      |     64     |\n",
            "|    layer3.37.conv2.weight    |   36864    |\n",
            "|     layer3.37.bn2.weight     |     64     |\n",
            "|      layer3.37.bn2.bias      |     64     |\n",
            "|    layer3.38.conv1.weight    |   36864    |\n",
            "|     layer3.38.bn1.weight     |     64     |\n",
            "|      layer3.38.bn1.bias      |     64     |\n",
            "|    layer3.38.conv2.weight    |   36864    |\n",
            "|     layer3.38.bn2.weight     |     64     |\n",
            "|      layer3.38.bn2.bias      |     64     |\n",
            "|    layer3.39.conv1.weight    |   36864    |\n",
            "|     layer3.39.bn1.weight     |     64     |\n",
            "|      layer3.39.bn1.bias      |     64     |\n",
            "|    layer3.39.conv2.weight    |   36864    |\n",
            "|     layer3.39.bn2.weight     |     64     |\n",
            "|      layer3.39.bn2.bias      |     64     |\n",
            "|    layer3.40.conv1.weight    |   36864    |\n",
            "|     layer3.40.bn1.weight     |     64     |\n",
            "|      layer3.40.bn1.bias      |     64     |\n",
            "|    layer3.40.conv2.weight    |   36864    |\n",
            "|     layer3.40.bn2.weight     |     64     |\n",
            "|      layer3.40.bn2.bias      |     64     |\n",
            "|    layer3.41.conv1.weight    |   36864    |\n",
            "|     layer3.41.bn1.weight     |     64     |\n",
            "|      layer3.41.bn1.bias      |     64     |\n",
            "|    layer3.41.conv2.weight    |   36864    |\n",
            "|     layer3.41.bn2.weight     |     64     |\n",
            "|      layer3.41.bn2.bias      |     64     |\n",
            "|    layer3.42.conv1.weight    |   36864    |\n",
            "|     layer3.42.bn1.weight     |     64     |\n",
            "|      layer3.42.bn1.bias      |     64     |\n",
            "|    layer3.42.conv2.weight    |   36864    |\n",
            "|     layer3.42.bn2.weight     |     64     |\n",
            "|      layer3.42.bn2.bias      |     64     |\n",
            "|    layer3.43.conv1.weight    |   36864    |\n",
            "|     layer3.43.bn1.weight     |     64     |\n",
            "|      layer3.43.bn1.bias      |     64     |\n",
            "|    layer3.43.conv2.weight    |   36864    |\n",
            "|     layer3.43.bn2.weight     |     64     |\n",
            "|      layer3.43.bn2.bias      |     64     |\n",
            "|    layer3.44.conv1.weight    |   36864    |\n",
            "|     layer3.44.bn1.weight     |     64     |\n",
            "|      layer3.44.bn1.bias      |     64     |\n",
            "|    layer3.44.conv2.weight    |   36864    |\n",
            "|     layer3.44.bn2.weight     |     64     |\n",
            "|      layer3.44.bn2.bias      |     64     |\n",
            "|    layer3.45.conv1.weight    |   36864    |\n",
            "|     layer3.45.bn1.weight     |     64     |\n",
            "|      layer3.45.bn1.bias      |     64     |\n",
            "|    layer3.45.conv2.weight    |   36864    |\n",
            "|     layer3.45.bn2.weight     |     64     |\n",
            "|      layer3.45.bn2.bias      |     64     |\n",
            "|    layer3.46.conv1.weight    |   36864    |\n",
            "|     layer3.46.bn1.weight     |     64     |\n",
            "|      layer3.46.bn1.bias      |     64     |\n",
            "|    layer3.46.conv2.weight    |   36864    |\n",
            "|     layer3.46.bn2.weight     |     64     |\n",
            "|      layer3.46.bn2.bias      |     64     |\n",
            "|    layer3.47.conv1.weight    |   36864    |\n",
            "|     layer3.47.bn1.weight     |     64     |\n",
            "|      layer3.47.bn1.bias      |     64     |\n",
            "|    layer3.47.conv2.weight    |   36864    |\n",
            "|     layer3.47.bn2.weight     |     64     |\n",
            "|      layer3.47.bn2.bias      |     64     |\n",
            "|    layer3.48.conv1.weight    |   36864    |\n",
            "|     layer3.48.bn1.weight     |     64     |\n",
            "|      layer3.48.bn1.bias      |     64     |\n",
            "|    layer3.48.conv2.weight    |   36864    |\n",
            "|     layer3.48.bn2.weight     |     64     |\n",
            "|      layer3.48.bn2.bias      |     64     |\n",
            "|    layer3.49.conv1.weight    |   36864    |\n",
            "|     layer3.49.bn1.weight     |     64     |\n",
            "|      layer3.49.bn1.bias      |     64     |\n",
            "|    layer3.49.conv2.weight    |   36864    |\n",
            "|     layer3.49.bn2.weight     |     64     |\n",
            "|      layer3.49.bn2.bias      |     64     |\n",
            "|    layer3.50.conv1.weight    |   36864    |\n",
            "|     layer3.50.bn1.weight     |     64     |\n",
            "|      layer3.50.bn1.bias      |     64     |\n",
            "|    layer3.50.conv2.weight    |   36864    |\n",
            "|     layer3.50.bn2.weight     |     64     |\n",
            "|      layer3.50.bn2.bias      |     64     |\n",
            "|    layer3.51.conv1.weight    |   36864    |\n",
            "|     layer3.51.bn1.weight     |     64     |\n",
            "|      layer3.51.bn1.bias      |     64     |\n",
            "|    layer3.51.conv2.weight    |   36864    |\n",
            "|     layer3.51.bn2.weight     |     64     |\n",
            "|      layer3.51.bn2.bias      |     64     |\n",
            "|    layer3.52.conv1.weight    |   36864    |\n",
            "|     layer3.52.bn1.weight     |     64     |\n",
            "|      layer3.52.bn1.bias      |     64     |\n",
            "|    layer3.52.conv2.weight    |   36864    |\n",
            "|     layer3.52.bn2.weight     |     64     |\n",
            "|      layer3.52.bn2.bias      |     64     |\n",
            "|    layer3.53.conv1.weight    |   36864    |\n",
            "|     layer3.53.bn1.weight     |     64     |\n",
            "|      layer3.53.bn1.bias      |     64     |\n",
            "|    layer3.53.conv2.weight    |   36864    |\n",
            "|     layer3.53.bn2.weight     |     64     |\n",
            "|      layer3.53.bn2.bias      |     64     |\n",
            "|    layer3.54.conv1.weight    |   36864    |\n",
            "|     layer3.54.bn1.weight     |     64     |\n",
            "|      layer3.54.bn1.bias      |     64     |\n",
            "|    layer3.54.conv2.weight    |   36864    |\n",
            "|     layer3.54.bn2.weight     |     64     |\n",
            "|      layer3.54.bn2.bias      |     64     |\n",
            "|          fc.weight           |    640     |\n",
            "|           fc.bias            |     10     |\n",
            "+------------------------------+------------+\n",
            "Total Trainable Params: 5348186\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5348186"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Hx0SO_z0j9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "e205a417-6bea-47a9-d26b-4e4163bbcd9b"
      },
      "source": [
        "ns  = [3, 5, 7, 9]\n",
        "clr = ['y', 'c', 'g', 'r']\n",
        "\n",
        "resnet_dfs = [pd.read_csv(f'results/resnet{6*n+2}.csv') for n in ns]\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "plt.axis([0, 80, 0, 100])\n",
        "\n",
        "\n",
        "for i in range(len(ns)):\n",
        "    plt.plot(resnet_dfs[i]['epoch'], resnet_dfs[i]['train_err']*100, f'{clr[i]}--',\n",
        "             label=f'ResNet-{6*ns[i]+2} train')\n",
        "    plt.plot(resnet_dfs[i]['epoch'], resnet_dfs[i]['test_err']*100, f'{clr[i]}',\n",
        "             label=f'ResNet-{6*ns[i]+2} test')\n",
        "\n",
        "plt.title('Comparison of four residual networks with 20, 32, 44 and 56 layers.')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('error (%)')\n",
        "plt.axhline(10, color='black', alpha=0.5, dashes=(10., 10.))\n",
        "plt.axhline(5, color='black', alpha=0.5, dashes=(10., 10.));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkPpRn3nz7FB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "8d3a132b-72ca-4820-a203-0347b506f86b"
      },
      "source": [
        "bests = [df[df['test_err'] == df['test_err'].min()].iloc[0] for df in resnet_dfs]\n",
        "bests_df= pd.concat(bests, axis=1).T\n",
        "bests_df['model'] = ['ResNet20', 'ResNet32', 'ResNet44', 'ResNet56']\n",
        "display(bests_df[['model', 'test_err']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>test_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>ResNet20</td>\n",
              "      <td>0.1643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>ResNet32</td>\n",
              "      <td>0.1881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>ResNet44</td>\n",
              "      <td>0.1735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>ResNet56</td>\n",
              "      <td>0.1709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       model  test_err\n",
              "63  ResNet20    0.1643\n",
              "61  ResNet32    0.1881\n",
              "68  ResNet44    0.1735\n",
              "64  ResNet56    0.1709"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiZhaDH1SXEO"
      },
      "source": [
        "##Plain Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZB5NKB-Keci"
      },
      "source": [
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
        "                     stride=stride, padding=1, bias=False)\n",
        "\n",
        "# block(removing out += residual line to be plain network)\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        ##out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Plain network\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "import os\n",
        "\n",
        "def trainModel(model,depth):\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9,weight_decay=1e-4)\n",
        "\n",
        "# Run on GPU if available\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  model.to(device)\n",
        "\n",
        "  outdir ='./results'\n",
        "  if not os.path.exists(outdir):\n",
        "    os.mkdir(outdir)\n",
        "\n",
        "  cols = ['epoch', 'train_loss', 'train_err', 'test_err']\n",
        "  results_df = pd.DataFrame(columns=cols).set_index('epoch')\n",
        "  \n",
        "  total_step = len(train_dataloader)\n",
        "  curr_lr = learning_rate\n",
        "  results_file = f'results/plainnet{depth}.csv'\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss  = 0.0\n",
        "    best_test_err = 1.0\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #  optimize\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        #Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # print average loss for last 50 mini-batches\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    \n",
        "    # # Decay learning rate\n",
        "    # if (epoch+1) % 20 == 0:\n",
        "    #     curr_lr /= 3\n",
        "    #     update_lr(optimizer, curr_lr)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    train_loss = loss.item()\n",
        "    train_err = evaluate(model, train_dataloader, device)\n",
        "    test_err = evaluate(model, test_dataloader, device)\n",
        "    results_df.loc[epoch] = [train_loss, train_err, test_err]\n",
        "    results_df.to_csv(results_file)\n",
        "    print(f'train_err: {train_err} test_err: {test_err}')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "  return train_loss"
      ],
      "metadata": {
        "id": "6owtztDzV1YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "def saveModel(model,layerNo):\n",
        "  snapShotName = \"plainnet%s.ckpt\" % (layerNo)\n",
        "  torch.save(model.state_dict(), snapShotName)\n",
        "  print(snapShotName)"
      ],
      "metadata": {
        "id": "RLNx0YlRWSP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8gTfCaSgtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff7a0eb-d3bb-4d65-a60d-103a74e1dcc2"
      },
      "source": [
        "Plainnetwork20Model = createResnetModelWithDepth(20)\n",
        "trainModel(Plainnetwork20Model,20)\n",
        "testModel(Plainnetwork20Model)\n",
        "saveModel(Plainnetwork20Model,20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.3083\n",
            "Epoch [1/80], Step [200/391] Loss: 2.3101\n",
            "Epoch [1/80], Step [300/391] Loss: 2.3002\n",
            "train_err: 0.90062 test_err: 0.8999\n",
            "Epoch [2/80], Step [100/391] Loss: 2.2995\n",
            "Epoch [2/80], Step [200/391] Loss: 2.2988\n",
            "Epoch [2/80], Step [300/391] Loss: 2.3031\n",
            "train_err: 0.89874 test_err: 0.8987\n",
            "Epoch [3/80], Step [100/391] Loss: 2.2975\n",
            "Epoch [3/80], Step [200/391] Loss: 2.3144\n",
            "Epoch [3/80], Step [300/391] Loss: 2.3144\n",
            "train_err: 0.89978 test_err: 0.8997\n",
            "Epoch [4/80], Step [100/391] Loss: 2.3030\n",
            "Epoch [4/80], Step [200/391] Loss: 2.2955\n",
            "Epoch [4/80], Step [300/391] Loss: 2.3238\n",
            "train_err: 0.89994 test_err: 0.8999\n",
            "Epoch [5/80], Step [100/391] Loss: 2.3022\n",
            "Epoch [5/80], Step [200/391] Loss: 2.3034\n",
            "Epoch [5/80], Step [300/391] Loss: 2.3003\n",
            "train_err: 0.90004 test_err: 0.8998\n",
            "Epoch [6/80], Step [100/391] Loss: 2.3075\n",
            "Epoch [6/80], Step [200/391] Loss: 2.2985\n",
            "Epoch [6/80], Step [300/391] Loss: 2.2939\n",
            "train_err: 0.89978 test_err: 0.9001\n",
            "Epoch [7/80], Step [100/391] Loss: 2.2965\n",
            "Epoch [7/80], Step [200/391] Loss: 2.3082\n",
            "Epoch [7/80], Step [300/391] Loss: 2.3002\n",
            "train_err: 0.89918 test_err: 0.8997\n",
            "Epoch [8/80], Step [100/391] Loss: 2.3082\n",
            "Epoch [8/80], Step [200/391] Loss: 2.3055\n",
            "Epoch [8/80], Step [300/391] Loss: 2.2966\n",
            "train_err: 0.8994 test_err: 0.9001\n",
            "Epoch [9/80], Step [100/391] Loss: 2.3070\n",
            "Epoch [9/80], Step [200/391] Loss: 2.2974\n",
            "Epoch [9/80], Step [300/391] Loss: 2.2980\n",
            "train_err: 0.89944 test_err: 0.9008\n",
            "Epoch [10/80], Step [100/391] Loss: 2.2863\n",
            "Epoch [10/80], Step [200/391] Loss: 2.3054\n",
            "Epoch [10/80], Step [300/391] Loss: 2.2971\n",
            "train_err: 0.89986 test_err: 0.899\n",
            "Epoch [11/80], Step [100/391] Loss: 2.3001\n",
            "Epoch [11/80], Step [200/391] Loss: 2.3139\n",
            "Epoch [11/80], Step [300/391] Loss: 2.2911\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [12/80], Step [100/391] Loss: 2.3060\n",
            "Epoch [12/80], Step [200/391] Loss: 2.2999\n",
            "Epoch [12/80], Step [300/391] Loss: 2.3016\n",
            "train_err: 0.89932 test_err: 0.9005\n",
            "Epoch [13/80], Step [100/391] Loss: 2.3117\n",
            "Epoch [13/80], Step [200/391] Loss: 2.2959\n",
            "Epoch [13/80], Step [300/391] Loss: 2.3130\n",
            "train_err: 0.89974 test_err: 0.8994\n",
            "Epoch [14/80], Step [100/391] Loss: 2.3039\n",
            "Epoch [14/80], Step [200/391] Loss: 2.3029\n",
            "Epoch [14/80], Step [300/391] Loss: 2.3005\n",
            "train_err: 0.89952 test_err: 0.8998\n",
            "Epoch [15/80], Step [100/391] Loss: 2.2959\n",
            "Epoch [15/80], Step [200/391] Loss: 2.3057\n",
            "Epoch [15/80], Step [300/391] Loss: 2.3162\n",
            "train_err: 0.90014 test_err: 0.9004\n",
            "Epoch [16/80], Step [100/391] Loss: 2.2944\n",
            "Epoch [16/80], Step [200/391] Loss: 2.2982\n",
            "Epoch [16/80], Step [300/391] Loss: 2.3051\n",
            "train_err: 0.90002 test_err: 0.8998\n",
            "Epoch [17/80], Step [100/391] Loss: 2.2997\n",
            "Epoch [17/80], Step [200/391] Loss: 2.3015\n",
            "Epoch [17/80], Step [300/391] Loss: 2.3057\n",
            "train_err: 0.89864 test_err: 0.8979\n",
            "Epoch [18/80], Step [100/391] Loss: 2.3085\n",
            "Epoch [18/80], Step [200/391] Loss: 2.2923\n",
            "Epoch [18/80], Step [300/391] Loss: 2.2973\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [19/80], Step [100/391] Loss: 2.3010\n",
            "Epoch [19/80], Step [200/391] Loss: 2.3165\n",
            "Epoch [19/80], Step [300/391] Loss: 2.3069\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [20/80], Step [100/391] Loss: 2.3112\n",
            "Epoch [20/80], Step [200/391] Loss: 2.2919\n",
            "Epoch [20/80], Step [300/391] Loss: 2.3100\n",
            "train_err: 0.89948 test_err: 0.8996\n",
            "Epoch [21/80], Step [100/391] Loss: 2.2997\n",
            "Epoch [21/80], Step [200/391] Loss: 2.3154\n",
            "Epoch [21/80], Step [300/391] Loss: 2.3036\n",
            "train_err: 0.8986 test_err: 0.8986\n",
            "Epoch [22/80], Step [100/391] Loss: 2.3002\n",
            "Epoch [22/80], Step [200/391] Loss: 2.3119\n",
            "Epoch [22/80], Step [300/391] Loss: 2.2969\n",
            "train_err: 0.89846 test_err: 0.8985\n",
            "Epoch [23/80], Step [100/391] Loss: 2.3045\n",
            "Epoch [23/80], Step [200/391] Loss: 2.3023\n",
            "Epoch [23/80], Step [300/391] Loss: 2.3000\n",
            "train_err: 0.89966 test_err: 0.8998\n",
            "Epoch [24/80], Step [100/391] Loss: 2.2970\n",
            "Epoch [24/80], Step [200/391] Loss: 2.3005\n",
            "Epoch [24/80], Step [300/391] Loss: 2.3033\n",
            "train_err: 0.89854 test_err: 0.8977\n",
            "Epoch [25/80], Step [100/391] Loss: 2.3018\n",
            "Epoch [25/80], Step [200/391] Loss: 2.3055\n",
            "Epoch [25/80], Step [300/391] Loss: 2.3177\n",
            "train_err: 0.89854 test_err: 0.8984\n",
            "Epoch [26/80], Step [100/391] Loss: 2.3052\n",
            "Epoch [26/80], Step [200/391] Loss: 2.2990\n",
            "Epoch [26/80], Step [300/391] Loss: 2.3023\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [27/80], Step [100/391] Loss: 2.3073\n",
            "Epoch [27/80], Step [200/391] Loss: 2.3088\n",
            "Epoch [27/80], Step [300/391] Loss: 2.3085\n",
            "train_err: 0.89794 test_err: 0.8973\n",
            "Epoch [28/80], Step [100/391] Loss: 2.3064\n",
            "Epoch [28/80], Step [200/391] Loss: 2.3112\n",
            "Epoch [28/80], Step [300/391] Loss: 2.2963\n",
            "train_err: 0.89828 test_err: 0.8981\n",
            "Epoch [29/80], Step [100/391] Loss: 2.3003\n",
            "Epoch [29/80], Step [200/391] Loss: 2.3106\n",
            "Epoch [29/80], Step [300/391] Loss: 2.3042\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [30/80], Step [100/391] Loss: 2.3023\n",
            "Epoch [30/80], Step [200/391] Loss: 2.2955\n",
            "Epoch [30/80], Step [300/391] Loss: 2.2936\n",
            "train_err: 0.89732 test_err: 0.897\n",
            "Epoch [31/80], Step [100/391] Loss: 2.3058\n",
            "Epoch [31/80], Step [200/391] Loss: 2.3139\n",
            "Epoch [31/80], Step [300/391] Loss: 2.3051\n",
            "train_err: 0.8984 test_err: 0.8973\n",
            "Epoch [32/80], Step [100/391] Loss: 2.3089\n",
            "Epoch [32/80], Step [200/391] Loss: 2.3116\n",
            "Epoch [32/80], Step [300/391] Loss: 2.3059\n",
            "train_err: 0.89904 test_err: 0.8987\n",
            "Epoch [33/80], Step [100/391] Loss: 2.3104\n",
            "Epoch [33/80], Step [200/391] Loss: 2.2976\n",
            "Epoch [33/80], Step [300/391] Loss: 2.3160\n",
            "train_err: 0.89962 test_err: 0.9\n",
            "Epoch [34/80], Step [100/391] Loss: 2.2964\n",
            "Epoch [34/80], Step [200/391] Loss: 2.2963\n",
            "Epoch [34/80], Step [300/391] Loss: 2.3037\n",
            "train_err: 0.89864 test_err: 0.8984\n",
            "Epoch [35/80], Step [100/391] Loss: 2.2968\n",
            "Epoch [35/80], Step [200/391] Loss: 2.3210\n",
            "Epoch [35/80], Step [300/391] Loss: 2.2959\n",
            "train_err: 0.8991 test_err: 0.9009\n",
            "Epoch [36/80], Step [100/391] Loss: 2.3013\n",
            "Epoch [36/80], Step [200/391] Loss: 2.2865\n",
            "Epoch [36/80], Step [300/391] Loss: 2.3023\n",
            "train_err: 0.89864 test_err: 0.8977\n",
            "Epoch [37/80], Step [100/391] Loss: 2.3117\n",
            "Epoch [37/80], Step [200/391] Loss: 2.2767\n",
            "Epoch [37/80], Step [300/391] Loss: 2.2856\n",
            "train_err: 0.89972 test_err: 0.9011\n",
            "Epoch [38/80], Step [100/391] Loss: 2.3032\n",
            "Epoch [38/80], Step [200/391] Loss: 2.2903\n",
            "Epoch [38/80], Step [300/391] Loss: 2.2487\n",
            "train_err: 0.90018 test_err: 0.8999\n",
            "Epoch [39/80], Step [100/391] Loss: 2.2278\n",
            "Epoch [39/80], Step [200/391] Loss: 2.1928\n",
            "Epoch [39/80], Step [300/391] Loss: 2.2240\n",
            "train_err: 0.89996 test_err: 0.8998\n",
            "Epoch [40/80], Step [100/391] Loss: 2.3185\n",
            "Epoch [40/80], Step [200/391] Loss: 2.3056\n",
            "Epoch [40/80], Step [300/391] Loss: 2.3007\n",
            "train_err: 0.8985 test_err: 0.8987\n",
            "Epoch [41/80], Step [100/391] Loss: 2.3029\n",
            "Epoch [41/80], Step [200/391] Loss: 2.3018\n",
            "Epoch [41/80], Step [300/391] Loss: 2.3009\n",
            "train_err: 0.89954 test_err: 0.9009\n",
            "Epoch [42/80], Step [100/391] Loss: 2.2904\n",
            "Epoch [42/80], Step [200/391] Loss: 2.3004\n",
            "Epoch [42/80], Step [300/391] Loss: 2.2954\n",
            "train_err: 0.90006 test_err: 0.8999\n",
            "Epoch [43/80], Step [100/391] Loss: 2.3075\n",
            "Epoch [43/80], Step [200/391] Loss: 2.3004\n",
            "Epoch [43/80], Step [300/391] Loss: 2.3057\n",
            "train_err: 0.89836 test_err: 0.8973\n",
            "Epoch [44/80], Step [100/391] Loss: 2.2990\n",
            "Epoch [44/80], Step [200/391] Loss: 2.3144\n",
            "Epoch [44/80], Step [300/391] Loss: 2.3025\n",
            "train_err: 0.8994 test_err: 0.9005\n",
            "Epoch [45/80], Step [100/391] Loss: 2.3043\n",
            "Epoch [45/80], Step [200/391] Loss: 2.3038\n",
            "Epoch [45/80], Step [300/391] Loss: 2.3074\n",
            "train_err: 0.90004 test_err: 0.9\n",
            "Epoch [46/80], Step [100/391] Loss: 2.3097\n",
            "Epoch [46/80], Step [200/391] Loss: 2.3082\n",
            "Epoch [46/80], Step [300/391] Loss: 2.2968\n",
            "train_err: 0.89942 test_err: 0.8998\n",
            "Epoch [47/80], Step [100/391] Loss: 2.2991\n",
            "Epoch [47/80], Step [200/391] Loss: 2.3112\n",
            "Epoch [47/80], Step [300/391] Loss: 2.3172\n",
            "train_err: 0.90006 test_err: 0.8998\n",
            "Epoch [48/80], Step [100/391] Loss: 2.2991\n",
            "Epoch [48/80], Step [200/391] Loss: 2.3036\n",
            "Epoch [48/80], Step [300/391] Loss: 2.3059\n",
            "train_err: 0.8994 test_err: 0.899\n",
            "Epoch [49/80], Step [100/391] Loss: 2.2970\n",
            "Epoch [49/80], Step [200/391] Loss: 2.3059\n",
            "Epoch [49/80], Step [300/391] Loss: 2.3211\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [50/80], Step [100/391] Loss: 2.3042\n",
            "Epoch [50/80], Step [200/391] Loss: 2.2972\n",
            "Epoch [50/80], Step [300/391] Loss: 2.3022\n",
            "train_err: 0.89996 test_err: 0.9\n",
            "Epoch [51/80], Step [100/391] Loss: 2.3003\n",
            "Epoch [51/80], Step [200/391] Loss: 2.3079\n",
            "Epoch [51/80], Step [300/391] Loss: 2.3022\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [52/80], Step [100/391] Loss: 2.2905\n",
            "Epoch [52/80], Step [200/391] Loss: 2.3016\n",
            "Epoch [52/80], Step [300/391] Loss: 2.3056\n",
            "train_err: 0.89974 test_err: 0.8997\n",
            "Epoch [53/80], Step [100/391] Loss: 2.3035\n",
            "Epoch [53/80], Step [200/391] Loss: 2.3131\n",
            "Epoch [53/80], Step [300/391] Loss: 2.3046\n",
            "train_err: 0.89944 test_err: 0.9002\n",
            "Epoch [54/80], Step [100/391] Loss: 2.3031\n",
            "Epoch [54/80], Step [200/391] Loss: 2.3060\n",
            "Epoch [54/80], Step [300/391] Loss: 2.3140\n",
            "train_err: 0.89998 test_err: 0.9\n",
            "Epoch [55/80], Step [100/391] Loss: 2.3166\n",
            "Epoch [55/80], Step [200/391] Loss: 2.3143\n",
            "Epoch [55/80], Step [300/391] Loss: 2.3117\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [56/80], Step [100/391] Loss: 2.2958\n",
            "Epoch [56/80], Step [200/391] Loss: 2.3002\n",
            "Epoch [56/80], Step [300/391] Loss: 2.3122\n",
            "train_err: 0.89996 test_err: 0.9001\n",
            "Epoch [57/80], Step [100/391] Loss: 2.2981\n",
            "Epoch [57/80], Step [200/391] Loss: 2.3098\n",
            "Epoch [57/80], Step [300/391] Loss: 2.2941\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [58/80], Step [200/391] Loss: 2.3155\n",
            "Epoch [58/80], Step [300/391] Loss: 2.2987\n",
            "train_err: 0.89906 test_err: 0.8997\n",
            "Epoch [59/80], Step [100/391] Loss: 2.2849\n",
            "Epoch [59/80], Step [200/391] Loss: 2.2023\n",
            "Epoch [59/80], Step [300/391] Loss: 2.2562\n",
            "train_err: 0.89926 test_err: 0.8991\n",
            "Epoch [60/80], Step [100/391] Loss: 2.1542\n",
            "Epoch [60/80], Step [200/391] Loss: 2.2653\n",
            "Epoch [60/80], Step [300/391] Loss: 2.1497\n",
            "train_err: 0.90002 test_err: 0.9001\n",
            "Epoch [61/80], Step [100/391] Loss: 2.3157\n",
            "Epoch [61/80], Step [200/391] Loss: 2.3018\n",
            "Epoch [61/80], Step [300/391] Loss: 2.3024\n",
            "train_err: 0.90012 test_err: 0.9\n",
            "Epoch [62/80], Step [100/391] Loss: 2.2980\n",
            "Epoch [62/80], Step [200/391] Loss: 2.3022\n",
            "Epoch [62/80], Step [300/391] Loss: 2.2981\n",
            "train_err: 0.90006 test_err: 0.9\n",
            "Epoch [63/80], Step [100/391] Loss: 2.3080\n",
            "Epoch [63/80], Step [200/391] Loss: 2.2953\n",
            "Epoch [63/80], Step [300/391] Loss: 2.2811\n",
            "train_err: 0.90016 test_err: 0.8996\n",
            "Epoch [64/80], Step [100/391] Loss: 2.3003\n",
            "Epoch [64/80], Step [200/391] Loss: 2.3010\n",
            "Epoch [64/80], Step [300/391] Loss: 2.3016\n",
            "train_err: 0.90016 test_err: 0.9\n",
            "Epoch [65/80], Step [100/391] Loss: 2.2983\n",
            "Epoch [65/80], Step [200/391] Loss: 2.3178\n",
            "Epoch [65/80], Step [300/391] Loss: 2.2966\n",
            "train_err: 0.8991 test_err: 0.899\n",
            "Epoch [66/80], Step [100/391] Loss: 2.3109\n",
            "Epoch [66/80], Step [200/391] Loss: 2.2975\n",
            "Epoch [66/80], Step [300/391] Loss: 2.2977\n",
            "train_err: 0.89982 test_err: 0.9\n",
            "Epoch [67/80], Step [100/391] Loss: 2.3002\n",
            "Epoch [67/80], Step [200/391] Loss: 2.2961\n",
            "Epoch [67/80], Step [300/391] Loss: 2.3097\n",
            "train_err: 0.8997 test_err: 0.9003\n",
            "Epoch [68/80], Step [100/391] Loss: 2.3006\n",
            "Epoch [68/80], Step [200/391] Loss: 2.3060\n",
            "Epoch [68/80], Step [300/391] Loss: 2.3101\n",
            "train_err: 0.90008 test_err: 0.9\n",
            "Epoch [69/80], Step [100/391] Loss: 2.3075\n",
            "Epoch [69/80], Step [200/391] Loss: 2.3003\n",
            "Epoch [69/80], Step [300/391] Loss: 2.3048\n",
            "train_err: 0.90022 test_err: 0.9\n",
            "Epoch [70/80], Step [100/391] Loss: 2.2146\n",
            "Epoch [70/80], Step [200/391] Loss: 2.1634\n",
            "Epoch [70/80], Step [300/391] Loss: 2.1937\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [71/80], Step [100/391] Loss: 2.1972\n",
            "Epoch [71/80], Step [200/391] Loss: 2.1845\n",
            "Epoch [71/80], Step [300/391] Loss: 2.3971\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [72/80], Step [100/391] Loss: 2.2010\n",
            "Epoch [72/80], Step [200/391] Loss: 2.2090\n",
            "Epoch [72/80], Step [300/391] Loss: 2.1894\n",
            "train_err: 0.89786 test_err: 0.8972\n",
            "Epoch [73/80], Step [100/391] Loss: 2.2741\n",
            "Epoch [73/80], Step [200/391] Loss: 2.1557\n",
            "Epoch [73/80], Step [300/391] Loss: 2.1247\n",
            "train_err: 0.89754 test_err: 0.8983\n",
            "Epoch [74/80], Step [100/391] Loss: 2.1846\n",
            "Epoch [74/80], Step [200/391] Loss: 2.0897\n",
            "Epoch [74/80], Step [300/391] Loss: 2.1941\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [75/80], Step [100/391] Loss: 2.0869\n",
            "Epoch [75/80], Step [200/391] Loss: 2.2278\n",
            "Epoch [75/80], Step [300/391] Loss: 2.1073\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [76/80], Step [100/391] Loss: 2.2633\n",
            "Epoch [76/80], Step [200/391] Loss: 2.2403\n",
            "Epoch [76/80], Step [300/391] Loss: 2.1391\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [77/80], Step [100/391] Loss: 2.1704\n",
            "Epoch [77/80], Step [200/391] Loss: 2.1493\n",
            "Epoch [77/80], Step [300/391] Loss: 2.1387\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [78/80], Step [100/391] Loss: 2.0745\n",
            "Epoch [78/80], Step [200/391] Loss: 2.1418\n",
            "Epoch [78/80], Step [300/391] Loss: 2.1779\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [79/80], Step [100/391] Loss: 2.3179\n",
            "Epoch [79/80], Step [200/391] Loss: 2.3028\n",
            "Epoch [79/80], Step [300/391] Loss: 2.3245\n",
            "train_err: 0.89362 test_err: 0.8937\n",
            "Epoch [80/80], Step [100/391] Loss: 2.2803\n",
            "Epoch [80/80], Step [200/391] Loss: 2.2957\n",
            "Epoch [80/80], Step [300/391] Loss: 2.2873\n",
            "train_err: 0.89744 test_err: 0.8975\n",
            "Accuracy of the model on the test images: 10.25 %\n",
            "plainnet20.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09O5xlIlSqGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be42cb2-39ab-476f-c0c2-1fa30e05818f"
      },
      "source": [
        "Plainnetwork32Model = createResnetModelWithDepth(32)\n",
        "trainModel(Plainnetwork32Model,32)\n",
        "testModel(Plainnetwork32Model)\n",
        "saveModel(Plainnetwork32Model,32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: 2.2968\n",
            "Epoch [1/80], Step [200/391] Loss: 2.2972\n",
            "Epoch [1/80], Step [300/391] Loss: 2.3126\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [2/80], Step [100/391] Loss: 2.3053\n",
            "Epoch [2/80], Step [200/391] Loss: 2.3082\n",
            "Epoch [2/80], Step [300/391] Loss: 2.3030\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [3/80], Step [100/391] Loss: 2.3096\n",
            "Epoch [3/80], Step [200/391] Loss: 2.3049\n",
            "Epoch [3/80], Step [300/391] Loss: 2.3085\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [4/80], Step [100/391] Loss: 2.2987\n",
            "Epoch [4/80], Step [200/391] Loss: 2.3000\n",
            "Epoch [4/80], Step [300/391] Loss: 2.2993\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [5/80], Step [100/391] Loss: 2.3017\n",
            "Epoch [5/80], Step [200/391] Loss: 2.3028\n",
            "Epoch [5/80], Step [300/391] Loss: 2.3146\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [6/80], Step [100/391] Loss: 2.3054\n",
            "Epoch [6/80], Step [200/391] Loss: 2.3073\n",
            "Epoch [6/80], Step [300/391] Loss: 2.3056\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [7/80], Step [100/391] Loss: 2.2884\n",
            "Epoch [7/80], Step [200/391] Loss: 2.3053\n",
            "Epoch [7/80], Step [300/391] Loss: 2.3024\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [8/80], Step [100/391] Loss: 2.3129\n",
            "Epoch [8/80], Step [200/391] Loss: 2.3089\n",
            "Epoch [8/80], Step [300/391] Loss: 2.3115\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [9/80], Step [100/391] Loss: 2.3008\n",
            "Epoch [9/80], Step [200/391] Loss: 2.3020\n",
            "Epoch [9/80], Step [300/391] Loss: 2.3063\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [10/80], Step [100/391] Loss: 2.3094\n",
            "Epoch [10/80], Step [200/391] Loss: 2.3001\n",
            "Epoch [10/80], Step [300/391] Loss: 2.2950\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [11/80], Step [100/391] Loss: 2.3052\n",
            "Epoch [11/80], Step [200/391] Loss: 2.3070\n",
            "Epoch [11/80], Step [300/391] Loss: 2.3029\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [12/80], Step [100/391] Loss: 2.3074\n",
            "Epoch [12/80], Step [200/391] Loss: 2.3000\n",
            "Epoch [12/80], Step [300/391] Loss: 2.3044\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [13/80], Step [100/391] Loss: 2.3008\n",
            "Epoch [13/80], Step [200/391] Loss: 2.2992\n",
            "Epoch [13/80], Step [300/391] Loss: 2.3154\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [14/80], Step [100/391] Loss: 2.3052\n",
            "Epoch [14/80], Step [200/391] Loss: 2.3044\n",
            "Epoch [14/80], Step [300/391] Loss: 2.2992\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [15/80], Step [100/391] Loss: 2.2965\n",
            "Epoch [15/80], Step [200/391] Loss: 2.3035\n",
            "Epoch [15/80], Step [300/391] Loss: 2.3007\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [16/80], Step [100/391] Loss: 2.3088\n",
            "Epoch [16/80], Step [200/391] Loss: 2.3026\n",
            "Epoch [16/80], Step [300/391] Loss: 2.2958\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [17/80], Step [100/391] Loss: 2.3118\n",
            "Epoch [17/80], Step [200/391] Loss: 2.2957\n",
            "Epoch [17/80], Step [300/391] Loss: 2.3022\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [18/80], Step [100/391] Loss: 2.3078\n",
            "Epoch [18/80], Step [200/391] Loss: 2.3080\n",
            "Epoch [18/80], Step [300/391] Loss: 2.3009\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [19/80], Step [100/391] Loss: 2.3062\n",
            "Epoch [19/80], Step [200/391] Loss: 2.3074\n",
            "Epoch [19/80], Step [300/391] Loss: 2.3187\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [20/80], Step [100/391] Loss: 2.3045\n",
            "Epoch [20/80], Step [200/391] Loss: 2.2984\n",
            "Epoch [20/80], Step [300/391] Loss: 2.2932\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [21/80], Step [100/391] Loss: 2.3020\n",
            "Epoch [21/80], Step [200/391] Loss: 2.3050\n",
            "Epoch [21/80], Step [300/391] Loss: 2.3070\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [22/80], Step [100/391] Loss: 2.3096\n",
            "Epoch [22/80], Step [200/391] Loss: 2.3015\n",
            "Epoch [22/80], Step [300/391] Loss: 2.2997\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [23/80], Step [100/391] Loss: 2.3018\n",
            "Epoch [23/80], Step [200/391] Loss: 2.3152\n",
            "Epoch [23/80], Step [300/391] Loss: 2.3106\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [24/80], Step [100/391] Loss: 2.3071\n",
            "Epoch [24/80], Step [200/391] Loss: 2.3014\n",
            "Epoch [24/80], Step [300/391] Loss: 2.3121\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [25/80], Step [100/391] Loss: 2.3048\n",
            "Epoch [25/80], Step [200/391] Loss: 2.3044\n",
            "Epoch [25/80], Step [300/391] Loss: 2.3082\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [26/80], Step [100/391] Loss: 2.3069\n",
            "Epoch [26/80], Step [200/391] Loss: 2.3104\n",
            "Epoch [26/80], Step [300/391] Loss: 2.3021\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [27/80], Step [100/391] Loss: 2.3077\n",
            "Epoch [27/80], Step [200/391] Loss: 2.3013\n",
            "Epoch [27/80], Step [300/391] Loss: 2.2953\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [28/80], Step [100/391] Loss: 2.2976\n",
            "Epoch [28/80], Step [200/391] Loss: 2.3014\n",
            "Epoch [28/80], Step [300/391] Loss: 2.2966\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [29/80], Step [100/391] Loss: 2.3028\n",
            "Epoch [29/80], Step [200/391] Loss: 2.3017\n",
            "Epoch [29/80], Step [300/391] Loss: 2.3166\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [30/80], Step [100/391] Loss: 2.3043\n",
            "Epoch [30/80], Step [200/391] Loss: 2.3046\n",
            "Epoch [30/80], Step [300/391] Loss: 2.3038\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [31/80], Step [100/391] Loss: 2.3037\n",
            "Epoch [31/80], Step [200/391] Loss: 2.3002\n",
            "Epoch [31/80], Step [300/391] Loss: 2.3207\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [32/80], Step [100/391] Loss: 2.3090\n",
            "Epoch [32/80], Step [200/391] Loss: 2.3034\n",
            "Epoch [32/80], Step [300/391] Loss: 2.2972\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [33/80], Step [100/391] Loss: 2.3048\n",
            "Epoch [33/80], Step [200/391] Loss: 2.3023\n",
            "Epoch [33/80], Step [300/391] Loss: 2.3087\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [34/80], Step [100/391] Loss: 2.2999\n",
            "Epoch [34/80], Step [200/391] Loss: 2.3014\n",
            "Epoch [34/80], Step [300/391] Loss: 2.3007\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [35/80], Step [100/391] Loss: 2.3067\n",
            "Epoch [35/80], Step [200/391] Loss: 2.3012\n",
            "Epoch [35/80], Step [300/391] Loss: 2.3083\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [36/80], Step [100/391] Loss: 2.3055\n",
            "Epoch [36/80], Step [200/391] Loss: 2.3115\n",
            "Epoch [36/80], Step [300/391] Loss: 2.3129\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [37/80], Step [100/391] Loss: 2.2991\n",
            "Epoch [37/80], Step [200/391] Loss: 2.3028\n",
            "Epoch [37/80], Step [300/391] Loss: 2.3143\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [38/80], Step [100/391] Loss: 2.3084\n",
            "Epoch [38/80], Step [200/391] Loss: 2.3127\n",
            "Epoch [38/80], Step [300/391] Loss: 2.2968\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [39/80], Step [100/391] Loss: 2.2991\n",
            "Epoch [39/80], Step [200/391] Loss: 2.2921\n",
            "Epoch [39/80], Step [300/391] Loss: 2.2931\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [40/80], Step [100/391] Loss: 2.3073\n",
            "Epoch [40/80], Step [200/391] Loss: 2.2982\n",
            "Epoch [40/80], Step [300/391] Loss: 2.3087\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [41/80], Step [100/391] Loss: 2.3097\n",
            "Epoch [41/80], Step [200/391] Loss: 2.3083\n",
            "Epoch [41/80], Step [300/391] Loss: 2.3043\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [42/80], Step [100/391] Loss: 2.3022\n",
            "Epoch [42/80], Step [200/391] Loss: 2.2936\n",
            "Epoch [42/80], Step [300/391] Loss: 2.3081\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [43/80], Step [100/391] Loss: 2.3071\n",
            "Epoch [43/80], Step [200/391] Loss: 2.3024\n",
            "Epoch [43/80], Step [300/391] Loss: 2.2962\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [44/80], Step [100/391] Loss: 2.3041\n",
            "Epoch [44/80], Step [200/391] Loss: 2.3065\n",
            "Epoch [44/80], Step [300/391] Loss: 2.2948\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [45/80], Step [100/391] Loss: 2.3037\n",
            "Epoch [45/80], Step [200/391] Loss: 2.3081\n",
            "Epoch [45/80], Step [300/391] Loss: 2.3019\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [46/80], Step [100/391] Loss: 2.3024\n",
            "Epoch [46/80], Step [200/391] Loss: 2.3010\n",
            "Epoch [46/80], Step [300/391] Loss: 2.2914\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [47/80], Step [100/391] Loss: 2.2969\n",
            "Epoch [47/80], Step [200/391] Loss: 2.3077\n",
            "Epoch [47/80], Step [300/391] Loss: 2.3102\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [48/80], Step [100/391] Loss: 2.2961\n",
            "Epoch [48/80], Step [200/391] Loss: 2.3094\n",
            "Epoch [48/80], Step [300/391] Loss: 2.3036\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [49/80], Step [100/391] Loss: 2.3037\n",
            "Epoch [49/80], Step [200/391] Loss: 2.3059\n",
            "Epoch [49/80], Step [300/391] Loss: 2.3076\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [50/80], Step [100/391] Loss: 2.3027\n",
            "Epoch [50/80], Step [200/391] Loss: 2.3093\n",
            "Epoch [50/80], Step [300/391] Loss: 2.3054\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [51/80], Step [100/391] Loss: 2.3073\n",
            "Epoch [51/80], Step [200/391] Loss: 2.3026\n",
            "Epoch [51/80], Step [300/391] Loss: 2.3049\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [52/80], Step [100/391] Loss: 2.3119\n",
            "Epoch [52/80], Step [200/391] Loss: 2.3042\n",
            "Epoch [52/80], Step [300/391] Loss: 2.3005\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [53/80], Step [100/391] Loss: 2.3043\n",
            "Epoch [53/80], Step [200/391] Loss: 2.3036\n",
            "Epoch [53/80], Step [300/391] Loss: 2.3100\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [54/80], Step [100/391] Loss: 2.3044\n",
            "Epoch [54/80], Step [200/391] Loss: 2.3068\n",
            "Epoch [54/80], Step [300/391] Loss: 2.3013\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [55/80], Step [100/391] Loss: 2.3038\n",
            "Epoch [55/80], Step [200/391] Loss: 2.3076\n",
            "Epoch [55/80], Step [300/391] Loss: 2.2992\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [56/80], Step [100/391] Loss: 2.3031\n",
            "Epoch [56/80], Step [200/391] Loss: 2.3088\n",
            "Epoch [56/80], Step [300/391] Loss: 2.2992\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [57/80], Step [100/391] Loss: 2.3018\n",
            "Epoch [57/80], Step [200/391] Loss: 2.3061\n",
            "Epoch [57/80], Step [300/391] Loss: 2.3085\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [58/80], Step [100/391] Loss: 2.3036\n",
            "Epoch [58/80], Step [200/391] Loss: 2.3006\n",
            "Epoch [58/80], Step [300/391] Loss: 2.3080\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [59/80], Step [100/391] Loss: 2.3017\n",
            "Epoch [59/80], Step [200/391] Loss: 2.3032\n",
            "Epoch [59/80], Step [300/391] Loss: 2.3026\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [60/80], Step [100/391] Loss: 2.2998\n",
            "Epoch [60/80], Step [200/391] Loss: 2.3025\n",
            "Epoch [60/80], Step [300/391] Loss: 2.3014\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [61/80], Step [100/391] Loss: 2.3003\n",
            "Epoch [61/80], Step [200/391] Loss: 2.3051\n",
            "Epoch [61/80], Step [300/391] Loss: 2.3031\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [62/80], Step [100/391] Loss: 2.3027\n",
            "Epoch [62/80], Step [200/391] Loss: 2.3014\n",
            "Epoch [62/80], Step [300/391] Loss: 2.3076\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [63/80], Step [100/391] Loss: 2.3056\n",
            "Epoch [63/80], Step [200/391] Loss: 2.3047\n",
            "Epoch [63/80], Step [300/391] Loss: 2.3069\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [64/80], Step [100/391] Loss: 2.2995\n",
            "Epoch [64/80], Step [200/391] Loss: 2.2982\n",
            "Epoch [64/80], Step [300/391] Loss: 2.3080\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [65/80], Step [100/391] Loss: 2.2991\n",
            "Epoch [65/80], Step [200/391] Loss: 2.3155\n",
            "Epoch [65/80], Step [300/391] Loss: 2.2973\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [66/80], Step [100/391] Loss: 2.3201\n",
            "Epoch [66/80], Step [200/391] Loss: 2.3074\n",
            "Epoch [66/80], Step [300/391] Loss: 2.2989\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [67/80], Step [100/391] Loss: 2.3022\n",
            "Epoch [67/80], Step [200/391] Loss: 2.2972\n",
            "Epoch [67/80], Step [300/391] Loss: 2.3000\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [68/80], Step [100/391] Loss: 2.3031\n",
            "Epoch [68/80], Step [200/391] Loss: 2.3053\n",
            "Epoch [68/80], Step [300/391] Loss: 2.3031\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [69/80], Step [100/391] Loss: 2.3032\n",
            "Epoch [69/80], Step [200/391] Loss: 2.3063\n",
            "Epoch [69/80], Step [300/391] Loss: 2.3061\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [70/80], Step [100/391] Loss: 2.3019\n",
            "Epoch [70/80], Step [200/391] Loss: 2.3021\n",
            "Epoch [70/80], Step [300/391] Loss: 2.3071\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [71/80], Step [100/391] Loss: 2.3055\n",
            "Epoch [71/80], Step [200/391] Loss: 2.3073\n",
            "Epoch [71/80], Step [300/391] Loss: 2.3006\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [72/80], Step [100/391] Loss: 2.2981\n",
            "Epoch [72/80], Step [200/391] Loss: 2.3057\n",
            "Epoch [72/80], Step [300/391] Loss: 2.3120\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [73/80], Step [100/391] Loss: 2.3098\n",
            "Epoch [73/80], Step [200/391] Loss: 2.3103\n",
            "Epoch [73/80], Step [300/391] Loss: 2.3106\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [74/80], Step [100/391] Loss: 2.3007\n",
            "Epoch [74/80], Step [200/391] Loss: 2.3016\n",
            "Epoch [74/80], Step [300/391] Loss: 2.2972\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [75/80], Step [100/391] Loss: 2.3079\n",
            "Epoch [75/80], Step [200/391] Loss: 2.3133\n",
            "Epoch [75/80], Step [300/391] Loss: 2.3036\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [76/80], Step [100/391] Loss: 2.3066\n",
            "Epoch [76/80], Step [200/391] Loss: 2.3115\n",
            "Epoch [76/80], Step [300/391] Loss: 2.3043\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [77/80], Step [100/391] Loss: 2.3024\n",
            "Epoch [77/80], Step [200/391] Loss: 2.3048\n",
            "Epoch [77/80], Step [300/391] Loss: 2.2950\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [78/80], Step [100/391] Loss: 2.3071\n",
            "Epoch [78/80], Step [200/391] Loss: 2.3024\n",
            "Epoch [78/80], Step [300/391] Loss: 2.3036\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [79/80], Step [100/391] Loss: 2.2976\n",
            "Epoch [79/80], Step [200/391] Loss: 2.3074\n",
            "Epoch [79/80], Step [300/391] Loss: 2.3096\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [80/80], Step [100/391] Loss: 2.3040\n",
            "Epoch [80/80], Step [200/391] Loss: 2.3128\n",
            "Epoch [80/80], Step [300/391] Loss: 2.3022\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Accuracy of the model on the test images: 10.0 %\n",
            "plainnet32.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MnJrmEHSp9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b78311-5a6a-426f-a41a-3f3a00a632ba"
      },
      "source": [
        "Plainnetwork44Model = createResnetModelWithDepth(44)\n",
        "trainModel(Plainnetwork44Model,44)\n",
        "testModel(Plainnetwork44Model)\n",
        "saveModel(Plainnetwork44Model,44)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: nan\n",
            "Epoch [1/80], Step [200/391] Loss: nan\n",
            "Epoch [1/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [2/80], Step [100/391] Loss: nan\n",
            "Epoch [2/80], Step [200/391] Loss: nan\n",
            "Epoch [2/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [3/80], Step [100/391] Loss: nan\n",
            "Epoch [3/80], Step [200/391] Loss: nan\n",
            "Epoch [3/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [4/80], Step [100/391] Loss: nan\n",
            "Epoch [4/80], Step [200/391] Loss: nan\n",
            "Epoch [4/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [5/80], Step [100/391] Loss: nan\n",
            "Epoch [5/80], Step [200/391] Loss: nan\n",
            "Epoch [5/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [6/80], Step [100/391] Loss: nan\n",
            "Epoch [6/80], Step [200/391] Loss: nan\n",
            "Epoch [6/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [7/80], Step [100/391] Loss: nan\n",
            "Epoch [7/80], Step [200/391] Loss: nan\n",
            "Epoch [7/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [8/80], Step [100/391] Loss: nan\n",
            "Epoch [8/80], Step [200/391] Loss: nan\n",
            "Epoch [8/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [9/80], Step [100/391] Loss: nan\n",
            "Epoch [9/80], Step [200/391] Loss: nan\n",
            "Epoch [9/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [10/80], Step [100/391] Loss: nan\n",
            "Epoch [10/80], Step [200/391] Loss: nan\n",
            "Epoch [10/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [11/80], Step [100/391] Loss: nan\n",
            "Epoch [11/80], Step [200/391] Loss: nan\n",
            "Epoch [11/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [12/80], Step [100/391] Loss: nan\n",
            "Epoch [12/80], Step [200/391] Loss: nan\n",
            "Epoch [12/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [13/80], Step [100/391] Loss: nan\n",
            "Epoch [13/80], Step [200/391] Loss: nan\n",
            "Epoch [13/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [14/80], Step [100/391] Loss: nan\n",
            "Epoch [14/80], Step [200/391] Loss: nan\n",
            "Epoch [14/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [15/80], Step [100/391] Loss: nan\n",
            "Epoch [15/80], Step [200/391] Loss: nan\n",
            "Epoch [15/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [16/80], Step [100/391] Loss: nan\n",
            "Epoch [16/80], Step [200/391] Loss: nan\n",
            "Epoch [16/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [17/80], Step [100/391] Loss: nan\n",
            "Epoch [17/80], Step [200/391] Loss: nan\n",
            "Epoch [17/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [18/80], Step [100/391] Loss: nan\n",
            "Epoch [18/80], Step [200/391] Loss: nan\n",
            "Epoch [18/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [19/80], Step [100/391] Loss: nan\n",
            "Epoch [19/80], Step [200/391] Loss: nan\n",
            "Epoch [19/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [20/80], Step [100/391] Loss: nan\n",
            "Epoch [20/80], Step [200/391] Loss: nan\n",
            "Epoch [20/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [21/80], Step [100/391] Loss: nan\n",
            "Epoch [21/80], Step [200/391] Loss: nan\n",
            "Epoch [21/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [22/80], Step [100/391] Loss: nan\n",
            "Epoch [22/80], Step [200/391] Loss: nan\n",
            "Epoch [22/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [23/80], Step [100/391] Loss: nan\n",
            "Epoch [23/80], Step [200/391] Loss: nan\n",
            "Epoch [23/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [24/80], Step [100/391] Loss: nan\n",
            "Epoch [24/80], Step [200/391] Loss: nan\n",
            "Epoch [24/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [25/80], Step [100/391] Loss: nan\n",
            "Epoch [25/80], Step [200/391] Loss: nan\n",
            "Epoch [25/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [26/80], Step [100/391] Loss: nan\n",
            "Epoch [26/80], Step [200/391] Loss: nan\n",
            "Epoch [26/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [27/80], Step [100/391] Loss: nan\n",
            "Epoch [27/80], Step [200/391] Loss: nan\n",
            "Epoch [27/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [28/80], Step [100/391] Loss: nan\n",
            "Epoch [28/80], Step [200/391] Loss: nan\n",
            "Epoch [28/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [29/80], Step [100/391] Loss: nan\n",
            "Epoch [29/80], Step [200/391] Loss: nan\n",
            "Epoch [29/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [30/80], Step [100/391] Loss: nan\n",
            "Epoch [30/80], Step [200/391] Loss: nan\n",
            "Epoch [30/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [31/80], Step [100/391] Loss: nan\n",
            "Epoch [31/80], Step [200/391] Loss: nan\n",
            "Epoch [31/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [32/80], Step [100/391] Loss: nan\n",
            "Epoch [32/80], Step [200/391] Loss: nan\n",
            "Epoch [32/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [33/80], Step [100/391] Loss: nan\n",
            "Epoch [33/80], Step [200/391] Loss: nan\n",
            "Epoch [33/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [34/80], Step [100/391] Loss: nan\n",
            "Epoch [34/80], Step [200/391] Loss: nan\n",
            "Epoch [34/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [35/80], Step [100/391] Loss: nan\n",
            "Epoch [35/80], Step [200/391] Loss: nan\n",
            "Epoch [35/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [36/80], Step [100/391] Loss: nan\n",
            "Epoch [36/80], Step [200/391] Loss: nan\n",
            "Epoch [36/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [37/80], Step [100/391] Loss: nan\n",
            "Epoch [37/80], Step [200/391] Loss: nan\n",
            "Epoch [37/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [38/80], Step [100/391] Loss: nan\n",
            "Epoch [38/80], Step [200/391] Loss: nan\n",
            "Epoch [38/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [39/80], Step [100/391] Loss: nan\n",
            "Epoch [39/80], Step [200/391] Loss: nan\n",
            "Epoch [39/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [40/80], Step [100/391] Loss: nan\n",
            "Epoch [40/80], Step [200/391] Loss: nan\n",
            "Epoch [40/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [41/80], Step [100/391] Loss: nan\n",
            "Epoch [41/80], Step [200/391] Loss: nan\n",
            "Epoch [41/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [42/80], Step [100/391] Loss: nan\n",
            "Epoch [42/80], Step [200/391] Loss: nan\n",
            "Epoch [42/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [43/80], Step [100/391] Loss: nan\n",
            "Epoch [43/80], Step [200/391] Loss: nan\n",
            "Epoch [43/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [44/80], Step [100/391] Loss: nan\n",
            "Epoch [44/80], Step [200/391] Loss: nan\n",
            "Epoch [44/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [45/80], Step [100/391] Loss: nan\n",
            "Epoch [45/80], Step [200/391] Loss: nan\n",
            "Epoch [45/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [46/80], Step [100/391] Loss: nan\n",
            "Epoch [46/80], Step [200/391] Loss: nan\n",
            "Epoch [46/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [47/80], Step [100/391] Loss: nan\n",
            "Epoch [47/80], Step [200/391] Loss: nan\n",
            "Epoch [47/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [48/80], Step [100/391] Loss: nan\n",
            "Epoch [48/80], Step [200/391] Loss: nan\n",
            "Epoch [48/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [49/80], Step [100/391] Loss: nan\n",
            "Epoch [49/80], Step [200/391] Loss: nan\n",
            "Epoch [49/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [50/80], Step [100/391] Loss: nan\n",
            "Epoch [50/80], Step [200/391] Loss: nan\n",
            "Epoch [50/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [51/80], Step [100/391] Loss: nan\n",
            "Epoch [51/80], Step [200/391] Loss: nan\n",
            "Epoch [51/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [52/80], Step [100/391] Loss: nan\n",
            "Epoch [52/80], Step [200/391] Loss: nan\n",
            "Epoch [52/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [53/80], Step [100/391] Loss: nan\n",
            "Epoch [53/80], Step [200/391] Loss: nan\n",
            "Epoch [53/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [54/80], Step [100/391] Loss: nan\n",
            "Epoch [54/80], Step [200/391] Loss: nan\n",
            "Epoch [54/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [55/80], Step [100/391] Loss: nan\n",
            "Epoch [55/80], Step [200/391] Loss: nan\n",
            "Epoch [55/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [56/80], Step [100/391] Loss: nan\n",
            "Epoch [56/80], Step [200/391] Loss: nan\n",
            "Epoch [56/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [57/80], Step [100/391] Loss: nan\n",
            "Epoch [57/80], Step [200/391] Loss: nan\n",
            "Epoch [57/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [58/80], Step [100/391] Loss: nan\n",
            "Epoch [58/80], Step [200/391] Loss: nan\n",
            "Epoch [58/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [59/80], Step [100/391] Loss: nan\n",
            "Epoch [59/80], Step [200/391] Loss: nan\n",
            "Epoch [59/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [60/80], Step [100/391] Loss: nan\n",
            "Epoch [60/80], Step [200/391] Loss: nan\n",
            "Epoch [60/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [61/80], Step [100/391] Loss: nan\n",
            "Epoch [61/80], Step [200/391] Loss: nan\n",
            "Epoch [61/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [62/80], Step [100/391] Loss: nan\n",
            "Epoch [62/80], Step [200/391] Loss: nan\n",
            "Epoch [62/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [63/80], Step [100/391] Loss: nan\n",
            "Epoch [63/80], Step [200/391] Loss: nan\n",
            "Epoch [63/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [64/80], Step [100/391] Loss: nan\n",
            "Epoch [64/80], Step [200/391] Loss: nan\n",
            "Epoch [64/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [65/80], Step [100/391] Loss: nan\n",
            "Epoch [65/80], Step [200/391] Loss: nan\n",
            "Epoch [65/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [66/80], Step [100/391] Loss: nan\n",
            "Epoch [66/80], Step [200/391] Loss: nan\n",
            "Epoch [66/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [67/80], Step [100/391] Loss: nan\n",
            "Epoch [67/80], Step [200/391] Loss: nan\n",
            "Epoch [67/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [68/80], Step [100/391] Loss: nan\n",
            "Epoch [68/80], Step [200/391] Loss: nan\n",
            "Epoch [68/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [69/80], Step [100/391] Loss: nan\n",
            "Epoch [69/80], Step [200/391] Loss: nan\n",
            "Epoch [69/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [70/80], Step [100/391] Loss: nan\n",
            "Epoch [70/80], Step [200/391] Loss: nan\n",
            "Epoch [70/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [71/80], Step [100/391] Loss: nan\n",
            "Epoch [71/80], Step [200/391] Loss: nan\n",
            "Epoch [71/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [72/80], Step [100/391] Loss: nan\n",
            "Epoch [72/80], Step [200/391] Loss: nan\n",
            "Epoch [72/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [73/80], Step [100/391] Loss: nan\n",
            "Epoch [73/80], Step [200/391] Loss: nan\n",
            "Epoch [73/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [74/80], Step [100/391] Loss: nan\n",
            "Epoch [74/80], Step [200/391] Loss: nan\n",
            "Epoch [74/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [75/80], Step [100/391] Loss: nan\n",
            "Epoch [75/80], Step [200/391] Loss: nan\n",
            "Epoch [75/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [76/80], Step [100/391] Loss: nan\n",
            "Epoch [76/80], Step [200/391] Loss: nan\n",
            "Epoch [76/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [77/80], Step [100/391] Loss: nan\n",
            "Epoch [77/80], Step [200/391] Loss: nan\n",
            "Epoch [77/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [78/80], Step [100/391] Loss: nan\n",
            "Epoch [78/80], Step [200/391] Loss: nan\n",
            "Epoch [78/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [79/80], Step [100/391] Loss: nan\n",
            "Epoch [79/80], Step [200/391] Loss: nan\n",
            "Epoch [79/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [80/80], Step [100/391] Loss: nan\n",
            "Epoch [80/80], Step [200/391] Loss: nan\n",
            "Epoch [80/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Accuracy of the model on the test images: 10.0 %\n",
            "plainnet44.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePBfRVHtSpvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a4307d-d443-4298-c06a-aff9301aa402"
      },
      "source": [
        "Plainnetwork56Model = createResnetModelWithDepth(56)\n",
        "trainModel(Plainnetwork56Model,56)\n",
        "testModel(Plainnetwork56Model)\n",
        "saveModel(Plainnetwork56Model,56)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch [1/80], Step [100/391] Loss: nan\n",
            "Epoch [1/80], Step [200/391] Loss: nan\n",
            "Epoch [1/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [2/80], Step [100/391] Loss: nan\n",
            "Epoch [2/80], Step [200/391] Loss: nan\n",
            "Epoch [2/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [3/80], Step [100/391] Loss: nan\n",
            "Epoch [3/80], Step [200/391] Loss: nan\n",
            "Epoch [3/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [4/80], Step [100/391] Loss: nan\n",
            "Epoch [4/80], Step [200/391] Loss: nan\n",
            "Epoch [4/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [5/80], Step [100/391] Loss: nan\n",
            "Epoch [5/80], Step [200/391] Loss: nan\n",
            "Epoch [5/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [6/80], Step [100/391] Loss: nan\n",
            "Epoch [6/80], Step [200/391] Loss: nan\n",
            "Epoch [6/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [7/80], Step [100/391] Loss: nan\n",
            "Epoch [7/80], Step [200/391] Loss: nan\n",
            "Epoch [7/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [8/80], Step [100/391] Loss: nan\n",
            "Epoch [8/80], Step [200/391] Loss: nan\n",
            "Epoch [8/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [9/80], Step [100/391] Loss: nan\n",
            "Epoch [9/80], Step [200/391] Loss: nan\n",
            "Epoch [9/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [10/80], Step [100/391] Loss: nan\n",
            "Epoch [10/80], Step [200/391] Loss: nan\n",
            "Epoch [10/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [11/80], Step [100/391] Loss: nan\n",
            "Epoch [11/80], Step [200/391] Loss: nan\n",
            "Epoch [11/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [12/80], Step [100/391] Loss: nan\n",
            "Epoch [12/80], Step [200/391] Loss: nan\n",
            "Epoch [12/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [13/80], Step [100/391] Loss: nan\n",
            "Epoch [13/80], Step [200/391] Loss: nan\n",
            "Epoch [13/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [14/80], Step [100/391] Loss: nan\n",
            "Epoch [14/80], Step [200/391] Loss: nan\n",
            "Epoch [14/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [15/80], Step [100/391] Loss: nan\n",
            "Epoch [15/80], Step [200/391] Loss: nan\n",
            "Epoch [15/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [16/80], Step [100/391] Loss: nan\n",
            "Epoch [16/80], Step [200/391] Loss: nan\n",
            "Epoch [16/80], Step [300/391] Loss: nan\n",
            "train_err: 0.9 test_err: 0.9\n",
            "Epoch [17/80], Step [100/391] Loss: nan\n",
            "Epoch [17/80], Step [200/391] Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8fa9bnHD2Sd"
      },
      "source": [
        "###Classification error and the number of parameters of each architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQVjcEMxC-g1"
      },
      "source": [
        "calculateModelParams(Plainnetwork20Model)\n",
        "calculateModelParams(Plainnetwork32Model)\n",
        "calculateModelParams(Plainnetwork44Model)\n",
        "calculateModelParams(Plainnetwork56Model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91LREsTa_2D1"
      },
      "source": [
        "ns  = [3, 5, 7, 9]\n",
        "clr = ['y', 'c', 'g', 'r']\n",
        "\n",
        "\n",
        "plainnet_dfs = [pd.read_csv(f'results/Plainnet{6*n+2}.csv') for n in ns]\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "plt.axis([0, 80, 0, 100])\n",
        "\n",
        "\n",
        "for i in range(len(ns)):\n",
        "    plt.plot(plainnet_dfs[i]['epoch'], plainnet_dfs[i]['train_err']*100, f'{clr[i]}--',\n",
        "             label=f'plain-{6*ns[i]+2} train')\n",
        "    plt.plot(plainnet_dfs[i]['epoch'], plainnet_dfs[i]['test_err']*100, f'{clr[i]}',\n",
        "             label=f'plain-{6*ns[i]+2} test')\n",
        "\n",
        "plt.title('Comparison of four plain convolutional networks with 20, 32, 44 and 56 layers.')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('error (%)')\n",
        "plt.axhline(10, color='black', alpha=0.5, dashes=(10., 10.))\n",
        "plt.axhline(5, color='black', alpha=0.5, dashes=(10., 10.));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSjzDKaQDR0W"
      },
      "source": [
        "bests = [df[df['test_err'] == df['test_err'].min()].iloc[0] for df in plainnet_dfs]\n",
        "bests_df= pd.concat(bests, axis=1).T\n",
        "bests_df['model'] = ['PlainNet20', 'PlainNet32', 'PlainNet44', 'PlainNet56']\n",
        "display(bests_df[['model', 'test_err']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raVwOJjP-Q5d"
      },
      "source": [
        " ##Q2) In the same Notebook, plot the classification error vs. the number of epochs for the above 4 ResNet architectures and in addition those generated by using deep CNN models without residual links (plain network presented at Figure 3middle of the above paper) of depth 20, 32, 44 and 56 layers, and"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLFFlIwB-X92"
      },
      "source": [
        "ns  = [3, 5, 7, 9]\n",
        "clr = ['y', 'c', 'g', 'r']\n",
        "\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(25, 7))\n",
        "\n",
        "plainnet_dfs = [pd.read_csv(f'results/plainnet{6*n+2}.csv') for n in ns]\n",
        "resnet_dfs = [pd.read_csv(f'results/resnet{6*n+2}.csv') for n in ns]\n",
        "\n",
        "def plot_results(dfs, ax, title):\n",
        "    ax.axis([0, 80, 0, 100])\n",
        "    \n",
        "    for i in range(len(ns)):\n",
        "        ax.plot(dfs[i]['epoch'], dfs[i]['train_err']*100, f'{clr[i]}--',\n",
        "                 label=f'plain-{6*ns[i]+2} train')\n",
        "        ax.plot(dfs[i]['epoch'], dfs[i]['test_err']*100, f'{clr[i]}',\n",
        "                 label=f'plain-{6*ns[i]+2} test')\n",
        "    \n",
        "    ax.set_title(title)\n",
        "    ax.legend(loc='bottom left')\n",
        "    ax.set_xlabel('epochs')\n",
        "    ax.set_ylabel('error (%)')\n",
        "    ax.axhline(10, color='black', alpha=0.5, dashes=(10., 10.))\n",
        "    ax.axhline(5, color='black', alpha=0.5, dashes=(10., 10.));\n",
        "    \n",
        "plot_results(plainnet_dfs, ax1, 'Plain Networks')\n",
        "plot_results(resnet_dfs, ax2, 'Residual Networks')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}