{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP61AWkgIsqbKcFEpknRDPs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeinabmohamed/CIT690E-DeepLearning-Zeinab_Abdelmawla-191009/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1e-XiIV8EQA"
      },
      "source": [
        "\n",
        "# **Assignment # 2**\n",
        "\n",
        "### Name : Zeinab Abdelmawla\n",
        "### NU ID : 191009 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpwevqe14n30"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qc02AAoFYKE"
      },
      "source": [
        "def plot(input,output,title,xLable,yLabel):\n",
        "  plt.plot(input, output)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xLable)\n",
        "  plt.ylabel(yLabel)\n",
        "  return plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR86K5NtAwlP"
      },
      "source": [
        "Q1 – Write a python program on Google colab to plot Activation function with\n",
        "Linear Units, Sigmoid Units, Hyperbolic Tangent Units, and Rectified Linear\n",
        "Units (ReLU), where the independent variable, x, is between -10 and 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGUiCEbZA_bO"
      },
      "source": [
        "\n",
        "*   Linear Activattion Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Z6ODemAfY0"
      },
      "source": [
        "def activation_fun_linear (x):\n",
        "  return x;\n",
        "\n",
        "input = torch.arange(-10, 11)\n",
        "plot(input,activation_fun_linear(input),'Linear Activation Function','Input','Activation output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LAULwE5Bm75"
      },
      "source": [
        "*   Sigmoid Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGuJL-C9BtuP"
      },
      "source": [
        "def activation_fun_sigmoid (x):\n",
        "  return 1/(1+torch.exp(-x));\n",
        "  \n",
        "input = torch.arange(-10, 11)\n",
        "plot(input,activation_fun_sigmoid(input),'Sigmoid Activation Function','Input','Activation output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h24ILl2GCGcW"
      },
      "source": [
        "*   Hyperbolic Tangent Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB_lQZLACD1F"
      },
      "source": [
        "def activation_fun_hyperbolic_tangent(x):\n",
        "  return torch.tanh(x);\n",
        "  \n",
        "input = torch.arange(-10, 11)\n",
        "plot(input,activation_fun_hyperbolic_tangent(input),'Hyperbolic_Tangent Activation Function','Input','Activation output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usNy2tH7CqG0"
      },
      "source": [
        "*    Rectified Linear Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXvpGfDAEkcR"
      },
      "source": [
        "```\n",
        "# Sol # 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVpF3PMGCwU0"
      },
      "source": [
        "def activation_fun_relu(x):\n",
        "  return torch.max(zeros,x);\n",
        "\n",
        "zeros = torch.zeros((21))  \n",
        "input = torch.arange(-10, 11)\n",
        "plot(input,activation_fun_relu(input),'ReLU Activation Function','Input','Activation output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAoYrqYYEvQw"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Sol # 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti72hak6EFA6"
      },
      "source": [
        "m = torch.nn.ReLU()\n",
        "input = torch.arange(-10, 11)\n",
        "plot(input, m(input),'ReLU Activation Function','Input','Activation output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLM2QHTNGy0E"
      },
      "source": [
        "2 – Given an input vector [-1, 0]. and output 1, write equations and \n",
        "find the activations, and the MSE error corresponding to the following \n",
        "feedforward neural network, where the bias is zero and the activation function \n",
        "used is Sigmoid.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAu2XBzOcXz"
      },
      "source": [
        ""
      ]
    }
  ]
}